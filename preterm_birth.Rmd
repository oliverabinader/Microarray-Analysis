---
title: "PRETERM BIRTH ANALYSIS"
author: "ABINADER Oliver"
date: "Monday, January 20th, 2020"
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
    number_sections: TRUE
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# List Of Packages

```{r packages,warning=FALSE,message=FALSE}
library(Biobase)
library(oligo)
library(limma)

library(MASS) 
library(e1071)
library(lme4)

library(gplots)
library(ggplot2)
library(ggcorrplot)

library(preprocessCore)
library(plotly)
library(wesanderson)
library(dplyr)
```

<div style="text-align: justify"><u>**PART II - Perform Statistical Analysis: Predicting Preterm Birth**</u></div><br/>

# Preparation Of The RData

<div style="text-align: justify">The goal of this project is to determine how accurately the maternal whole blood transcriptome from samples collected during pregnancy (17-36 weeks) in asymptomatic women, can predict preterm birth. Women with preterm birth included in the challenge delivered before 37 weeks of gestation either by spontaneous preterm delivery (sPTD) or by preterm premature rupture of membranes (PPROM). The gestational ages at blood draw of all samples from a given patient are provided in the data section.

I am required to develop models in order to make three sets of predictions for all individuals in the test set. The first set of predictions will classify individuals as sPTD v/s PPROM v/s Control, the second one will classify women as sPTD vs Control, while the third prediction will classify individuals as PPROM vs Control.I have the freedom to use any of the samples collected from 17-36 weeks of gestation for a given patient when predicting that delivery occurred before 37 weeks.
But first I need to preperare the eset dataset that will be used for the analysis. This consists of a fully, complete dataset that will hold two objects: the first one contains the gene expression matrix and the second one will have the informations for each microarray/sample.</div>

## Import AllSamples.csv File 

```{r,warning=FALSE,message=FALSE}
rm(list=ls())

#all samples involved in data preprocessing;
allSamples <- read.csv("~/Downloads/allSamples.csv")
head(allSamples) #provides G.A. for all samples/microarrays.
cat("The number of total microarray samples equals to",dim(allSamples)[1],"\n")
```

## Microarray Samples Used In This Challenge

```{r,warning=FALSE,message=FALSE}
#defines which samples will be used in this challenge among allSamples
ano_v20_nokey <- read.csv("/Users/oliverabinader/Downloads/ano_v20_nokey.csv",stringsAsFactors = F)
head(ano_v20_nokey)
cat("The number of microarray samples in this challenge equals to",dim(ano_v20_nokey)[1],"\n")
```

## Load RMA.RData From Both Folders

```{r,warning=FALSE,message=FALSE}
#this is the full HTA2.0 RMA preprocessed set obtained from .CEL files as described in preprocess_data_SC1.R  
load("/Users/oliverabinader/Downloads/HTA20_RMA.RData")
cat("The dimension of this dataset is",dim(eset_HTA20),", so I have",dim(eset_HTA20)[1],"gene ids and",dim(eset_HTA20)[2],"samples.\n")

#see preprocess.r to see how this dataset was obtained from .CEL files in HuGene21ST folder
load("/Users/oliverabinader/Downloads/HuGene21ST_RMA.RData")
cat("The dimension of this dataset is",dim(eset_HuGene21ST),", so I have",dim(eset_HuGene21ST)[1],"gene ids and",dim(eset_HuGene21ST)[2],"samples.\n")
```

## Find Common Gene Ids Between Both Microarrays

```{r,warning=FALSE,message=FALSE}
#find common ENTREZ IDs (ROWS) between the two microarray platforms
cgenes <- c(rownames(eset_HuGene21ST),rownames(eset_HTA20))
#take all rows from both dataframes and combine them together in a vector called cgenes, length=62465
cgenes <- names(table(cgenes)[table(cgenes)==2]) 
head(cgenes)
#table(cgenes) -> both 1 and 2 / length=33006
#table(cgenes)[table(cgenes)==2] -> only 2 / length=29459
#table(cgenes)[table(cgenes)==1] -> only 1 / length=3547
#names(...) -> get the names of each element in the vector / in this case get the names of the 29459 elements in vector cgenes.
```

## Concatenate Sample Data For The Common Genes

```{r,warning=FALSE,message=FALSE}
#concatenate sample data for common genes
eset <- cbind(eset_HuGene21ST[cgenes,],eset_HTA20[cgenes,])

#NOTE:
#eset_HuGene21ST[cgenes,] -> take 1st 3 rows with ALL COLS / length(eset_HuGene21ST[cgenes,]) = 326 
#eset_HTA20[cgenes,] -> take 1st row with PART OF COLS / length(eset_HTA20[cgenes,]) = 21652365
#length(eset) = 1061
```

## Quantile/Normalize Over The Two Sets

```{r,warning=FALSE,message=FALSE}
#quantile normalize 
eset <- data.matrix(eset) #Convert a Data Frame to a Numeric Matrix
eset <- normalize.quantiles(eset) #Using a normalization based upon quantiles, this function normalizes a matrix of probe level intensities.

colnames(eset) <- c(colnames(eset_HuGene21ST),colnames(eset_HTA20))
rownames(eset) <- cgenes
```

## Extract Gestational Age Value For All Samples Used In This Analysis

```{r,warning=FALSE,message=FALSE}
#extract Gestational Age = G.A. value 
ga <- allSamples$GA[match(colnames(eset),allSamples$SampleID)] 
```

## Remove Platform Effect As Well As G.A. Effect

```{r,warning=FALSE,message=FALSE}
#remove P.E. and G.A. effects
eset <- removeBatchEffect(eset,batch=ifelse(substr(colnames(eset),1,3)=="GSM",0,1),covariates=cbind(ga,ga^2))
esetSC23 <- as.data.frame(eset)
```

## Save Data Involved In This Challenge

```{r,warning=FALSE,message=FALSE}
#keep data from samples involved in this challenge 
eset <- eset[,ano_v20_nokey$SampleID]
save(ano_v20_nokey, eset, file="/Users/oliverabinader/Desktop/new_eset_v20.RData")
```

# The Eset Dataset

```{r, message=FALSE,echo=FALSE,warning=FALSE}
#RData file: eset_v20.RData, it contains two objects.
path <- "/Users/oliverabinader/Desktop/new_eset_v20.RData"
load(path)
```

## Object Number 1

<div style="text-align: justify">The eset object contains gene level combined training and test set gene expression matrix obtained using prepare_data.R</div><br />

```{r, message=FALSE,warning=FALSE}
backup <- eset
dat <- t(backup) #transpose dataset
dat <- as.data.frame(dat)
cat("The number of rows followed by the number of columns is",dim(dat),", so I have",dim(dat)[1],"samples and",dim(dat)[2],"gene ids.\n")
cat("The first six columns of the dataset are\n")
head(colnames(dat))
cat("The last six columns of the dataset are\n")
tail(colnames(dat))

bckuP <- dat
```

### Some Initial Statistics

<div style="text-align: justify">I will first calculate the mean and the standard deviation of each predictor. Then, I will retrieve the highest and the lowest mean values as well as the standard deviation values between the 29459 predictors. Afterwards, I will present the results in a table.

```{r, message=FALSE, warning=FALSE}
#Columns statistics: "lapply" applies the desired function BY COLUMN and returns each column as a separate element in a list.
a2 <- lapply(dat,sd); var2 <- as.character(a2)
a3 <- lapply(dat,mean); var3 <- as.character(a3)

M <- matrix(nrow = 2,ncol = 29459) #matrix 1
colnames(M) <- colnames(dat)
rownames(M) <- c("Standard Deviation","Mean")
M[1,] <- var2;M[2,] <- var3
variable1 <- as.table(M)
```

This table summarizes the highest & lowest Standard Deviation and Mean values as well as the name of the column.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
names <- colnames(dat)
N <- matrix(nrow = 2,ncol = 4) #matrix 2
colnames(N) <- c("Highest Value","Gene Id","Lowest Value","Gene Id")
rownames(N) <- c("Standard Deviation","Mean")
N[1,1] <- M[1,which.max(M[1,])]; N[1,2] <- names[which.max(M[1,])]; N[1,3] <- M[1,which.min(M[1,])]; N[1,4] <- names[which.min(M[1,])]
N[2,1] <- M[2,which.max(M[2,])]; N[2,2] <- names[which.max(M[2,])]; N[2,3] <- M[2,which.min(M[2,])]; N[2,4] <- names[which.min(M[2,])]
variable2 <- as.table(N); knitr::kable(variable2)
```

### Standard Deviation Calculation

<div style="text-align: justify">I re-organize object number 1 in a descending order based on the standard deviation values. So I will see two tables: I retrieve the first thirty gene ids from object number 1 then I sort this dataset and this is shown in the second table whereby all the variables are now present in another order.</div><br />

```{r, message=FALSE, warning=FALSE}
cat("The first 30 gene ids from object number 1 are represented in the following table.\n")
varb2 <- as.matrix(colnames(dat[1:30]))
colnames(varb2) <- "Gene Ids"
rible2 <- as.table(varb2); knitr::kable(rible2)

dat[740,] <- M[1,] #add standard deviation row to the dat dataset.
rownames(dat)[rownames(dat) == "740"] <- "Standard Deviation" #changing name of last row in dat dataset.
variab <- as.data.frame(t(dat)) #The dat dataset is now transposed.
variabl <- variab[order(variab[,740], decreasing = TRUE),]  #sort the variab dataset based on the standard deviation values.
sorted <- as.data.frame(t(variabl)) #final dataset whereby the columns in matrix M have been sorted from decreasing to increasing order.
sorted <- sorted[-740, ] #remove the last row from sorted dataset 
```

```{r, message=FALSE, echo=FALSE,warning=FALSE}
cat("The number of rows followed by the number of columns is",dim(sorted),", so I have",dim(sorted)[1],"rows and",dim(sorted)[2],"gene ids.\nThe first 30 sorted gene ids are represented in the following table.\n")
```

```{r, message=FALSE, warning=FALSE}
varble2 <- as.matrix(colnames(sorted[1:30]))
colnames(varble2) <- "Gene Ids"
varible2 <- as.table(varble2); knitr::kable(varible2)
```

### Standard Deviation Visualization 

<div style="text-align: justify">Statistically speaking, the standard deviation (sd) is a measure of the amount of variation or dispersion of a set of values. The following plot shows the sd of all the predictors. Thus, a low standard deviation indicates that the values tend to be close to the mean of the set, whereas a high standard deviation means that the values are spread out over a wider range. The R package plotly was used to create interactive web-based graphs via the open source JavaScript graphing library plotly.js.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
standard_dev <- as.data.frame(sapply(bckuP, sd)) #standard deviation for each column
standard_dev$col <- rownames(standard_dev) #names of rows from standard_dev dataset
colnames(standard_dev) <- c("sd","col")
col_indeces <- c()
for (index in bckuP) {
  col_indeces <- c(col_indeces, which(colnames(bckuP)==index)) }
#checking which gene has highest/lowest sd value
J <- colnames(bckuP); J <- as.character(J); cat("The gene having the highest sd is",J[max(standard_dev$sd)],"with a value of",max(standard_dev$sd),"\nThe gene having the lowest sd has a value of",min(standard_dev$sd),"\nSince most of the points fluctuates between 0 and 0.50, I can say that the mean of the standard deviation equals to",mean(standard_dev$sd),"\n")

p <- plot_ly(data = standard_dev, x = ~col, y = ~sd ,type = "scatter", color = standard_dev$sd)
add_lines(p,y=0.50)
```

### Checking Columns Uniquess 

<div style="text-align: justify">I am going to check which column(s) has(have) the same value for all the observations.</div><br />

```{r, message=FALSE, warning=FALSE}
VEC <- apply(dat, 2, function(a) length(unique(a)) != 1)
VEC <- as.character(VEC);count<-0 #count is the number of columns which contains non unique values
for(i in 1:length(VEC)){
  if(VEC[i]==TRUE)
    count<-count+1
}
```

```{r, message=FALSE,echo=FALSE,warning=FALSE}
if(count==dim(dat)[2]){
  cat("The dataset does not contain any column(s) with unique value(s).\n")
} else {
  cat("The dataset contains any column(s) with unique value(s).\n")
}
```

## The Dataset To Be Used

```{r, message=FALSE,echo=FALSE,warning=FALSE}
bcup <- bckuP[colnames(sorted)]
cat("The dataset to be used from object number 1 is called bcup.\nThe number of rows followed by the number of columns is",dim(bcup),", so I have",dim(bcup)[1],"samples and",dim(bcup)[2],"gene ids.\n")

cat("The first six columns of the dataset are\n")
head(colnames(bcup))
cat("The last six columns of the dataset are\n")
tail(colnames(bcup))
```

## First Reduced Object Number 1

<div style="text-align: justify">I will start the analysis by using a reduced dataset of object number 1.</div><br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
reduced_dat_200 <- bcup[,1:200] #the dataset reduced_dat_200 that will be used from object 1
cat("The number of rows followed by the number of columns is",dim(reduced_dat_200),", so I have",dim(reduced_dat_200)[1],"samples and",dim(reduced_dat_200)[2],"gene ids.\n")
```

## Second Reduced Object Number 1

<div style="text-align: justify">Then, I will move on and use another subdataset of object number 1 containing the first 300 columns of object number 1.</div><br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
reduced_dat_300 <- bcup[,1:300] #the dataset reduced_dat_300 that will be used from object 1
cat("The number of rows followed by the number of columns is",dim(reduced_dat_300),", so I have",dim(reduced_dat_300)[1],"samples and",dim(reduced_dat_300)[2],"gene ids.\n")
```

## Third Reduced Object Number 1

<div style="text-align: justify">After that, I will be using a third reduced form of object number 1.</div><br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
reduced_dat_500 <- bcup[,1:500] #the dataset reduced_dat_500 that will be used from object 1
cat("The number of rows followed by the number of columns is",dim(reduced_dat_500),", so I have",dim(reduced_dat_500)[1],"samples and",dim(reduced_dat_500)[2],"gene ids.\n")
```

## Object Number 2

<div style="text-align: justify">Now, Let's move on to the second object whereby I am going to use some of the attributes in my analysis. The ano object contains the same sample information for the 739 samples as the file ano_v20_nokey.csv. Let's have a small look on this object.<br />
<u>The following columns includes: </u><br />
SampleID: unique identifier of the sample.<br />
IndividualID: unique patient identifier.<br />
GA: gestational age as determined by the last menstrual period and or ultrasound.<br />
GADel: gestational age at delivery.<br />
Group: outcome of pregnancy.<br />
Set: name of the source dataset.<br />
Train: 1 for samples to be used for training, 0 for samples to be used for predicting.<br />
Platform: gene expression platform used to generate the cell files.<br />
TTD: interval in weeks from sample to delivery (GADel-GA).<br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
backup1 <- ano_v20_nokey
backup1 <- as.data.frame(backup1) #this is the dataset for object number 2
cat("The number of rows followed by the number of columns is",dim(backup1),", so I have",dim(backup1)[1],"microarrays and",dim(backup1)[2],"attributes.\n")
cat("Print the column names of this dataset.\n")
head(backup1)
```

```{r, message=FALSE,warning=FALSE}
cat("The column names are\n");names(backup1)
cat("The classes are\n");lapply(backup1,class) 
cat("The summary of each variable:\n");summary(backup1)
#Conversion of some predictors' classes.
backup1$SampleID<-as.factor(backup1$SampleID)
backup1$IndividualID<-as.factor(backup1$IndividualID)
backup1$Group<-as.factor(backup1$Group)
backup1$Set<-as.factor(backup1$Set)
backup1$Platform<-as.factor(backup1$Platform)
backup1$Train<-as.numeric(backup1$Train)
cat("The adjusted classes are\n");lapply(backup1,class) 
cat("The new summary of each variable:\n");summary(backup1)
cat("The number of Individuals/pregnant women is",length(unique(backup1$IndividualID)),"\n")
cat("Let's plot the GA predictor.\n");plot(backup1$GA)
```

<u>On the x-axis:</u><br />
I can see two phases in this plot. In the first phase, between 0 and approximately 300, the points are presented in structural form meaning that the values follow certain pattern or intervals, they are lined-up meaning that they form lines. In the second part of the graph, above 300, the points are continuous, such distribution is one in which data can take on any value within a specified range.
<br /><u>On the y-axis:</u><br />
The points vary from 15 to approximately 33 weeks. There are two intervals/phases according to when the pregant women had her last menstrual cycle: T1(17 to 23 weeks) and T2(27 to 33 weeks) as seen in the microarray analysis. A gap can be seen between these two phases.<br />

<u>**PART II A - PREDICTING PRETERM BIRTH using the first 200 columns**</u></div><br/>

# First Dataset

<div style="text-align: justify">*First, I am going to use the dataset containing the first 200 columns from object number 1 with some additional columns(GA,Group,IndividualID and Train) from the second object.*</div>

## The Combined Dataset

```{r, message=FALSE, warning=FALSE}
data <- reduced_dat_200

#the additional columns
data$Class <- backup1$Group
data$GA <- backup1$GA
data$Individual <- backup1$IndividualID
data$Train <- backup1$Train

#indices of obvs (one sample per patient) to be used
odd <- seq(1,by=2, len=166)
dd <- odd[1:166]
dd <- c(dd,333,337,339,343,347,350,353,357,361,364,368,372,376,380,383,387,390,393,396,398,401,403,406,409,412,417,421,425,428,431)
DF2 <- data[dd,]
```

<div style="text-align: justify">I'll divide the original dataset into two datasets. The train_dataset is used to build models whereas the prediction_dataset is use to predict preterm birth.</div><br />

## Multiclass Analysis

```{r,warning=FALSE,echo=FALSE,message=FALSE}
train_dataset <- DF2[DF2$Train==1,-c(which(colnames(DF2)=="Train"),which(colnames(DF2)=="Individual"))] #This dataset contains mainly the observations present in the dataset classified as either sPTD, PPROM or control.
prediction_dataset <- DF2[DF2$Train==0,-c(which(colnames(DF2)=="Train"),which(colnames(DF2)=="Individual"))] #This dataset contains mainly the observations present in the dataset not classified in either class.
```

### Some Initial Statistics

```{r, message=FALSE, warning=FALSE}
#assign ur data frame to a new variable.
train_backup <- train_dataset 
cat("The dimension of this dataframe is",dim(train_backup),"\n")

#the type of each column
classes <- lapply(train_backup,class) 
cat("\nPrint the first six columns of the dataframe.\n")
head(classes)
cat("Print the last six predictors of the dataframe.\n")
tail(classes)

#With this dataset, the summary() function will not useful since I have a large number of predictors.
```

<div style="text-align: justify">This table summarizes the number of numerical/categorical/logical predictors.</div><br />

```{r, message=FALSE, echo=FALSE,warning=FALSE}
n=0;c=0; a <- sapply(train_backup, is.numeric); for (i in 1:dim(train_backup)[2]){if(a[i]==TRUE){n=n+1}else{c=c+1}}
lg <- length(Filter(is.logical, train_backup))

O <- matrix(nrow = 4,ncol = 1) #matrix 1
colnames(O) <- "Count"
rownames(O) <- c("Numeric Variable(s)","Factor Predictor(s)","Logical Column(s)","Total")
O[1,] <- n; O[2,] <- c; O[3,] <- lg; O[4,] <- c+n+lg
riable1 <- as.table(O); knitr::kable(riable1)
```

### Identification Of Missing Values

<div style="text-align: justify">Some columns may present missing values. What I need to do is to identify them first and if present, I need to remove them and replace them with real values.<br />

```{r, message=FALSE, warning=FALSE}
question_marks <- which(train_backup=="?",arr.ind = T)  

NA_values <- which(is.na(train_backup), arr.ind=T)

NaN_values <- which(apply(train_backup, 2, function(x) all(is.nan(x))))

infinite_values <- which(apply(train_backup, 2, function(x) all(is.infinite(x))))

blanck_values <- function (x) {sum(x=="") }
bvalues <- apply(train_backup, 2,blanck_values); bvalues<-as.character(bvalues);count<-0
for(index in 1:length(bvalues)){
  if(bvalues[index]!=0){
    count=count+1 } }
```

This table summarizes the different types of missing values and their count.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x <- matrix(nrow = 5,ncol = 1,byrow = F)
colnames(x) <- c("Count")
rownames(x) <- c("Question marks","NA values","NaN values","Infinite values","Blank values")
tot <- dim(question_marks)[1]+dim(NA_values)[1]+length(NaN_values)+length(infinite_values)+count
x[1,1] <- dim(question_marks)[1]
x[2,1] <- dim(NA_values)[1]
x[3,1] <- length(NaN_values)
x[4,1] <- length(infinite_values)
x[5,1] <- tot
var <- as.table(x); knitr::kable(var)
```

### Checking Data Normalization

<div style="text-align: justify">I will do the shapiro test to check for normality, which can only be done on the numerical predictors.There are several methods for normality test such as Kolmogorov-Smirnov (K-S) normality test and Shapiro-Wilks test.</div><br />

```{r, message=FALSE, warning=FALSE}
numerical_predictor<-c() #a vector that will contain all the numerical predictors indicies
count2<-1 
for(i in 1:ncol(train_backup))  { # for loop to get all the numerical predictors indicies
  if(is.numeric(train_backup[,i])==TRUE) {
    numerical_predictor[count2]<-i
    count2<-count2+1 }
}

#if u apply the shapiro test on the numercical predictors, u'll then get their p_values and save them in a variable called p_val
p_val<-c()
test<-vector("list",1)
for(i in 1: length(numerical_predictor)) {
  test[[i]]<-shapiro.test(train_backup[,numerical_predictor[i]])
  p_val[i]<-test[[i]]$p.value
}
#p-value is a vector of all the p-values for all genes

normal<-which(p_val<0.05) #Since pval is less than 5%, hence accepting the null hypothesis means the data is normally distributed. However, rejecting the null hypothesis means the data will not normally distributed.

n<-(dim(train_backup)[2])-length(normal)
d<-length(normal)

cat("The number of columns that are not normally distributed is:",n,"\n")
cat("The number of columns that are normally distributed is:",d,"\n")
```

### About The Class Predictor

```{r, message=FALSE, warning=FALSE}
#table of class
cat("The distribution of the 3 groups in the Class attribute")
table(train_backup$Class)

cat("The 3 groups are:",levels(train_backup$Class),"\nWhereby:\n 0 means Control\n 1 means PPROM (preterm premature rupture of membranes)\n 2 means sPTD (spontaneous preterm labor and delivery with intact membranes)\nLet's calculate the frequency of each subclass.")

control <- length(which(train_backup$Class=="Control"))
PPROM <- length(which(train_backup$Class=="PPROM"))
sPTD <- length(which(train_backup$Class=="sPTD"))

per_control <- control/length(train_backup$Class)*100
per_PPROM <- PPROM/length(train_backup$Class)*100
per_sPTD <- sPTD/length(train_backup$Class)*100

cat("The percentage of the control group is",format(round(per_control, 2), nsmall = 2),"\n")
cat("The percentage of the PPROM group is",format(round(per_PPROM, 2), nsmall = 2),"\n")
cat("The percentage of the sPTD group is",format(round(per_sPTD, 2), nsmall = 2),"\n")
```

### Some Representative Plots
<div style="text-align: justify">The pairs plot cannot be done at all because the presence of at most 29k predictors will be invisible in such kind of plot.</div>

#### Frequency Plot
<div style="text-align: justify">ggplot2 is a data visualization package for the statistical programming language R.</div> 

```{r, message=FALSE,echo=FALSE,warning=FALSE}
ggplot(data=train_backup, aes(x=Class,  fill=Class))  + geom_bar() +  scale_x_discrete(name = 'Class',labels=labs) + theme_bw() + ggtitle("The occurence of each level in the categorical variable")
```

#### Correlogram
<div style="text-align: justify">Let's examine the correlation between some continuous variables present in the same dataframe. This is conveniently implemented using the ggcorrplot package. Correlation coefficients are used to measure the strength of the relationship between two variables. When the value of correlation coefficient is close to zero, generally between -0.1 and +0.1, the variables are said to have no linear relationship or a very weak linear relationship.</div> 

```{r, message=FALSE,echo=FALSE,warning=FALSE}
ggcorrplot(round(cor(train_backup[c(1:16)]), 1), hc.order = TRUE,type = "full",lab = TRUE,lab_size = 3,method="circle",colors= c("tomato2", "white", "springgreen3"), title="Correlogram between the first 16 gene ids",ggtheme=theme_bw)
```

### Correlation Analysis

```{r, warning=FALSE,message=FALSE}
var <- cor(train_backup[1:200]) #correlation
var[lower.tri(var)] <- NA #replaces values in lower triangular matrix to NA
var[is.na(var)] <- 0 #then replace the NA to 0
diag(var)<-0 #replace values in the diagonal equals to 1 to 0
df <- as.data.frame(var) #change the class of df to a dataframe
df[df>=1] <- 0 #replace all values bigger than 1 to by 0
fct <- apply(df,2,max) #get the max value from each column
m <- as.matrix(fct) #save the fct as a matrix in a new variable called m
```

<div style="text-align: justify">Let's zoom in and visualize the highly correlated and the non highly correlated genes.</div><br />

```{r, warning=FALSE,message=FALSE}
#get the highly correlated genes->having a correlation coefficient above 70%
highly_correlated_genes <- m[m[,1] > 0.70,]
highly_correlated_genes <- as.matrix(highly_correlated_genes)
cat("The number of highly correlated genes equals to",length(highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(highly_correlated_genes))

#get the non highly correlated genes->having a correlation coefficient below 70%
not_highly_correlated_genes <- m[m[,1] <= 0.70,]
not_highly_correlated_genes <- as.matrix(not_highly_correlated_genes)
cat("The number of non highly correlated genes equals to",length(not_highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(not_highly_correlated_genes))
```

### Correlation Visualization

<div style="text-align: justify">A heat map uses a matrix layout with colour and shading to show the relationship between two categories of values. The values are presented along each axis and the corresponding cell is then colour-coded to represent the relationship between the two categories.<br />
The name of the package: gplots<br />
Argument 2 = dendrogram: character string indicating whether to draw 'none', 'row', 'column' or 'both' dendrograms. <br />
Argument 3 = trace: character string indicating whether a solid "trace" line should be drawn across 'row's or down 'column's, 'both' or 'none'.<br />
Argument 4 = col: colors used for the image.</div><br />

```{r, warning=FALSE,message=FALSE}
correlationMatrix <- cor(train_backup[,1:200])
heatmap.2(correlationMatrix,dendrogram = c("none"), trace = "none", col = as.vector(wes_palette(name = "FantasticFox1", n=15, type="continuous")))
```

### Building Models

<div style="text-align: justify">The categorical predictor has three levels: Control is the first level, PPROM is the second one and sPTD is the third class.

```{r, message=FALSE, warning=FALSE}
DATASET2 <- train_backup
levels(DATASET2$Class)
levels(DATASET2$Class) <- c(0,1,2); levels(DATASET2$Class)
attach(DATASET2)
number<-dim(DATASET2)[2]-2 #number of genes only (predictors)
```

<u>Analysis method that I might consider for predicting preterm birth:</u><br />
First, I will build linear discriminant analysis models.<br />
Second, I will build several support vector machine models using different kernel.</div><br />

#### Fitting LDA Models

<div style="text-align: justify"><u>Using Cross-validation:</u>

```{r, message=FALSE, warning=FALSE}
CV1 <- function(data, fold, output)
{
  set.seed(1)

  n <- nrow(data)
  index <- sample(n,n)
  l <- vector("list")
  accuracy <- rep(1,fold)
  lda.fit <- c()
  
  group <- cut(index, breaks = fold, labels =FALSE)
  table(group)

  for(j in 1:fold)
  {
    test <- which(group==j)
    train <- index[-test]
    
    lda.fit <- lda(Class ~ data[,gene]+data[,which(colnames(data)=="GA")], data = data, subset = train, family = multinomial)
    lda.pred <- predict(lda.fit,data[test,]) 
    lda.class <- lda.pred$class 
    
    #ACCURACY = TEST CORRECT RATE
    accuracy[j] <- mean(lda.class==Class[test])
  }
 l <- list(lda.fit,accuracy); return(l)
}

l1 <- vector("list")

for(gene in 1:number) 
  l1[[length(l1)+1]] <- CV1(DATASET2,100,Class) 
names(l1) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l1, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means1 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means1)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means1)
```

<u>Using Bootsrapping:</u>

```{r, warning=FALSE,message=FALSE}
BT1 <- function(data,Y,R,percent) { 
  set.seed(2)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  l <- vector("list",1) #creation of empty list
  lda.fit<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an lda model on train data
    lda.fit <- lda(Class ~ data[,gene]+data[,which(colnames(data)=="GA")],data = data, subset = new_train_indices, family=multinomial)

    #5) How well does this model perform on the test data? 
    lda.pred=predict(lda.fit,data[test_indices,]) 

    #6)In order to make a prediction, convert these predicted probabilities into class labels: 0 or 1 - CLASS PREDICTION
    lda.class=lda.pred$class 

    #7) calculate a new ESTIMATED TEST ERROR RATE using mean() - ACCURACY = TEST CORRECT RATE
    accuracy[i]<-mean(lda.class==Class[test_indices])
  }
  l <- list(lda.fit,accuracy); return(l)
}

l2<-vector("list")

for(gene in 1:number)
  l2[[length(l2)+1]] <- BT1(DATASET2,Class,100,30) 
names(l2) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l2, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means2 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means2)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:</div>
```{r, warning=FALSE,message=FALSE}
which.max(col_means2)
```

#### Fitting SVM Model Using Radial Kernel

<div style="text-align: justify">The support vector machine (SVM) is an extension of the support vector classifier that results from enlarging the feature space using kernels to accommodate a non-linear boundary between classes. Fitting svm model whereby the predictors are the following: ONLY one highly correlated gene, all the non highly correlated genes and the gestational age predictor.</div><br/>

```{r, warning=FALSE,message=FALSE}
BT3 <- function(data,Y,R,percent) { 
  set.seed(4)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l <- vector("list",1) #creation of empty list

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out2 <- tune.svm(Class ~ . - `105377884_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`-`3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`-`820_at`- `150000_at`- `1991_at`- `154664_at`-`3045_at`- `28448_at`, data=data[new_train_indices,], type="C-classification", kernel="radial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out2$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out2,accuracy)
  return(l)
}

ans2 <- BT3(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans2[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans2[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans2[[2]])*100, 2), nsmall = 2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 3)

```{r, warning=FALSE,message=FALSE}
BT5 <- function(data,Y,R,percent) { 
  set.seed(6)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l <- vector("list",1) #creation of empty list

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit svm model on train data
    tune.out3 <- tune.svm(Class ~ . - `105377884_at`- `4317_at`- `10964_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`-`3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`-`820_at`- `150000_at`- `1991_at`- `154664_at`-`3045_at`- `28448_at`, data=data[new_train_indices,], type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 3)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy);return(l)
}

ans4 <- BT5(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans4[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans4[[1]]$best.parameters$gamma)
cat("The highest accuracy is equal to",format(round(mean(ans4[[2]])*100, 2), nsmall = 2),"\n")
```

#### Fitting SVM Model Using Sigmoid Kernel

```{r, warning=FALSE,message=FALSE}
BT6 <- function(data,Y,R,percent) { 
  set.seed(7)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l <- vector("list",1) #creation of empty list

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit svm model on train data
    tune.out4 <- tune.svm(Class ~ . - `105377884_at`- `4317_at`- `10964_at`- `3123_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`-`3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`-`820_at`- `150000_at`- `1991_at`- `154664_at`-`3045_at`- `28448_at`,  data=data[new_train_indices,], type="C-classification",kernel="sigmoid",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out4$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out4,accuracy); return(l)
}

ans5 <- BT6(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans5[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans5[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans5[[2]])*100, 2), nsmall = 2),"\n")
```

### Choosing The Best Model

<div style="text-align: justify">I will compare the accuracies between the models having highest accuracies.<br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x <- matrix(nrow = 5,ncol = 3,byrow = F)
colnames(x) <- c("Highest Accuracy","Cost","Gamma")
rownames(x) <- c("LDA using CV", "LDA using BT", "SVM with radial kernel", "SVM with polynomial kernel (degree 3)", "SVM with sigmoid kernel")
x[1,1] <- max(col_means1)*100;x[1,2]<-"-";x[1,3]<-"-"
x[2,1] <- max(col_means2)*100;x[2,2]<-"-";x[2,3]<-"-"
x[3,1] <- mean(ans2[[2]])*100;x[3,2]<-ans2[[1]]$best.parameters$cost;x[3,3]<-ans2[[1]]$best.parameters$gamma
x[4,1] <- mean(ans4[[2]])*100;x[4,2]<-ans4[[1]]$best.parameters$cost;x[4,3]<-ans4[[1]]$best.parameters$gamma
x[5,1] <- mean(ans5[[2]])*100;x[5,2]<-ans5[[1]]$best.parameters$cost;x[5,3]<-ans5[[1]]$best.parameters$gamma
var <- as.table(x); knitr::kable(var)

names<-rownames(x)
m1 <- names[which(x==max(x))]
a1 <- max(x[,1]) 
cat("The model(s) having the highest accuracy is(are)",m1,"\n")
cat("The highest accuracy is equal to",a1,"\n")
```

Now, I'll predict preterm birth on the test/predicting dataset using the newdata argument.</div><br />

```{r, warning=FALSE,message=FALSE}
svm_probability <- predict(ans2[[1]]$best.model, newdata = prediction_dataset) 
```

## Binary Analysis (sPTD v/s Control)

```{r,warning=FALSE,echo=FALSE,message=FALSE}
train_dataset <- DF2[DF2$Train==1,-c(which(colnames(DF2)=="Train"),which(colnames(DF2)=="Individual"))] #This dataset contains mainly the observations present in the dataset classified as either sPTD, PPROM or control.
prediction_dataset <- DF2[DF2$Train==0,-c(which(colnames(DF2)=="Train"),which(colnames(DF2)=="Individual"))] #This dataset contains mainly the observations present in the dataset not classified in either class.
```

### Some Initial Statistics

```{r, message=FALSE, warning=FALSE}
#assign ur data frame to a new variable.
train_backup <- train_dataset 
cat("The dimension of this dataframe is",dim(train_backup),"\n")

#the type of each column
classes <- lapply(train_backup,class) 
cat("\nPrint the first six columns of the dataframe.\n")
head(classes)
cat("Print the last six predictors of the dataframe.\n")
tail(classes)

#With this dataset, the summary() function will not useful since I have a large number of predictors.
```

<div style="text-align: justify">This table summarizes the number of numerical/categorical/logical predictors.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
n=0;c=0; a <- sapply(train_backup, is.numeric); for (i in 1:dim(train_backup)[2]){if(a[i]==TRUE){n=n+1}else{c=c+1}}
#ct <- length(Filter(is.factor, train_backup))
lg <- length(Filter(is.logical, train_backup))

O <- matrix(nrow = 4,ncol = 1) #matrix 1
colnames(O) <- "Count"
rownames(O) <- c("Numeric Variable(s)","Factor Predictor(s)","Logical Column(s)","Total")
O[1,] <- n; O[2,] <- c; O[3,] <- lg; O[4,] <- c+n+lg
riable1 <- as.table(O); knitr::kable(riable1)
```

### Identification Of Missing Values

<div style="text-align: justify">Some columns may present missing values. What I need to do is to identify them first and if present, I need to remove them and replace them with real values.<br />

```{r, message=FALSE, warning=FALSE}
question_marks <- which(train_backup=="?",arr.ind = T)  

NA_values <- which(is.na(train_backup), arr.ind=T)

NaN_values <- which(apply(train_backup, 2, function(x) all(is.nan(x))))

infinite_values <- which(apply(train_backup, 2, function(x) all(is.infinite(x))))

blanck_values <- function (x) {sum(x=="") }
bvalues <- apply(train_backup, 2,blanck_values); bvalues<-as.character(bvalues);count<-0
for(index in 1:length(bvalues)){
  if(bvalues[index]!=0){
    count=count+1 } }
```

This table summarizes the different types of missing values.</div><br />

```{r, message=FALSE, echo=FALSE,warning=FALSE}
x <- matrix(nrow = 5,ncol = 1,byrow = F)
colnames(x) <- c("Count")
rownames(x) <- c("Question marks","NA values","NaN values","Infinite values","Blank values")
tot <- dim(question_marks)[1]+dim(NA_values)[1]+length(NaN_values)+length(infinite_values)+count
x[1,1] <- dim(question_marks)[1]
x[2,1] <- dim(NA_values)[1]
x[3,1] <- length(NaN_values)
x[4,1] <- length(infinite_values)
x[5,1] <- tot
var <- as.table(x); knitr::kable(var)
```

### About The Class Predictor

```{r, message=FALSE,echo=FALSE,warning=FALSE}
#table of class
cat("The distribution of the 3 groups in the Class attribute")
table(train_backup$Class)

train_backup <- train_backup[-which(train_backup$Class == "PPROM"),]
table(train_backup$Class)
```

<div style="text-align: justify">Removing the PPROM class.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
train_backup$Class <- droplevels(train_backup$Class)
table(train_backup$Class) #nber of occurence in class

cat("The two groups are:",levels(train_backup$Class),"\nWhereby:\n 0 means Control\n 1 means sPTD (spontaneous preterm labor and delivery with intact membranes)\nLet's calculate the frequency of each subclass.")

control <- length(which(train_backup$Class=="Control"))
sPTD <- length(which(train_backup$Class=="sPTD"))

per_control <- control/length(train_backup$Class)*100
per_sPTD <- sPTD/length(train_backup$Class)*100

cat("The percentage of the control group is",format(round(per_control, 2), nsmall = 2),"\n")
cat("The percentage of the sPTD group is",format(round(per_sPTD, 2), nsmall = 2),"\n")
```

### Some Representative Plots
<div style="text-align: justify">The pairs plot cannot be done at all because the presence of at most 29k predictors will be invisible in such kind of plot.</div>

#### Frequency Plot
<div style="text-align: justify">ggplot2 is a data visualization package for the statistical programming language R.</div> <br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
ggplot(data=train_backup, aes(x=Class,  fill=Class))  + geom_bar() +  scale_x_discrete(name = 'Class',labels=labs) + theme_bw() + ggtitle("The occurence of each level in the categorical variable")
```

#### Correlogram
<div style="text-align: justify">Let's examine the correlation between some continuous variables present in the same dataframe. This is conveniently implemented using the ggcorrplot package. Correlation coefficients are used to measure the strength of the relationship between two variables. When the value of correlation coefficient is close to zero, generally between -0.1 and +0.1, the variables are said to have no linear relationship or a very weak linear relationship.</div> 

```{r, message=FALSE,echo=FALSE,warning=FALSE}
ggcorrplot(round(cor(train_backup[c(1:16)]), 1), hc.order = TRUE,type = "full",lab = TRUE,lab_size = 3,method="circle",colors= c("tomato2", "white", "springgreen3"), title="Correlogram between the first 16 gene ids",ggtheme=theme_bw)
```

### Correlation Analysis

```{r, warning=FALSE,message=FALSE}
var <- cor(train_backup[1:200]) #correlation
var[lower.tri(var)] <- NA #replaces values in lower triangular matrix to NA
var[is.na(var)] <- 0 #then replace the NA to 0
diag(var)<-0 #replace values in the diagonal equals to 1 to 0
df <- as.data.frame(var) #change the class of df to a dataframe
df[df>=1] <- 0 #replace all values bigger than 1 to by 0
fct <- apply(df,2,max) #get the max value from each column
m <- as.matrix(fct) #save the fct as a matrix in a new variable called m
```

<div style="text-align: justify">Let's zoom in and visualize the highly correlated and the non highly correlated genes.</div><br />

```{r, warning=FALSE,message=FALSE}
#get the highly correlated genes->having a correlation coefficient above 70%
highly_correlated_genes <- m[m[,1] > 0.70,]
highly_correlated_genes <- as.matrix(highly_correlated_genes)
cat("The number of highly correlated genes equals to",length(highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(highly_correlated_genes))

#get the non highly correlated genes->having a correlation coefficient below 70%
not_highly_correlated_genes <- m[m[,1] <= 0.70,]
not_highly_correlated_genes <- as.matrix(not_highly_correlated_genes)
cat("The number of non highly correlated genes equals to",length(not_highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(not_highly_correlated_genes))
```

### Building Models

<div style="text-align: justify">The categorical predictor has two levels: Control is the first level and sPTD is the second one.

```{r, message=FALSE, warning=FALSE}
DATASET2 <- train_backup
levels(DATASET2$Class)
levels(DATASET2$Class) <- c(0,1); levels(DATASET2$Class)
attach(DATASET2)
number<-dim(DATASET2)[2]-2 
```

<u>Analysis methods that I might consider for predicting preterm birth:</u><br />
Firstly, I will build generalized linear models.<br />
Secondly, I will move on to linear discriminant analysis.<br />
Thirdly, I will build several support vector machine models using different kernels.</div><br />

#### Fitting GLM Models

<div style="text-align: justify"><u>Using Cross-validation:</u> 

```{r, message=FALSE, warning=FALSE}
CV2 <- function(data,fold,Y)
{
  n=nrow(data)
  
  set.seed(8)
  index=sample(n,n)
  l<-vector("list")
  model<-c()

  group=cut(index, breaks = fold, labels =FALSE)
  pval=c();accuracy=c()
  for( j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model=glm(Class~data[,gene]+data[,which(colnames(data)=="GA")],data=data, subset=train, family=binomial)
    pval[j]= summary(model)$coef[2,4] #get the pvalue 
    glm.pred=predict(model,data[test,],type="response")
    
    glm.prob=rep(0,nrow(data))
    glm.prob[glm.pred >.5]=1
    accuracy[j]=mean(glm.prob==Class[test]) 
  }
  
 l=list(model,pval,accuracy);return(l)
}

l3<-vector("list")

for(gene in 1:number)
  l3[[length(l3)+1]] <- CV2(DATASET2,100,Class)
names(l3) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l3, "[[", 3)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means3 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means3)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means3)
```

<u>P_value Interpretability</u><br />
In statistics, the p-value is the probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. A p-value less than or equal to 0.05 is statistically significant. It indicates a strong evidence against the null hypothesis. Therefore, I'll reject the null hypothesis and accept the alternative hypothesis.<br />

```{r, warning=FALSE,message=FALSE}
#retrieving all the pvalues from the list 
matrix_pval1 <- sapply(l3, "[[", 2); matrix_pval1 <- as.data.frame(matrix_pval1)
df_pval1 <- apply(matrix_pval1, 2, mean)
dF1 <- as.data.frame(t(df_pval1))
c<-0; vec <- c(); vec1 <- c()
for(i in 1:dim(dF1)[2]){
  if(dF1[i]<0.05){
    c<-c+1 
    vec <- c(vec,names(dF1[i]))
    vec1 <- c(vec1,as.character(dF1)[i])
  }
}
```

```{r, warning=FALSE,echo=FALSE,message=FALSE}
o <- matrix(nrow = 3 ,ncol = 1); o[1,1] <- c; o[2,1]<-dim(dF1)[2]-c; o[3,1] <- dim(dF1)[2]
rownames(o)<-c("True Positive","False Positive","Total Number Of Genes"); colnames(o)<-c("Count")
var <- as.table(o); knitr::kable(var)
```

This table shows how many genes are statistically significants and how many are not based on p-values. A true positive is an outcome where the model correctly predicts the positive class; however, a false positive is an outcome where the model incorrectly predicts the positive class.<br />

```{r, warning=FALSE,echo=FALSE,message=FALSE}
if(o[1,1] > 0){
  cat("Now let's zoom in and visualize which genes are statistically significant.\n")
  k<-matrix(nrow = length(vec),ncol = 2); k[,1]<-vec; k[,2]<-vec1
  colnames(k)<-c("Gene_Ids","P_value"); rownames(k)<-c(1:length(vec))
  backup_k <- k; var2 <- as.data.frame(backup_k) #max(as.character(var2$P_value))
  variable2 <- as.table(k); knitr::kable(variable2) }
```

<u>Using Bootsrapping:</u>

```{r, message=FALSE, warning=FALSE}
BT7 <- function(data,Y,R,percent) { 
  set.seed(9)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  pval<-rep(1,R)
  l <- vector("list",1) #creation of empty list
  model<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    model=glm(Class~data[,gene]+data[,which(colnames(data)=="GA")],data=data, subset=new_train_indices, family=binomial)
    pval[i]= summary(model)$coef[2,4] #get the pvalue 
    glm.pred=predict(model,data[test_indices,],type="response")
    
    glm.prob=rep(0,nrow(data))
    glm.prob[glm.pred >.5]=1
    accuracy[i]=mean(glm.prob==Class[test_indices]) 
  }
  l <- list(model,pval,accuracy); return(l)
}

l4<-vector("list")

for(gene in 1:number)
  l4[[length(l4)+1]] <- BT7(DATASET2,Class,100,30) 
names(l4) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l4, "[[", 3)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means4 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means4)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means4)
```

<u>P_value Interpretability</u><br />
In statistics, the p-value is the probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. A p-value less than or equal to 0.05 is statistically significant. It indicates a strong evidence against the null hypothesis. Therefore, I'll reject the null hypothesis and accept the alternative hypothesis.<br />

```{r, warning=FALSE,message=FALSE}
#retrieving all the pvalues from the list 
matrix_pval1 <- sapply(l4, "[[", 2); matrix_pval1 <- as.data.frame(matrix_pval1)
df_pval1 <- apply(matrix_pval1, 2, mean)
dF1 <- as.data.frame(t(df_pval1))
c<-0; vec <- c(); vec1 <- c()
for(i in 1:dim(dF1)[2]){
  if(dF1[i]<0.05){
    c<-c+1 
    vec <- c(vec,names(dF1[i]))
    vec1 <- c(vec1,as.character(dF1)[i])
  }
}
```

```{r, warning=FALSE,echo=FALSE,message=FALSE}
o <- matrix(nrow = 3 ,ncol = 1); o[1,1] <- c; o[2,1]<-dim(dF1)[2]-c; o[3,1] <- dim(dF1)[2]
rownames(o)<-c("True Positive","False Positive","Total Number Of Genes"); colnames(o)<-c("Count")
var <- as.table(o); knitr::kable(var)
```

This table shows how many genes are statistically significants and how many are not based on p-values. A true positive is an outcome where the model correctly predicts the positive class; however, a false positive is an outcome where the model incorrectly predicts the positive class.</div><br />

```{r, warning=FALSE,echo=FALSE,message=FALSE}
if(o[1,1] > 0){
  cat("Now let's zoom in and visualize which genes are statistically significant.\n")
  k<-matrix(nrow = length(vec),ncol = 2); k[,1]<-vec; k[,2]<-vec1
  colnames(k)<-c("Gene_Ids","P_value"); rownames(k)<-c(1:length(vec))
  backup_k <- k; var2 <- as.data.frame(backup_k) #max(as.character(var2$P_value))
  variable2 <- as.table(k); knitr::kable(variable2) }
```

#### Fitting LDA Models

<div style="text-align: justify"><u>Using Cross-validation:</u>

```{r, message=FALSE, warning=FALSE}
CV3 <- function(data, fold, output)
{
  set.seed(10)

  n=nrow(data)
  index=sample(n,n)
  l<-vector("list")
  model2<-c()
  
  group=cut(index, breaks = fold, labels =FALSE)
  accuracy=c()
  
  for( j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model2=lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=train, family=binomial)
    lda.pred=predict(model2,data[test,]) 
    
    #CLASS PREDICTION
    lda.class=lda.pred$class 
    #ACCURACY = TEST CORRECT RATE
    accuracy[j]<-mean(lda.class==Class[test])
  }
  
 l=list(model2,accuracy);return(l)
}

l5<-vector("list")

for(gene in 1:number)
  l5[[length(l5)+1]] <- CV3(DATASET2,100,Class)
names(l5) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l5, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means5 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means5)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means5)
```

<u>Using Bootsrapping:</u>

```{r, warning=FALSE,message=FALSE}
BT8 <- function(data,Y,R,percent) { 
  set.seed(11)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 
  l<-vector("list")
  model2<-c()
  
  #1)some initiation vectors.
  accuracy <- rep(1,R)

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an lda model on train data
    model2 <- lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=new_train_indices, family=binomial)

    #5) How well does this model perform on the test data? 
    lda.pred=predict(model2,data[test_indices,]) 

    #6)In order to make a prediction, convert these predicted probabilities into class labels: 0 or 1 - CLASS PREDICTION
    lda.class=lda.pred$class 

    #7) calculate a new ESTIMATED TEST ERROR RATE using mean() - ACCURACY = TEST CORRECT RATE
    accuracy[i]<-mean(lda.class==Class[test_indices])
  }
  l <- list(model2,accuracy); return(l)
}

l6<-vector("list")

for(gene in 1:number)
  l6[[length(l6)+1]] <- BT8(DATASET2,Class,100,30) 
names(l6) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l6, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means6 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means6)*100, 2),nsmall=2),"\n")
```

The gene id having highest mean with its index:</div>
```{r, warning=FALSE,message=FALSE}
which.max(col_means6)
```

#### Fitting SVM Model Using Linear Kernel

<div style="text-align: justify">The support vector machine (SVM) is an extension of the support vector classifier that results from enlarging the feature space using kernels to accommodate a non-linear boundary between classes. Fitting svm model whereby the predictors are the following: ONLY one highly correlated gene, all the non highly correlated genes and the gestational age predictor.</div><br/>

```{r, warning=FALSE,message=FALSE}
BT9 <- function(data,Y,R,percent) { 
  set.seed(12)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 
  l<-vector("list")

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out1 <- tune.svm(Class~`105377884_at`+`105377885_at`+ `3127_at`+ `3050_at`+ `28475_at`+ `105376839_at`+ `102724528_at`+ `647859_at`+ `7280_at`+ `722_at`+ `10562_at`+ `91543_at`+ `100049587_at`+ `6967_at`+ `6007_at`+ `221687_at`+ `100500857_at`+ `100287029_at`+ `101929128_at`+ `10911_at`+ `101928046_at`+ `6978_at`+ `28299_at`+ `439996_at`+ `57126_at`+ `100130520_at`+ `284486_at`+ `107984757_at`+ `83857_at`+ `5909_at`+ `285852_at`+ `105377267_at`+ `1178_at`+ `100506159_at`+ `57535_at`+ `28400_at`+ `3117_at`+ `5004_at`+ `403323_at`+ `780853_at`+ `28882_at`+ `3512_at`+ `1510_at`+ `55365_at`+ `28458_at`+ `100507639_at`+ `26804_at`+ `643418_at`+ `28935_at`+ `1675_at`+ `6976_at`+ `101929244_at`+ `692210_at`+ `193629_at`+ `28445_at`+ `28426_at`+ `3904_at`+ `28906_at`+ `343172_at`+ `105374150_at`+ `100302170_at`+ `152518_at`+ `28585_at`+ `1116_at`+ `105372321_at`+ `105377342_at`+ `1824_at`+ `28423_at`+ `2352_at`+ `28796_at`+ `3501_at`+ `106480750_at`+ `2215_at`+ `28884_at`+ `2838_at`+ `55600_at`+ `402057_at`+ `100033432_at`+ `105377459_at`+ `102724919_at`+ `28778_at`+ `10410_at`+ `54097_at`+ `6983_at`+ `106480559_at`+ `10900_at`+ `105375130_at`+ `26787_at`+ `28559_at`+ `653510_at`+ `101928948_at`+ `105369942_at`+ `100033426_at`+ `7130_at`+ `390561_at`+ `8781_at`+ `6286_at`+ `28500_at`+ `391267_at`+ `107986485_at`+ `9934_at`+ `79854_at`+ `2999_at`+ `26816_at`+ `101927708_at`+ `25826_at`+ `28434_at`+ `28802_at`+ `692208_at`+ `100170227_at`+ `407021_at`+ `106481894_at`+ `105377384_at`+ `107985743_at`+ `28797_at`+ `28822_at`+ `106480140_at`+ `1232_at`+ `5266_at`+ `101927178_at`+ `9301_at`+ `5197_at`+ `253039_at`+ `692063_at`+ `284422_at`+ `9349_at`+ `105374601_at`+ `105374264_at`+ `353088_at`+ `343171_at`+ `374969_at`+ `26785_at`+ `50865_at`+ `102724720_at`+ `4500_at`+ `28519_at`+GA, data=data[new_train_indices,], type="C-classification",kernel="linear",cost = 10^(-2:3))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out1$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out1,accuracy)
  return(l)
}

ans6 <- BT9(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans6[[1]]$best.parameters$cost)
cat("The accuracy is equal to",format(round(mean(ans6[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Radial Kernel

```{r, warning=FALSE,message=FALSE}
BT10 <- function(data,Y,R,percent) { 
  set.seed(13)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 
  l<-vector("list")

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out2 <- tune.svm(Class~`4317_at`+`105377885_at`+ `3127_at`+ `3050_at`+ `28475_at`+ `105376839_at`+ `102724528_at`+ `647859_at`+ `7280_at`+ `722_at`+ `10562_at`+ `91543_at`+ `100049587_at`+ `6967_at`+ `6007_at`+ `221687_at`+ `100500857_at`+ `100287029_at`+ `101929128_at`+ `10911_at`+ `101928046_at`+ `6978_at`+ `28299_at`+ `439996_at`+ `57126_at`+ `100130520_at`+ `284486_at`+ `107984757_at`+ `83857_at`+ `5909_at`+ `285852_at`+ `105377267_at`+ `1178_at`+ `100506159_at`+ `57535_at`+ `28400_at`+ `3117_at`+ `5004_at`+ `403323_at`+ `780853_at`+ `28882_at`+ `3512_at`+ `1510_at`+ `55365_at`+ `28458_at`+ `100507639_at`+ `26804_at`+ `643418_at`+ `28935_at`+ `1675_at`+ `6976_at`+ `101929244_at`+ `692210_at`+ `193629_at`+ `28445_at`+ `28426_at`+ `3904_at`+ `28906_at`+ `343172_at`+ `105374150_at`+ `100302170_at`+ `152518_at`+ `28585_at`+ `1116_at`+ `105372321_at`+ `105377342_at`+ `1824_at`+ `28423_at`+ `2352_at`+ `28796_at`+ `3501_at`+ `106480750_at`+ `2215_at`+ `28884_at`+ `2838_at`+ `55600_at`+ `402057_at`+ `100033432_at`+ `105377459_at`+ `102724919_at`+ `28778_at`+ `10410_at`+ `54097_at`+ `6983_at`+ `106480559_at`+ `10900_at`+ `105375130_at`+ `26787_at`+ `28559_at`+ `653510_at`+ `101928948_at`+ `105369942_at`+ `100033426_at`+ `7130_at`+ `390561_at`+ `8781_at`+ `6286_at`+ `28500_at`+ `391267_at`+ `107986485_at`+ `9934_at`+ `79854_at`+ `2999_at`+ `26816_at`+ `101927708_at`+ `25826_at`+ `28434_at`+ `28802_at`+ `692208_at`+ `100170227_at`+ `407021_at`+ `106481894_at`+ `105377384_at`+ `107985743_at`+ `28797_at`+ `28822_at`+ `106480140_at`+ `1232_at`+ `5266_at`+ `101927178_at`+ `9301_at`+ `5197_at`+ `253039_at`+ `692063_at`+ `284422_at`+ `9349_at`+ `105374601_at`+ `105374264_at`+ `353088_at`+ `343171_at`+ `374969_at`+ `26785_at`+ `50865_at`+ `102724720_at`+ `4500_at`+ `28519_at`+GA,data=data[new_train_indices,],type="C-classification",kernel="radial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out2$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out2,accuracy);return(l)
}

ans7 <- BT10(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans7[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans7[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans7[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 2)

```{r, warning=FALSE,message=FALSE}
BT11 <- function(data,Y,R,percent) { 
  set.seed(14)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 
  l<-vector("list")

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class~`10964_at`+`105377885_at`+ `3127_at`+ `3050_at`+ `28475_at`+ `105376839_at`+ `102724528_at`+ `647859_at`+ `7280_at`+ `722_at`+ `10562_at`+ `91543_at`+ `100049587_at`+ `6967_at`+ `6007_at`+ `221687_at`+ `100500857_at`+ `100287029_at`+ `101929128_at`+ `10911_at`+ `101928046_at`+ `6978_at`+ `28299_at`+ `439996_at`+ `57126_at`+ `100130520_at`+ `284486_at`+ `107984757_at`+ `83857_at`+ `5909_at`+ `285852_at`+ `105377267_at`+ `1178_at`+ `100506159_at`+ `57535_at`+ `28400_at`+ `3117_at`+ `5004_at`+ `403323_at`+ `780853_at`+ `28882_at`+ `3512_at`+ `1510_at`+ `55365_at`+ `28458_at`+ `100507639_at`+ `26804_at`+ `643418_at`+ `28935_at`+ `1675_at`+ `6976_at`+ `101929244_at`+ `692210_at`+ `193629_at`+ `28445_at`+ `28426_at`+ `3904_at`+ `28906_at`+ `343172_at`+ `105374150_at`+ `100302170_at`+ `152518_at`+ `28585_at`+ `1116_at`+ `105372321_at`+ `105377342_at`+ `1824_at`+ `28423_at`+ `2352_at`+ `28796_at`+ `3501_at`+ `106480750_at`+ `2215_at`+ `28884_at`+ `2838_at`+ `55600_at`+ `402057_at`+ `100033432_at`+ `105377459_at`+ `102724919_at`+ `28778_at`+ `10410_at`+ `54097_at`+ `6983_at`+ `106480559_at`+ `10900_at`+ `105375130_at`+ `26787_at`+ `28559_at`+ `653510_at`+ `101928948_at`+ `105369942_at`+ `100033426_at`+ `7130_at`+ `390561_at`+ `8781_at`+ `6286_at`+ `28500_at`+ `391267_at`+ `107986485_at`+ `9934_at`+ `79854_at`+ `2999_at`+ `26816_at`+ `101927708_at`+ `25826_at`+ `28434_at`+ `28802_at`+ `692208_at`+ `100170227_at`+ `407021_at`+ `106481894_at`+ `105377384_at`+ `107985743_at`+ `28797_at`+ `28822_at`+ `106480140_at`+ `1232_at`+ `5266_at`+ `101927178_at`+ `9301_at`+ `5197_at`+ `253039_at`+ `692063_at`+ `284422_at`+ `9349_at`+ `105374601_at`+ `105374264_at`+ `353088_at`+ `343171_at`+ `374969_at`+ `26785_at`+ `50865_at`+ `102724720_at`+ `4500_at`+ `28519_at`+GA,data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 2)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy);return(l)
}

ans8 <- BT11(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans8[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans8[[1]]$best.parameters$gamma)
cat("The highest accuracy is equal to",format(round(mean(ans8[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 3)

```{r, warning=FALSE,message=FALSE}
BT12 <- function(data,Y,R,percent) { 
  set.seed(15)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 
  l<-vector("list")

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class~`3123_at`+`105377885_at`+ `3127_at`+ `3050_at`+ `28475_at`+ `105376839_at`+ `102724528_at`+ `647859_at`+ `7280_at`+ `722_at`+ `10562_at`+ `91543_at`+ `100049587_at`+ `6967_at`+ `6007_at`+ `221687_at`+ `100500857_at`+ `100287029_at`+ `101929128_at`+ `10911_at`+ `101928046_at`+ `6978_at`+ `28299_at`+ `439996_at`+ `57126_at`+ `100130520_at`+ `284486_at`+ `107984757_at`+ `83857_at`+ `5909_at`+ `285852_at`+ `105377267_at`+ `1178_at`+ `100506159_at`+ `57535_at`+ `28400_at`+ `3117_at`+ `5004_at`+ `403323_at`+ `780853_at`+ `28882_at`+ `3512_at`+ `1510_at`+ `55365_at`+ `28458_at`+ `100507639_at`+ `26804_at`+ `643418_at`+ `28935_at`+ `1675_at`+ `6976_at`+ `101929244_at`+ `692210_at`+ `193629_at`+ `28445_at`+ `28426_at`+ `3904_at`+ `28906_at`+ `343172_at`+ `105374150_at`+ `100302170_at`+ `152518_at`+ `28585_at`+ `1116_at`+ `105372321_at`+ `105377342_at`+ `1824_at`+ `28423_at`+ `2352_at`+ `28796_at`+ `3501_at`+ `106480750_at`+ `2215_at`+ `28884_at`+ `2838_at`+ `55600_at`+ `402057_at`+ `100033432_at`+ `105377459_at`+ `102724919_at`+ `28778_at`+ `10410_at`+ `54097_at`+ `6983_at`+ `106480559_at`+ `10900_at`+ `105375130_at`+ `26787_at`+ `28559_at`+ `653510_at`+ `101928948_at`+ `105369942_at`+ `100033426_at`+ `7130_at`+ `390561_at`+ `8781_at`+ `6286_at`+ `28500_at`+ `391267_at`+ `107986485_at`+ `9934_at`+ `79854_at`+ `2999_at`+ `26816_at`+ `101927708_at`+ `25826_at`+ `28434_at`+ `28802_at`+ `692208_at`+ `100170227_at`+ `407021_at`+ `106481894_at`+ `105377384_at`+ `107985743_at`+ `28797_at`+ `28822_at`+ `106480140_at`+ `1232_at`+ `5266_at`+ `101927178_at`+ `9301_at`+ `5197_at`+ `253039_at`+ `692063_at`+ `284422_at`+ `9349_at`+ `105374601_at`+ `105374264_at`+ `353088_at`+ `343171_at`+ `374969_at`+ `26785_at`+ `50865_at`+ `102724720_at`+ `4500_at`+ `28519_at`+GA,data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 3)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy);return(l)
}

ans9 <- BT12(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans9[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans9[[1]]$best.parameters$gamma)
cat("The highest accuracy is equal to",format(round(mean(ans9[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Sigmoid Kernel

```{r, warning=FALSE,message=FALSE}
BT13 <- function(data,Y,R,percent) { 
  set.seed(16)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 
  l<-vector("list")

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out4 <- tune.svm(Class~`3429_at`+`105377885_at`+ `3127_at`+ `3050_at`+ `28475_at`+ `105376839_at`+ `102724528_at`+ `647859_at`+ `7280_at`+ `722_at`+ `10562_at`+ `91543_at`+ `100049587_at`+ `6967_at`+ `6007_at`+ `221687_at`+ `100500857_at`+ `100287029_at`+ `101929128_at`+ `10911_at`+ `101928046_at`+ `6978_at`+ `28299_at`+ `439996_at`+ `57126_at`+ `100130520_at`+ `284486_at`+ `107984757_at`+ `83857_at`+ `5909_at`+ `285852_at`+ `105377267_at`+ `1178_at`+ `100506159_at`+ `57535_at`+ `28400_at`+ `3117_at`+ `5004_at`+ `403323_at`+ `780853_at`+ `28882_at`+ `3512_at`+ `1510_at`+ `55365_at`+ `28458_at`+ `100507639_at`+ `26804_at`+ `643418_at`+ `28935_at`+ `1675_at`+ `6976_at`+ `101929244_at`+ `692210_at`+ `193629_at`+ `28445_at`+ `28426_at`+ `3904_at`+ `28906_at`+ `343172_at`+ `105374150_at`+ `100302170_at`+ `152518_at`+ `28585_at`+ `1116_at`+ `105372321_at`+ `105377342_at`+ `1824_at`+ `28423_at`+ `2352_at`+ `28796_at`+ `3501_at`+ `106480750_at`+ `2215_at`+ `28884_at`+ `2838_at`+ `55600_at`+ `402057_at`+ `100033432_at`+ `105377459_at`+ `102724919_at`+ `28778_at`+ `10410_at`+ `54097_at`+ `6983_at`+ `106480559_at`+ `10900_at`+ `105375130_at`+ `26787_at`+ `28559_at`+ `653510_at`+ `101928948_at`+ `105369942_at`+ `100033426_at`+ `7130_at`+ `390561_at`+ `8781_at`+ `6286_at`+ `28500_at`+ `391267_at`+ `107986485_at`+ `9934_at`+ `79854_at`+ `2999_at`+ `26816_at`+ `101927708_at`+ `25826_at`+ `28434_at`+ `28802_at`+ `692208_at`+ `100170227_at`+ `407021_at`+ `106481894_at`+ `105377384_at`+ `107985743_at`+ `28797_at`+ `28822_at`+ `106480140_at`+ `1232_at`+ `5266_at`+ `101927178_at`+ `9301_at`+ `5197_at`+ `253039_at`+ `692063_at`+ `284422_at`+ `9349_at`+ `105374601_at`+ `105374264_at`+ `353088_at`+ `343171_at`+ `374969_at`+ `26785_at`+ `50865_at`+ `102724720_at`+ `4500_at`+ `28519_at`+GA,data=data[new_train_indices,],type="C-classification",kernel="sigmoid",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out4$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out4,accuracy);return(l)
}

ans10 <- BT13(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans10[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans10[[1]]$best.parameters$gamma)
cat("The highest accuracy is equal to",format(round(mean(ans10[[2]])*100, 2),nsmall=2),"\n")
```

### Choosing The Best Model

<div style="text-align: justify">I will now compare the accuracies between the models having highest accuracies.<br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x1 <- matrix(nrow = 9,ncol = 3,byrow = F)
colnames(x1) <- c("Highest Accuracy","Cost","Gamma")
rownames(x1) <- c("GLM using CV","GLM using BT","LDA using CV", "LDA using BT", "SVM with linear kernel", "SVM with radial kernel", "SVM with polynomial kernel (degree 2)", "SVM with polynomial kernel (degree 3)", "SVM with sigmoid kernel")
x1[1,1] <- max(col_means3)*100;x1[1,2] <- "-";x1[1,3] <- "-"
x1[2,1] <- max(col_means4)*100;x1[2,2] <- "-";x1[2,3] <- "-"
x1[3,1] <- max(col_means5)*100;x1[3,2] <- "-";x1[3,3] <- "-"
x1[4,1] <- max(col_means6)*100;x1[4,2] <- "-";x1[4,3] <- "-"
x1[5,1] <- mean(ans6[[2]])*100;x1[5,2] <- ans6[[1]]$best.parameters$cost;x1[5,3] <- "-"
x1[6,1] <- mean(ans7[[2]])*100;x1[6,2] <- ans7[[1]]$best.parameters$cost;x1[6,3] <- ans7[[1]]$best.parameters$gamma
x1[7,1] <- mean(ans8[[2]])*100;x1[7,2] <- ans8[[1]]$best.parameters$cost;x1[7,3] <- ans8[[1]]$best.parameters$gamma
x1[8,1] <- mean(ans9[[2]])*100;x1[8,2] <- ans9[[1]]$best.parameters$cost;x1[8,3] <- ans9[[1]]$best.parameters$gamma
x1[9,1] <- mean(ans10[[2]])*100;x1[9,2] <- ans10[[1]]$best.parameters$cost;x1[9,3] <- ans10[[1]]$best.parameters$gamma
var <- as.table(x1); knitr::kable(var)

names<-rownames(x1)  
m2 <- names[which(x1==max(x1))]
a2 <- max(x1[,1])
cat("The model(s) having the highest accuracy is(are)",m2,"\n")
cat("The highest accuracy is equal to",a2,"\n")
```

Now, I'll predict PTB on the test/predicting dataset.</div><br />

```{r, warning=FALSE,message=FALSE}
glm_probability <- predict(l4[[which.max(col_means4)]][[1]], newdata = prediction_dataset, type = "response") 
```

## Binary Analysis (PPROM v/s Control)

```{r,warning=FALSE,echo=FALSE,message=FALSE}
train_dataset <- DF2[DF2$Train==1,-c(which(colnames(DF2)=="Train"),which(colnames(DF2)=="Individual"))] #This dataset contains mainly the observations present in the dataset classified as either sPTD, PPROM or control.
prediction_dataset <- DF2[DF2$Train==0,-c(which(colnames(DF2)=="Train"),which(colnames(DF2)=="Individual"))] #This dataset contains mainly the observations present in the dataset not classified in either class.
```

### Some Initial Statistics

```{r, message=FALSE,echo=FALSE,warning=FALSE}
#assign ur data frame to a new variable.
train_backup <- train_dataset 
cat("The dimension of this dataframe is",dim(train_backup),"\n")
```

<div style="text-align: justify">This table summarizes the number of numerical/categorical/logical predictors.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
n=0;c=0; a <- sapply(train_backup, is.numeric); for (i in 1:dim(train_backup)[2]){if(a[i]==TRUE){n=n+1}else{c=c+1}}
#ct <- length(Filter(is.factor, train_backup))
lg <- length(Filter(is.logical, train_backup))

O <- matrix(nrow = 4,ncol = 1) #matrix 1
colnames(O) <- "Count"
rownames(O) <- c("Numeric Variable(s)","Factor Predictor(s)","Logical Column(s)","Total")
O[1,] <- n; O[2,] <- c; O[3,] <- lg; O[4,] <- c+n+lg
riable1 <- as.table(O); knitr::kable(riable1)
```

### Identification Of Missing Values

<div style="text-align: justify">Some columns may present missing values. What I need to do is to identify them first and if present, I need to remove them and replace them with real values.

```{r, message=FALSE,echo=FALSE,warning=FALSE}
question_marks <- which(train_backup=="?",arr.ind = T)  

NA_values <- which(is.na(train_backup), arr.ind=T)

NaN_values <- which(apply(train_backup, 2, function(x) all(is.nan(x))))

infinite_values <- which(apply(train_backup, 2, function(x) all(is.infinite(x))))

blanck_values <- function (x) {sum(x=="") }
bvalues <- apply(train_backup, 2,blanck_values); bvalues<-as.character(bvalues);count<-0
for(index in 1:length(bvalues)){
  if(bvalues[index]!=0){
    count=count+1 } }
```

This table will summarize the different types of missing values.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x <- matrix(nrow = 5,ncol = 1,byrow = F)
colnames(x) <- c("Count")
rownames(x) <- c("Question marks","NA values","NaN values","Infinite values","Blank values")
tot <- dim(question_marks)[1]+dim(NA_values)[1]+length(NaN_values)+length(infinite_values)+count
x[1,1] <- dim(question_marks)[1]
x[2,1] <- dim(NA_values)[1]
x[3,1] <- length(NaN_values)
x[4,1] <- length(infinite_values)
x[5,1] <- tot
var <- as.table(x); knitr::kable(var)
```

### About The Class Predictor

```{r, message=FALSE, echo=FALSE, warning=FALSE}
#table of class
cat("The distribution of the 3 groups in the Class attribute")
table(train_backup$Class)

train_backup <- train_backup[-which(train_backup$Class == "sPTD"),]
table(train_backup$Class)
```

<div style="text-align: justify">Removing the sPTD class.</div>

```{r, message=FALSE, echo=FALSE, warning=FALSE}
train_backup$Class <- droplevels(train_backup$Class)
table(train_backup$Class) #nber of occurence in class

cat("The two groups are:",levels(train_backup$Class),"\nWhereby:\n 0 means Control\n 1 means PPROM (preterm premature rupture of membranes)\nLet's calculate the frequency of each subclass.")

control <- length(which(train_backup$Class=="Control"))
PPROM <- length(which(train_backup$Class=="PPROM"))

per_control <- control/length(train_backup$Class)*100
per_PPROM <- PPROM/length(train_backup$Class)*100

cat("The percentage of the control group is",format(round(per_control, 2), nsmall = 2),"\n")
cat("The percentage of the sPTD group is",format(round(per_PPROM, 2), nsmall = 2),"\n")
```

### Some Representative Plots
<div style="text-align: justify">The pairs plot cannot be done at all because the presence of at most 29k predictors will be invisible in such kind of plot.</div> 

#### Frequency Plot
<div style="text-align: justify">ggplot2 is a data visualization package for the statistical programming language R.</div> 

```{r, message=FALSE,echo=FALSE,warning=FALSE}
ggplot(data=train_backup, aes(x=Class,  fill=Class))  + geom_bar() +  scale_x_discrete(name = 'Class',labels=labs) + theme_bw() + ggtitle("The occurence of each level in the categorical variable")
```

#### Scatterplot
<div style="text-align: justify">A scatter plot is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data. This plot shows the distribution of gestational age in each of the classes.</div><br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
#plot class v/s GA
ggplot(train_backup,aes(Class,GA)) +labs(title = "Scatterplot of the class across the gestational ages as determined by the last menstrual period or ultrasound") +geom_point()
```

### Correlation Analysis

```{r, warning=FALSE,echo=FALSE,message=FALSE}
var <- cor(train_backup[1:200]) #correlation
var[lower.tri(var)] <- NA #replaces values in lower triangular matrix to NA
var[is.na(var)] <- 0 #then replace the NA to 0
diag(var)<-0 #replace values in the diagonal equals to 1 to 0
df <- as.data.frame(var) #change the class of df to a dataframe
df[df>=1] <- 0 #replace all values bigger than 1 to by 0
fct <- apply(df,2,max) #get the max value from each column
m <- as.matrix(fct) #save the fct as a matrix in a new variable called m
```

<div style="text-align: justify">Let's zoom in and visualize the highly correlated and the non highly correlated genes.</div><br/>

```{r, warning=FALSE,echo=FALSE,message=FALSE}
#get the highly correlated genes->having a correlation coefficient above 70%
highly_correlated_genes <- m[m[,1] > 0.70,]
highly_correlated_genes <- as.matrix(highly_correlated_genes)
cat("The number of highly correlated genes equals to",length(highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(highly_correlated_genes))

#get the non highly correlated genes->having a correlation coefficient below 70%
not_highly_correlated_genes <- m[m[,1] <= 0.70,]
not_highly_correlated_genes <- as.matrix(not_highly_correlated_genes)
cat("The number of non highly correlated genes equals to",length(not_highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(not_highly_correlated_genes))
```

### Building Models

<div style="text-align: justify">The categorical predictor has two levels: Control is the first level and PPROM is the second one.

```{r, message=FALSE, warning=FALSE}
DATASET2 <- train_backup
levels(DATASET2$Class)
levels(DATASET2$Class) <- c(0,1); levels(DATASET2$Class)
attach(DATASET2)
number<-dim(DATASET2)[2]-2 
```

<u>Analysis methods that I might consider for predicting preterm birth:</u><br />
Firstly, I will build generalized linear models.<br />
Secondly, I will move on to linear discriminant analysis.<br />
Thirdly, I will build several support vector machine models using different kernels.</div><br />

#### Fitting GLM Models

<div style="text-align: justify"><u>Using Cross-validation:</u>

```{r, message=FALSE, warning=FALSE}
CV4<-function(data,fold,Y)
{
  set.seed(17)

  n=nrow(data)
  index=sample(n,n)
  l<-vector("list")
  model<-c()
  
  group=cut(index, breaks = fold, labels =FALSE)
  pval=c();accuracy=c()
  for( j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model=glm(Class~data[,gene]+data[,which(colnames(data)=="GA")],data=data, subset=train, family=binomial)
    pval[j]= summary(model)$coef[2,4] #get the pvalue 
    glm.pred=predict(model,data[test,],type="response")
    
    glm.prob=rep(0,nrow(data))
    glm.prob[glm.pred >.5]=1
    accuracy[j]=mean(glm.prob==Class[test]) 
  }
  
 l=list(model,pval,accuracy);return(l)
}

l7<-vector("list")

for(gene in 1:number)
  l7[[length(l7)+1]] <- CV4(DATASET2,100,Class)
names(l7) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l7, "[[", 3)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means7 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means7)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means7)
```

<u>P_value Interpretability</u><br />
In statistics, the p-value is the probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. A p-value less than or equal to 0.05 is statistically significant. It indicates a strong evidence against the null hypothesis. Therefore, I'll reject the null hypothesis and accept the alternative hypothesis.<br />

```{r, warning=FALSE,message=FALSE}
#retrieving all the pvalues from the list 
matrix_pval1 <- sapply(l7, "[[", 2); matrix_pval1 <- as.data.frame(matrix_pval1)
df_pval1 <- apply(matrix_pval1, 2, mean)
dF1 <- as.data.frame(t(df_pval1))
c<-0; vec <- c(); vec1 <- c()
for(i in 1:dim(dF1)[2]){
  if(dF1[i]<0.05){
    c<-c+1 
    vec <- c(vec,names(dF1[i]))
    vec1 <- c(vec1,as.character(dF1)[i])
  }
}
```

```{r, warning=FALSE,echo=FALSE,message=FALSE}
o <- matrix(nrow = 3 ,ncol = 1); o[1,1] <- c; o[2,1]<-dim(dF1)[2]-c; o[3,1] <- dim(dF1)[2]
rownames(o)<-c("True Positive","False Positive","Total Number Of Genes"); colnames(o)<-c("Count")
var <- as.table(o); knitr::kable(var)
```

This table shows how many genes are statistically significants and how many are not based on p-values. A true positive is an outcome where the model correctly predicts the positive class; however, a false positive is an outcome where the model incorrectly predicts the positive class.<br />

```{r, warning=FALSE,echo=FALSE,message=FALSE}
if(o[1,1] > 0){
  cat("Now let's zoom in and visualize which genes are statistically significant.\n")
  k<-matrix(nrow = length(vec),ncol = 2); k[,1]<-vec; k[,2]<-vec1
  colnames(k)<-c("Gene_Ids","P_value"); rownames(k)<-c(1:length(vec))
  backup_k <- k; var2 <- as.data.frame(backup_k) #max(as.character(var2$P_value))
  variable2 <- as.table(k); knitr::kable(variable2) }
```

<u>Using Bootsrapping:</u>

```{r, message=FALSE, warning=FALSE}
BT14 <- function(data,Y,R,percent) { 
  set.seed(18)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  pval<-rep(1,R)
  l <- vector("list",1) #creation of empty list
  model<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    model=glm(Class~data[,gene]+data[,which(colnames(data)=="GA")],data=data, subset=new_train_indices, family=binomial)
    pval[i]= summary(model)$coef[2,4] #get the pvalue 
    glm.pred=predict(model,data[test_indices,],type="response")
    
    glm.prob=rep(0,nrow(data))
    glm.prob[glm.pred >.5]=1
    accuracy[i]=mean(glm.prob==Class[test_indices]) 
  }
  l <- list(model,pval,accuracy); return(l)
}

l8<-vector("list")

for(gene in 1:number)
  l8[[length(l8)+1]] <- BT14(DATASET2,Class,100,30) 
names(l8) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l8, "[[", 3)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means8 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means8)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means8)
```

<u>P_value Interpretability</u><br />
In statistics, the p-value is the probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. A p-value less than or equal to 0.05 is statistically significant. It indicates a strong evidence against the null hypothesis. Therefore, I'll reject the null hypothesis and accept the alternative hypothesis.<br />

```{r, warning=FALSE,message=FALSE}
#retrieving all the pvalues from the list 
matrix_pval1 <- sapply(l8, "[[", 2); matrix_pval1 <- as.data.frame(matrix_pval1)
df_pval1 <- apply(matrix_pval1, 2, mean)
dF1 <- as.data.frame(t(df_pval1))
c<-0; vec <- c(); vec1 <- c()
for(i in 1:dim(dF1)[2]){
  if(dF1[i]<0.05){
    c<-c+1 
    vec <- c(vec,names(dF1[i]))
    vec1 <- c(vec1,as.character(dF1)[i])
  }
}
```

```{r, warning=FALSE,echo=FALSE,message=FALSE}
o <- matrix(nrow = 3 ,ncol = 1); o[1,1] <- c; o[2,1]<-dim(dF1)[2]-c; o[3,1] <- dim(dF1)[2]
rownames(o)<-c("True Positive","False Positive","Total Number Of Genes"); colnames(o)<-c("Count")
var <- as.table(o); knitr::kable(var)
```

This table shows how many genes are statistically significants and how many are not based on p-values. A true positive is an outcome where the model correctly predicts the positive class; however, a false positive is an outcome where the model incorrectly predicts the positive class.</div><br />

```{r, warning=FALSE,echo=FALSE,message=FALSE}
if(o[1,1] > 0){
  cat("Now let's zoom in and visualize which genes are statistically significant.\n")
  k<-matrix(nrow = length(vec),ncol = 2); k[,1]<-vec; k[,2]<-vec1
  colnames(k)<-c("Gene_Ids","P_value"); rownames(k)<-c(1:length(vec))
  backup_k <- k; var2 <- as.data.frame(backup_k) #max(as.character(var2$P_value))
  variable2 <- as.table(k); knitr::kable(variable2) }
```

#### Fitting LDA Models

<div style="text-align: justify"><u>Using Cross-validation:</u>

```{r, message=FALSE, warning=FALSE}
CV5 <- function(data, fold, output)
{
  set.seed(19)

  n=nrow(data)
  index=sample(n,n)
  l<-vector("list")
  model2<-c()

  group=cut(index, breaks = fold, labels =FALSE)
  accuracy=c()
  
  for( j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model2=lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=train, family=binomial)
    lda.pred=predict(model2,data[test,]) 
    
    #CLASS PREDICTION
    lda.class=lda.pred$class 
    #ACCURACY = TEST CORRECT RATE
    accuracy[j]<-mean(lda.class==Class[test])
  }
  
 l=list(model2,accuracy);return(l)
}

l9<-vector("list")

for(gene in 1:number)
  l9[[length(l9)+1]] <- CV5(DATASET2,100,Class)
names(l9) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l9, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means9 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means9)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means9)
```

<u>Using Bootsrapping:</u>

```{r, warning=FALSE,message=FALSE}
BT15 <- function(data,Y,R,percent) { 
  set.seed(20)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  l<-vector("list")
  model2<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an lda model on train data
    model2 <- lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=new_train_indices, family=binomial)

    #5) How well does this model perform on the test data? 
    lda.pred=predict(model2,data[test_indices,]) 

    #6)In order to make a prediction, convert these predicted probabilities into class labels: 0 or 1 - CLASS PREDICTION
    lda.class=lda.pred$class 

    #7) calculate a new ESTIMATED TEST ERROR RATE using mean() - ACCURACY = TEST CORRECT RATE
    accuracy[i]<-mean(lda.class==Class[test_indices])
  }
  l <- list(model2,accuracy); return(l)
}

l10<-vector("list")

for(gene in 1:number)
  l10[[length(l10)+1]] <- BT15(DATASET2,Class,100,30) 
names(l10) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l10, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means10 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means10)*100, 2),nsmall=2),"\n")
```

The gene id having highest mean with its index:</div>
```{r, warning=FALSE,message=FALSE}
which.max(col_means10)
```

#### Fitting SVM Model Using Radial Kernel

<div style="text-align: justify">The support vector machine (SVM) is an extension of the support vector classifier that results from enlarging the feature space using kernels to accommodate a non-linear boundary between classes. Fitting svm model whereby the predictors are the following: ONLY one highly correlated gene, all the non highly correlated genes and the gestational age predictor.</div><br/>

```{r, warning=FALSE,message=FALSE}
BT17 <- function(data,Y,R,percent) { 
  set.seed(22)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit svm model on train data
    tune.out2 <- tune.svm(Class~`1088_at`+`105377885_at`+ `3127_at`+ `3050_at`+ `28475_at`+ `105376839_at`+ `102724528_at`+ `647859_at`+ `7280_at`+ `722_at`+ `10562_at`+ `91543_at`+ `100049587_at`+ `6967_at`+ `6007_at`+ `221687_at`+ `100500857_at`+ `100287029_at`+ `101929128_at`+ `10911_at`+ `101928046_at`+ `6978_at`+ `28299_at`+ `439996_at`+ `57126_at`+ `100130520_at`+ `107984757_at`+ `83857_at`+ `5909_at`+ `285852_at`+ `105377267_at`+ `1178_at`+ `100506159_at`+ `57535_at`+ `28400_at`+ `3117_at`+ `5004_at`+ `403323_at`+ `780853_at`+ `28882_at`+ `3512_at`+ `1510_at`+ `55365_at`+ `160364_at`+ `28458_at`+ `100507639_at`+ `26804_at`+ `643418_at`+ `28935_at`+ `1675_at`+ `6976_at`+ `101929244_at`+ `692210_at`+ `193629_at`+ `28445_at`+ `28426_at`+ `3904_at`+ `28906_at`+ `343172_at`+ `105374150_at`+ `100302170_at`+ `152518_at`+ `28585_at`+ `1116_at`+ `105372321_at`+ `105377342_at`+`1824_at`+ `28423_at`+ `2352_at`+ `28796_at`+ `3501_at`+ `106480750_at`+ `2215_at`+ `28884_at`+ `2838_at`+ `55600_at`+ `402057_at`+ `100033432_at`+ `105377459_at`+ `102724919_at`+ `28778_at`+ `10410_at`+ `54097_at`+ `6983_at`+ `106480559_at`+ `10900_at`+ `105375130_at`+ `26787_at`+ `28559_at`+ `653510_at`+ `101928948_at`+ `105369942_at`+ `100033426_at`+ `7130_at`+ `390561_at`+ `8781_at`+ `6286_at`+ `28500_at`+ `391267_at`+ `107986485_at`+ `9934_at`+ `79854_at`+ `2999_at`+ `26816_at`+ `101927708_at`+ `25826_at`+ `28434_at`+ `28802_at`+ `692208_at`+ `100170227_at`+ `407021_at`+ `106481894_at`+ `105377384_at`+ `107985743_at`+`28797_at`+ `28822_at`+ `106480140_at`+ `1232_at`+ `5266_at`+ `101927178_at`+ `9301_at`+ `5197_at`+ `253039_at`+ `692063_at`+ `284422_at`+ `9349_at`+ `105374601_at`+ `105374264_at`+ `353088_at`+ `374969_at`+ `26785_at`+ `50865_at`+ `102724720_at`+ `4500_at`+ `28519_at`+GA,data=data[new_train_indices,],type="C-classification",kernel="radial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out2$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out2,accuracy)
  return(l)
}

ans12 <- BT17(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans12[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans12[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans12[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 2)

```{r, warning=FALSE,message=FALSE}
BT18 <- function(data,Y,R,percent) { 
  set.seed(23)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit svm model on train data
    tune.out3 <- tune.svm(Class~`10561_at`+`105377885_at`+ `3127_at`+ `3050_at`+ `28475_at`+ `105376839_at`+ `102724528_at`+ `647859_at`+ `7280_at`+ `722_at`+ `10562_at`+ `91543_at`+ `100049587_at`+ `6967_at`+ `6007_at`+ `221687_at`+ `100500857_at`+ `100287029_at`+ `101929128_at`+ `10911_at`+ `101928046_at`+ `6978_at`+ `28299_at`+ `439996_at`+ `57126_at`+ `100130520_at`+ `107984757_at`+ `83857_at`+ `5909_at`+ `285852_at`+ `105377267_at`+ `1178_at`+ `100506159_at`+ `57535_at`+ `28400_at`+ `3117_at`+ `5004_at`+ `403323_at`+ `780853_at`+ `28882_at`+ `3512_at`+ `1510_at`+ `55365_at`+ `160364_at`+ `28458_at`+ `100507639_at`+ `26804_at`+ `643418_at`+ `28935_at`+ `1675_at`+ `6976_at`+ `101929244_at`+ `692210_at`+ `193629_at`+ `28445_at`+ `28426_at`+ `3904_at`+ `28906_at`+ `343172_at`+ `105374150_at`+ `100302170_at`+ `152518_at`+ `28585_at`+ `1116_at`+ `105372321_at`+ `105377342_at`+`1824_at`+ `28423_at`+ `2352_at`+ `28796_at`+ `3501_at`+ `106480750_at`+ `2215_at`+ `28884_at`+ `2838_at`+ `55600_at`+ `402057_at`+ `100033432_at`+ `105377459_at`+ `102724919_at`+ `28778_at`+ `10410_at`+ `54097_at`+ `6983_at`+ `106480559_at`+ `10900_at`+ `105375130_at`+ `26787_at`+ `28559_at`+ `653510_at`+ `101928948_at`+ `105369942_at`+ `100033426_at`+ `7130_at`+ `390561_at`+ `8781_at`+ `6286_at`+ `28500_at`+ `391267_at`+ `107986485_at`+ `9934_at`+ `79854_at`+ `2999_at`+ `26816_at`+ `101927708_at`+ `25826_at`+ `28434_at`+ `28802_at`+ `692208_at`+ `100170227_at`+ `407021_at`+ `106481894_at`+ `105377384_at`+ `107985743_at`+`28797_at`+ `28822_at`+ `106480140_at`+ `1232_at`+ `5266_at`+ `101927178_at`+ `9301_at`+ `5197_at`+ `253039_at`+ `692063_at`+ `284422_at`+ `9349_at`+ `105374601_at`+ `105374264_at`+ `353088_at`+ `374969_at`+ `26785_at`+ `50865_at`+ `102724720_at`+ `4500_at`+ `28519_at`+GA,data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 2)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy);return(l)
}

ans13 <- BT18(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans13[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans13[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans13[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 3)

```{r, warning=FALSE,message=FALSE}
BT19 <- function(data,Y,R,percent) { 
  set.seed(24)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit svm model on train data
    tune.out3 <- tune.svm(Class~`10321_at`+`105377885_at`+ `3127_at`+ `3050_at`+ `28475_at`+ `105376839_at`+ `102724528_at`+ `647859_at`+ `7280_at`+ `722_at`+ `10562_at`+ `91543_at`+ `100049587_at`+ `6967_at`+ `6007_at`+ `221687_at`+ `100500857_at`+ `100287029_at`+ `101929128_at`+ `10911_at`+ `101928046_at`+ `6978_at`+ `28299_at`+ `439996_at`+ `57126_at`+ `100130520_at`+ `107984757_at`+ `83857_at`+ `5909_at`+ `285852_at`+ `105377267_at`+ `1178_at`+ `100506159_at`+ `57535_at`+ `28400_at`+ `3117_at`+ `5004_at`+ `403323_at`+ `780853_at`+ `28882_at`+ `3512_at`+ `1510_at`+ `55365_at`+ `160364_at`+ `28458_at`+ `100507639_at`+ `26804_at`+ `643418_at`+ `28935_at`+ `1675_at`+ `6976_at`+ `101929244_at`+ `692210_at`+ `193629_at`+ `28445_at`+ `28426_at`+ `3904_at`+ `28906_at`+ `343172_at`+ `105374150_at`+ `100302170_at`+ `152518_at`+ `28585_at`+ `1116_at`+ `105372321_at`+ `105377342_at`+`1824_at`+ `28423_at`+ `2352_at`+ `28796_at`+ `3501_at`+ `106480750_at`+ `2215_at`+ `28884_at`+ `2838_at`+ `55600_at`+ `402057_at`+ `100033432_at`+ `105377459_at`+ `102724919_at`+ `28778_at`+ `10410_at`+ `54097_at`+ `6983_at`+ `106480559_at`+ `10900_at`+ `105375130_at`+ `26787_at`+ `28559_at`+ `653510_at`+ `101928948_at`+ `105369942_at`+ `100033426_at`+ `7130_at`+ `390561_at`+ `8781_at`+ `6286_at`+ `28500_at`+ `391267_at`+ `107986485_at`+ `9934_at`+ `79854_at`+ `2999_at`+ `26816_at`+ `101927708_at`+ `25826_at`+ `28434_at`+ `28802_at`+ `692208_at`+ `100170227_at`+ `407021_at`+ `106481894_at`+ `105377384_at`+ `107985743_at`+`28797_at`+ `28822_at`+ `106480140_at`+ `1232_at`+ `5266_at`+ `101927178_at`+ `9301_at`+ `5197_at`+ `253039_at`+ `692063_at`+ `284422_at`+ `9349_at`+ `105374601_at`+ `105374264_at`+ `353088_at`+ `374969_at`+ `26785_at`+ `50865_at`+ `102724720_at`+ `4500_at`+ `28519_at`+GA,data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 3)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy)
  return(l)
}

ans14 <- BT19(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans14[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans14[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans14[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Sigmoid Kernel

```{r, warning=FALSE,message=FALSE}
BT20 <- function(data,Y,R,percent) { 
  set.seed(25)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit svm model on train data
    tune.out4 <- tune.svm(Class~`51191_at`+`105377885_at`+ `3127_at`+ `3050_at`+ `28475_at`+ `105376839_at`+ `102724528_at`+ `647859_at`+ `7280_at`+ `722_at`+ `10562_at`+ `91543_at`+ `100049587_at`+ `6967_at`+ `6007_at`+ `221687_at`+ `100500857_at`+ `100287029_at`+ `101929128_at`+ `10911_at`+ `101928046_at`+ `6978_at`+ `28299_at`+ `439996_at`+ `57126_at`+ `100130520_at`+ `107984757_at`+ `83857_at`+ `5909_at`+ `285852_at`+ `105377267_at`+ `1178_at`+ `100506159_at`+ `57535_at`+ `28400_at`+ `3117_at`+ `5004_at`+ `403323_at`+ `780853_at`+ `28882_at`+ `3512_at`+ `1510_at`+ `55365_at`+ `160364_at`+ `28458_at`+ `100507639_at`+ `26804_at`+ `643418_at`+ `28935_at`+ `1675_at`+ `6976_at`+ `101929244_at`+ `692210_at`+ `193629_at`+ `28445_at`+ `28426_at`+ `3904_at`+ `28906_at`+ `343172_at`+ `105374150_at`+ `100302170_at`+ `152518_at`+ `28585_at`+ `1116_at`+ `105372321_at`+ `105377342_at`+`1824_at`+ `28423_at`+ `2352_at`+ `28796_at`+ `3501_at`+ `106480750_at`+ `2215_at`+ `28884_at`+ `2838_at`+ `55600_at`+ `402057_at`+ `100033432_at`+ `105377459_at`+ `102724919_at`+ `28778_at`+ `10410_at`+ `54097_at`+ `6983_at`+ `106480559_at`+ `10900_at`+ `105375130_at`+ `26787_at`+ `28559_at`+ `653510_at`+ `101928948_at`+ `105369942_at`+ `100033426_at`+ `7130_at`+ `390561_at`+ `8781_at`+ `6286_at`+ `28500_at`+ `391267_at`+ `107986485_at`+ `9934_at`+ `79854_at`+ `2999_at`+ `26816_at`+ `101927708_at`+ `25826_at`+ `28434_at`+ `28802_at`+ `692208_at`+ `100170227_at`+ `407021_at`+ `106481894_at`+ `105377384_at`+ `107985743_at`+`28797_at`+ `28822_at`+ `106480140_at`+ `1232_at`+ `5266_at`+ `101927178_at`+ `9301_at`+ `5197_at`+ `253039_at`+ `692063_at`+ `284422_at`+ `9349_at`+ `105374601_at`+ `105374264_at`+ `353088_at`+ `374969_at`+ `26785_at`+ `50865_at`+ `102724720_at`+ `4500_at`+ `28519_at`+GA,data=data[new_train_indices,],type="C-classification",kernel="sigmoid",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out4$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out4,accuracy);return(l)
}

ans15 <- BT20(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans15[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans15[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans15[[2]])*100, 2),nsmall=2),"\n")
```

### Choosing The Best Model

<div style="text-align: justify">I will now compare the accuracies between the models having highest accuracies.<br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x2 <- matrix(nrow = 8,ncol = 3,byrow = F)
colnames(x2) <- c("Highest Accuracy","Cost","Gamma")
rownames(x2) <- c("GLM using CV","GLM using BT","LDA using CV", "LDA using BT", "SVM with radial kernel", "SVM with polynomial kernel (degree 2)", "SVM with polynomial kernel (degree 3)", "SVM with sigmoid kernel")
x2[1,1] <- max(col_means7)*100;x2[1,2] <- "-";x2[1,3] <- "-"
x2[2,1] <- max(col_means8)*100;x2[2,2] <- "-";x2[2,3] <- "-"
x2[3,1] <- max(col_means9)*100;x2[3,2] <- "-";x2[3,3] <- "-"
x2[4,1] <- max(col_means10)*100;x2[4,2] <- "-";x2[4,3] <- "-"
x2[5,1] <- mean(ans12[[2]])*100;x2[5,2] <- ans12[[1]]$best.parameters$cost;x2[5,3] <- ans12[[1]]$best.parameters$gamma
x2[6,1] <- mean(ans13[[2]])*100;x2[6,2] <- ans13[[1]]$best.parameters$cost;x2[6,3] <- ans13[[1]]$best.parameters$gamma
x2[7,1] <- mean(ans14[[2]])*100;x2[7,2] <- ans14[[1]]$best.parameters$cost;x2[7,3] <- ans14[[1]]$best.parameters$gamma
x2[8,1] <- mean(ans15[[2]])*100;x2[8,2] <- ans15[[1]]$best.parameters$cost;x2[8,3] <- ans15[[1]]$best.parameters$gamma
var <- as.table(x2); knitr::kable(var)

names<-rownames(x2)   
m3 <- names[which(x2==max(x2))]
a3 <- max(x2[,1])
cat("The model(s) having the highest accuracy is(are)",m3,"\n")
cat("The highest accuracy is equal to",a3,"\n")
```

Now, I'll predict PTB on the test/predicting dataset.</div><br />

```{r, warning=FALSE,message=FALSE}
glm_probability <- predict(l8[[which.max(col_means8)]][[1]], newdata = prediction_dataset, type = "response") 
```

## My Results

<div style="text-align: justify">I will find the best model between the 3 different set of prediction: Multiclass, sPTD v/s Control and PPROM v/s Control.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x3 <- matrix(nrow = 3,ncol = 2,byrow = F)
colnames(x3) <- c("Highest Accuracy","Best Model(s) Name")
rownames(x3) <- c("Multiclass Prediction","sPTD v/s Control Prediction","PPROM v/s Control Prediction")
x3[1,1] <- a1;x3[1,2]<-m1
x3[2,1] <- a2;x3[2,2]<-m2
x3[3,1] <- a3;x3[3,2]<-m3
var <- as.table(x3); knitr::kable(var)

names<-rownames(x3)
cat("The set of prediction having the highest accuracy is",names[which(x3[,1]==max(x3[,1]))],"\n")
cat("The highest accuracy is equal to",format(round(max(as.numeric(x3[,1])), 2),nsmall=2),"\n")
```

## The Project's Results

<div style="text-align: justify">This table shows in a decrease order the accuracies of the models of all the participants who entered this project as well as my best model's accuracy for predicting preterm birth in asymptomatic women<br/>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
data1 <- read.table("/Users/oliverabinader/Desktop/acc_results.txt",header = T,sep=" ")

data1[100,] <- as.numeric(max(x3[,1]))/100
data1 <- apply(data1, 1, function(x) 100*x)

m <- sort(data1, decreasing = TRUE)
d <- as.data.frame(m)
colnames(d) <- "Accuracy"; rownames(d) <- 1:nrow(d)
rownames(d)[rownames(d) == which(d$Accuracy == as.numeric(max(x3[,1])))] <- "Oliver" 

knitr::kable(d)
```

**I can finally see that I am classified as the second participant in this project. Part A was taking a dataset that contains at most 200 gene ids.**

<u>**PART II B - PREDICTING PRETERM BIRTH using the first 300 columns.**</u></div><br/>

# Second Dataset

<div style="text-align: justify">*Second, I am going to use the dataset containing the first 300 columns from object number 1 with some additional columns(GA,Group,IndividualID and Train) from the second object.*</div>

## The Combined Dataset

```{r, message=FALSE, warning=FALSE}
data <- reduced_dat_300

#the additional columns
data$Class <- backup1$Group
data$GA <- backup1$GA
data$Individual <- backup1$IndividualID
data$Train <- backup1$Train

#indices of obvs (one sample per patient) to be used
odd <- seq(1,by=2, len=166)
dd=odd[1:166]
dd=c(dd,333,337,339,343,347,350,353,357,361,364,368,372,376,380,383,387,390,393,396,398,401,403,406,409,412,417,421,425,428,431)
DF_2=data[dd,]
```

<div style="text-align: justify">I'll divide the original dataset into two datasets. The train_dataset is used to build models whereas the prediction_dataset is use to predict preterm birth.</div><br />

## Multiclass Investigation

```{r,warning=FALSE,echo=FALSE,message=FALSE}
train_dataset <- DF_2[DF_2$Train==1,-c(which(colnames(DF_2)=="Train"),which(colnames(DF_2)=="Individual"))] #This dataset contains mainly the observations present in the dataset classified as either sPTD, PPROM or control.
prediction_dataset <- DF_2[DF_2$Train==0,-c(which(colnames(DF_2)=="Train"),which(colnames(DF_2)=="Individual"))] #This dataset contains mainly the observations present in the dataset not classified in either class.
```

### Some Initial Statistics

```{r, message=FALSE, warning=FALSE}
#assign ur data frame to a new variable.
train_backup <- train_dataset 
cat("The dimension of this dataframe is",dim(train_backup),"\n")
cat("The number of rows is",dim(train_backup)[1],"\nThe number of columns is",dim(train_backup)[2],"\n")
```

<div style="text-align: justify">This table summarizes the number of numerical/categorical/logical predictors.</div><br/>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
n=0;c=0; a <- sapply(train_backup, is.numeric); for (i in 1:dim(train_backup)[2]){if(a[i]==TRUE){n=n+1}else{c=c+1}}
#ct <- length(Filter(is.factor, train_backup))
lg <- length(Filter(is.logical, train_backup))

O <- matrix(nrow = 4,ncol = 1) #matrix 1
colnames(O) <- "Count"
rownames(O) <- c("Numeric Variable(s)","Factor Predictor(s)","Logical Column(s)","Total")
O[1,] <- n; O[2,] <- c; O[3,] <- lg; O[4,] <- c+n+lg
riable1 <- as.table(O); knitr::kable(riable1)
```

### Identification Of Missing Values

<div style="text-align: justify">Some columns may present missing values. What I need to do is to identify them first and if present, I need to remove them and replace them with real values.

```{r, message=FALSE,echo=FALSE,warning=FALSE}
question_marks <- which(train_backup=="?",arr.ind = T)  

NA_values <- which(is.na(train_backup), arr.ind=T)

NaN_values <- which(apply(train_backup, 2, function(x) all(is.nan(x))))

infinite_values <- which(apply(train_backup, 2, function(x) all(is.infinite(x))))

blanck_values <- function (x) {sum(x=="") }
bvalues <- apply(train_backup, 2,blanck_values); bvalues<-as.character(bvalues);count<-0
for(index in 1:length(bvalues)){
  if(bvalues[index]!=0){
    count=count+1 } }
```

This table summarizes the different types of missing values and their count.</div><br/>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x <- matrix(nrow = 5,ncol = 1,byrow = F)
colnames(x) <- c("Count")
rownames(x) <- c("Question marks","NA values","NaN values","Infinite values","Blank values")
tot <- dim(question_marks)[1]+dim(NA_values)[1]+length(NaN_values)+length(infinite_values)+count
x[1,1] <- dim(question_marks)[1]
x[2,1] <- dim(NA_values)[1]
x[3,1] <- length(NaN_values)
x[4,1] <- length(infinite_values)
x[5,1] <- tot
var <- as.table(x); knitr::kable(var)
```

### Checking Data Normalization

<div style="text-align: justify">I will do the shapiro test to check for normality, which can only be done on the numerical predictors.There are several methods for normality test such as Kolmogorov-Smirnov (K-S) normality test and Shapiro-Wilks test.</div><br/>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
numerical_predictor<-c() #a vector that will contain all the numerical predictors indicies
count2<-1 
for(i in 1:ncol(train_backup))  { # for loop to get all the numerical predictors indicies
  if(is.numeric(train_backup[,i])==TRUE) {
    numerical_predictor[count2]<-i
    count2<-count2+1 }
}

#if u apply the shapiro test on the numercical predictors, u'll then get their p_values and save them in a variable called p_val
p_val<-c()
test<-vector("list",1)
for(i in 1: length(numerical_predictor)) {
  test[[i]]<-shapiro.test(train_backup[,numerical_predictor[i]])
  p_val[i]<-test[[i]]$p.value
}
#p-value is a vector of all the p-values for all genes

normal<-which(p_val<0.05) #Since pval is less than 5%, hence accepting the null hypothesis means the data is normally distributed. However, rejecting the null hypothesis means the data will not normally distributed.

n<-(dim(train_backup)[2])-length(normal)
d<-length(normal)

cat("The number of columns that are not normally distributed is:",n,"\n")
cat("The number of columns that are normally distributed is:",d,"\n")
```

### About The Class Predictor

```{r, message=FALSE, echo=FALSE,warning=FALSE}
#table of class
cat("The distribution of the 3 groups in the Class attribute")
table(train_backup$Class)

cat("The 3 groups are:",levels(train_backup$Class),"\nWhereby:\n 0 means Control\n 1 means PPROM (preterm premature rupture of membranes)\n 2 means sPTD (spontaneous preterm labor and delivery with intact membranes)\nLet's calculate the frequency of each subclass.")

control <- length(which(train_backup$Class=="Control"))
PPROM <- length(which(train_backup$Class=="PPROM"))
sPTD <- length(which(train_backup$Class=="sPTD"))

per_control <- control/length(train_backup$Class)*100
per_PPROM <- PPROM/length(train_backup$Class)*100
per_sPTD <- sPTD/length(train_backup$Class)*100

cat("The percentage of the control group is",format(round(per_control, 2), nsmall = 2),"\n")
cat("The percentage of the PPROM group is",format(round(per_PPROM, 2), nsmall = 2),"\n")
cat("The percentage of the sPTD group is",format(round(per_sPTD, 2), nsmall = 2),"\n")
```

### Some Representative Plots

<div style="text-align: justify">The pairs plot cannot be done at all because the presence of at most 29k predictors will be invisible in such kind of plot.</div> 

#### Frequency Plot

<div style="text-align: justify">ggplot2 is a data visualization package for the statistical programming language R.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
ggplot(data=train_backup, aes(x=Class,  fill=Class))  + geom_bar() +  scale_x_discrete(name = 'Class',labels=labs) + theme_bw() + ggtitle("The occurence of each level in the categorical variable")
```

#### Correlogram

<div style="text-align: justify">Let's examine the correlation between some continuous variables present in the same dataframe. This is conveniently implemented using the ggcorrplot package. Correlation coefficients are used to measure the strength of the relationship between two variables. When the value of correlation coefficient is close to zero, generally between -0.1 and +0.1, the variables are said to have no linear relationship or a very weak linear relationship.</div> 

```{r, message=FALSE,echo=FALSE,warning=FALSE}
ggcorrplot(round(cor(train_backup[c(1:16)]), 1), hc.order = TRUE,type = "full",lab = TRUE,lab_size = 3,method="circle",colors= c("tomato2", "white", "springgreen3"), title="Correlogram between the first 16 gene ids",ggtheme=theme_bw)
```

### Correlation Analysis

```{r, warning=FALSE,message=FALSE}
var <- cor(train_backup[1:300]) #correlation
var[lower.tri(var)] <- NA #replaces values in lower triangular matrix to NA
var[is.na(var)] <- 0 #then replace the NA to 0
diag(var)<-0 #replace values in the diagonal equals to 1 to 0
df <- as.data.frame(var) #change the class of df to a dataframe
df[df>=1] <- 0 #replace all values bigger than 1 to by 0
fct <- apply(df,2,max) #get the max value from each column
m <- as.matrix(fct) #save the fct as a matrix in a new variable called m
```

<div style="text-align: justify">Let's zoom in and visualize the highly correlated and the non highly correlated genes.</div><br/>

```{r, warning=FALSE,message=FALSE}
#get the highly correlated genes->having a correlation coefficient above 70%
highly_correlated_genes <- m[m[,1] > 0.70,]
highly_correlated_genes <- as.matrix(highly_correlated_genes)
cat("The number of highly correlated genes equals to",length(highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(highly_correlated_genes))

#get the non highly correlated genes->having a correlation coefficient below 70%
not_highly_correlated_genes <- m[m[,1] <= 0.70,]
not_highly_correlated_genes <- as.matrix(not_highly_correlated_genes)
cat("The number of non highly correlated genes equals to",length(not_highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(not_highly_correlated_genes))
```

### Building Models

<div style="text-align: justify">The categorical predictor has three classes: Control is the first level, PPROM is the second level and sPTD is the third one.

```{r, message=FALSE, warning=FALSE}
DATASET <- train_backup
levels(DATASET$Class)
levels(DATASET$Class) <- c(0,1,2); levels(DATASET$Class)
attach(DATASET)
number<-dim(DATASET)[2]-2
```

<u>Analysis method that I might consider for predicting preterm birth:</u><br />
First, I will build linear discriminant analysis models.<br />
Second, I will build support vector machine models using different kernels.<br /></div>

#### Fitting LDA Models

<u>Using Cross-validation:</u>

```{r, message=FALSE, warning=FALSE}
CV6 <- function(data, fold, output)
{
  set.seed(26)

  n=nrow(data)
  index=sample(n,n)
  l<-vector("list")
  model2<-c()

  group=cut(index, breaks = fold, labels =FALSE)
  accuracy=c()
  
  for(j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model2=lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=train, family=miltinomial)
    lda.pred=predict(model2,data[test,]) 
    
    #CLASS PREDICTION
    lda.class=lda.pred$class 
    #ACCURACY = TEST CORRECT RATE
    accuracy[j]<-mean(lda.class==Class[test])
  }
  
 l=list(model2,accuracy);return(l)
}

l11<-vector("list")

for(gene in 1:number)
  l11[[length(l11)+1]] <- CV6(DATASET,100,Class)
names(l11) <- colnames(DATASET[1:number])

matrix_acc <- sapply(l11, "[[", 2)
df_acc <- as.data.frame(matrix_acc)
col_means11 <- apply(df_acc, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means11)*100, 2),nsmall=2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means11)
```

<u>Using Bootsrapping:</u>

```{r, warning=FALSE,message=FALSE}
BT21 <- function(data,Y,R,percent) { 
  set.seed(27)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 
  model2<-c()

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  l<-vector("list")

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an lda model on train data
    model2 <- lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=new_train_indices, family=multinomial)

    #5) How well does this model perform on the test data? 
    lda.pred=predict(model2,data[test_indices,]) 

    #6)In order to make a prediction, convert these predicted probabilities into class labels: 0 or 1 - CLASS PREDICTION
    lda.class=lda.pred$class 

    #7) calculate a new ESTIMATED TEST ERROR RATE using mean() - ACCURACY = TEST CORRECT RATE
    accuracy[i]<-mean(lda.class==Class[test_indices])
  }
  l <- list(model2,accuracy); return(l)
}

l12<-vector("list")

for(gene in 1:number)
  l12[[length(l12)+1]] <- BT21(DATASET,Class,100,30) 
names(l12) <- colnames(DATASET[1:number])

matrix_a <- sapply(l12, "[[", 2)
df_a <- as.data.frame(matrix_a)
col_means12 <- apply(df_a, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means12)*100, 2),nsmall=2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means12)
```

#### Fitting SVM Model Using Radial Kernel

<div style="text-align: justify">The support vector machine (SVM) is an extension of the support vector classifier that results from enlarging the feature space using kernels to accommodate a non-linear boundary between classes. Fitting svm model whereby the predictors are the following: ONLY one highly correlated gene, all the non highly correlated genes and the gestational age predictor.</div><br/>

```{r, warning=FALSE,message=FALSE}
BT23 <- function(data,Y,R,percent) { 
  set.seed(29)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out2 <- tune.svm(Class ~ . -`105377884_at`- `4317_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`-`6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`-`3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `25907_at`- `24138_at`- `28946_at`, data=data[new_train_indices,],type="C-classification",kernel="radial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out2$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out2,accuracy)
  return(l)
}

ans17 <- BT23(DATASET,Class,100,30) 
cat("The best cost value is equal to",ans17[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans17[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans17[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 2)

```{r, warning=FALSE,message=FALSE}
BT24 <- function(data,Y,R,percent) { 
  set.seed(30)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class ~ . -`105377884_at`- `4317_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`-`6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`-`3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `25907_at`- `24138_at`- `28946_at`,  data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 2)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy);return(l)
}

ans18 <- BT24(DATASET,Class,100,30) 
cat("The best cost value is equal to",ans18[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans18[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans18[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 3)

```{r, warning=FALSE,message=FALSE}
BT25 <- function(data,Y,R,percent) { 
  set.seed(31)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class ~ . -`105377884_at`- `4317_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`-`6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`-`3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `25907_at`- `24138_at`- `28946_at`,  data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 3)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy);return(l)
}

ans19 <- BT25(DATASET,Class,100,30) 
cat("The best cost value is equal to",ans19[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans19[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans19[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Sigmoid Kernel

```{r, warning=FALSE,message=FALSE}
BT26 <- function(data,Y,R,percent) { 
  set.seed(32)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out4 <- tune.svm(Class ~ . -`105377884_at`- `4317_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`-`6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`-`3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `25907_at`- `24138_at`- `28946_at`,  data=data[new_train_indices,],type="C-classification",kernel="sigmoid",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out4$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out4,accuracy)
  return(l)
}

ans20 <- BT26(DATASET,Class,100,30) 
cat("The best cost value is equal to",ans20[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans20[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans20[[2]])*100, 2),nsmall=2),"\n")
```

### Choosing The Best Model

<div style="text-align: justify">I will now compare the accuracies between the models having highest accuracies.<br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x4 <- matrix(nrow = 6,ncol = 3,byrow = F)
colnames(x4) <- c("Highest Accuracy","Cost","Gamma")
rownames(x4) <- c("LDA using CV", "LDA using BT", "SVM with radial kernel", "SVM with polynomial kernel (degree 2)", "SVM with polynomial kernel (degree 3)", "SVM with sigmoid kernel")
x4[1,1] <- max(col_means11)*100;x4[1,2] <- "-";x4[1,3] <- "-"
x4[2,1] <- max(col_means12)*100;x4[2,2] <- "-";x4[2,3] <- "-"
x4[3,1] <- mean(ans17[[2]])*100;x4[3,2] <- ans17[[1]]$best.parameters$cost;x4[3,3] <- ans17[[1]]$best.parameters$gamma
x4[4,1] <- mean(ans18[[2]])*100;x4[4,2] <- ans18[[1]]$best.parameters$cost;x4[4,3] <- ans18[[1]]$best.parameters$gamma
x4[5,1] <- mean(ans19[[2]])*100;x4[5,2] <- ans19[[1]]$best.parameters$cost;x4[5,3] <- ans19[[1]]$best.parameters$gamma
x4[6,1] <- mean(ans20[[2]])*100;x4[6,2] <- ans20[[1]]$best.parameters$cost;x4[6,3] <- ans20[[1]]$best.parameters$gamma
var <- as.table(x4); knitr::kable(var)

names<-rownames(x4)
m4<-names[which(x4==max(x4))]
a4<-max(x4[,1])
cat("The model(s) having the highest accuracy is(are)",m4,"\n")
cat("The highest accuracy is equal to",a4,"\n")
```

Now, I'll predict premature birth on the test/predicting dataset using the newdata argument.</div><br />

```{r, warning=FALSE,message=FALSE}
lda_probability <- predict(l12[[which.max(col_means12)]][[1]], newdata = prediction_dataset) 
```

## Binary Analysis (sPTD v/s Control)

```{r,warning=FALSE,echo=FALSE,message=FALSE}
train_dataset <- DF_2[DF_2$Train==1,-c(which(colnames(DF_2)=="Train"),which(colnames(DF_2)=="Individual"))] #This dataset contains mainly the observations present in the dataset classified as either sPTD, PPROM or control.
prediction_dataset <- DF_2[DF_2$Train==0,-c(which(colnames(DF_2)=="Train"),which(colnames(DF_2)=="Individual"))] #This dataset contains mainly the observations present in the dataset not classified in either class.
```

### Some Initial Statistics

```{r, message=FALSE, warning=FALSE}
#assign ur data frame to a new variable.
train_backup <- train_dataset 
cat("The dimension of this dataframe is",dim(train_backup),"\n")

#the type of each column
classes <- lapply(train_backup,class) 
cat("\nPrint the first six columns of the dataframe.\n")
head(classes)
cat("Print the last six predictors of the dataframe.\n")
tail(classes)
```

### Identification Of Missing Values

<div style="text-align: justify">Some columns may present missing values. What I need to do is to identify them first and if present, I need to remove them and replace them with real values.

```{r, message=FALSE,warning=FALSE}
question_marks <- which(train_backup=="?",arr.ind = T)  

NA_values <- which(is.na(train_backup), arr.ind=T)

NaN_values <- which(apply(train_backup, 2, function(x) all(is.nan(x))))

infinite_values <- which(apply(train_backup, 2, function(x) all(is.infinite(x))))

blanck_values <- function (x) {sum(x=="") }
bvalues <- apply(train_backup, 2,blanck_values); bvalues<-as.character(bvalues);count<-0
for(index in 1:length(bvalues)){
  if(bvalues[index]!=0){
    count=count+1 } }
```

This table summarizes the different types of missing values.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x <- matrix(nrow = 5,ncol = 1,byrow = F)
colnames(x) <- c("Count")
rownames(x) <- c("Question marks","NA values","NaN values","Infinite values","Blank values")
tot <- dim(question_marks)[1]+dim(NA_values)[1]+length(NaN_values)+length(infinite_values)+count
x[1,1] <- dim(question_marks)[1]
x[2,1] <- dim(NA_values)[1]
x[3,1] <- length(NaN_values)
x[4,1] <- length(infinite_values)
x[5,1] <- tot
var <- as.table(x); knitr::kable(var)
```

### About The Class Predictor

```{r, message=FALSE, warning=FALSE}
#table of class
cat("The distribution of the 3 groups in the Class attribute")
table(train_backup$Class)
```

Removing the PPROM class.

```{r, message=FALSE, warning=FALSE}
train_backup <- train_backup[-which(train_backup$Class == "PPROM"),]
table(train_backup$Class)

train_backup$Class <- droplevels(train_backup$Class)
table(train_backup$Class) #nber of occurence in class

cat("The two groups are:",levels(train_backup$Class),"\nWhereby:\n 0 means Control\n 1 means sPTD (spontaneous preterm labor and delivery with intact membranes)\nLet's calculate the frequency of each subclass.")

control <- length(which(train_backup$Class=="Control"))
sPTD <- length(which(train_backup$Class=="sPTD"))

per_control <- control/length(train_backup$Class)*100
per_sPTD <- sPTD/length(train_backup$Class)*100

cat("The percentage of the control group is",format(round(per_control, 2), nsmall = 2),"\n")
cat("The percentage of the sPTD group is",format(round(per_sPTD, 2), nsmall = 2),"\n")
```

### Some Representative Plots

<div style="text-align: justify">The pairs plot cannot be done at all because the presence of at most 29k predictors will be invisible in such kind of plot.</div>

#### Frequency Plot

<div style="text-align: justify">ggplot2 is a data visualization package for the statistical programming language R.</div> 

```{r, message=FALSE,echo=FALSE,warning=FALSE}
ggplot(data=train_backup, aes(x=Class,  fill=Class))  + geom_bar() +  scale_x_discrete(name = 'Class',labels=labs) + theme_bw() + ggtitle("The occurence of each level in the categorical variable")
```

#### Scatterplot
<div style="text-align: justify">A scatter plot is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data. This plot shows the distribution of gestational age in each of the classes.</div><br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
#plot class v/s GA
ggplot(train_backup,aes(Class,GA)) +labs(title = "Scatterplot of the class across the gestational ages as determined by the last menstrual period or ultrasound") +geom_point()
```

### Correlation Analysis

```{r, warning=FALSE,message=FALSE}
var <- cor(train_backup[1:300]) #correlation
var[lower.tri(var)] <- NA #replaces values in lower triangular matrix to NA
var[is.na(var)] <- 0 #then replace the NA to 0
diag(var)<-0 #replace values in the diagonal equals to 1 to 0
df <- as.data.frame(var) #change the class of df to a dataframe
df[df>=1] <- 0 #replace all values bigger than 1 to by 0
fct <- apply(df,2,max) #get the max value from each column
m <- as.matrix(fct) #save the fct as a matrix in a new variable called m
```

<div style="text-align: justify">Let's zoom in and visualize the highly correlated and the non highly correlated genes.</div><br/><br/>

```{r, warning=FALSE,message=FALSE}
#get the highly correlated genes->having a correlation coefficient above 70%
highly_correlated_genes <- m[m[,1] > 0.70,]
highly_correlated_genes <- as.matrix(highly_correlated_genes)
cat("The number of highly correlated genes equals to",length(highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(highly_correlated_genes))

#get the non highly correlated genes->having a correlation coefficient below 70%
not_highly_correlated_genes <- m[m[,1] <= 0.70,]
not_highly_correlated_genes <- as.matrix(not_highly_correlated_genes)
cat("The number of non highly correlated genes equals to",length(not_highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(not_highly_correlated_genes))
```

### Correlation Visualization

```{r, warning=FALSE,echo=FALSE,message=FALSE}
correlationMatrix <- cor(train_backup[,1:300])
heatmap.2(correlationMatrix,dendrogram=c("none"), trace = "none", col = as.vector(wes_palette(name = "FantasticFox1", n=15, type="continuous")))
```

### Building Models

<div style="text-align: justify">The categorical predictor has two levels: Control is the first level and sPTD is the second one.

```{r, message=FALSE, warning=FALSE}
DATASET <- train_backup
levels(DATASET$Class)
levels(DATASET$Class) <- c(0,1); levels(DATASET$Class)
attach(DATASET)
number<-dim(DATASET)[2]-2 
```

<u>Analysis methods that I might consider for predicting preterm birth.</u><br />
Firstly, I will build generalized linear models.<br />
Secondly, I will move on to linear discriminant analysis.<br />
Thirdly, I will build several support vector machine models using different kernels.</div> <br />

#### Fitting GLM Models

<u>Using Cross-validation:</u>

```{r, message=FALSE, warning=FALSE}
CV7<-function(data,fold,Y)
{
  set.seed(33)
    
  n=nrow(data)
  index=sample(n,n)
  l<-vector("list")
  model<-c()

  group=cut(index, breaks = fold, labels =FALSE)
  pval=c();accuracy=c()
  for( j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model=glm(Class~data[,gene]+data[,which(colnames(data)=="GA")],data=data, subset=train, family=binomial)
    pval[j]= summary(model)$coef[2,4] #get the pvalue 
    glm.pred=predict(model,data[test,],type="response")
    
    glm.prob=rep(0,nrow(data))
    glm.prob[glm.pred >.5]=1
    accuracy[j]=mean(glm.prob==Class[test]) 
  }
  
 l=list(model,pval,accuracy);return(l)
}

l13<-vector("list")

for(gene in 1:number)
  l13[[length(l13)+1]] <- CV7(DATASET,100,Class)
names(l13) <- colnames(DATASET[1:number])
matrix_accuracy <- sapply(l13, "[[", 3)

df_accuracy <- as.data.frame(matrix_accuracy)
col_means13 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means13)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means13)
```

<div style="text-align: justify"><u>P_value Interpretability</u><br />
In statistics, the p-value is the probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. A p-value less than or equal to 0.05 is statistically significant. It indicates a strong evidence against the null hypothesis. Therefore, I'll  reject the null hypothesis and accept the alternative hypothesis.<br />

```{r, warning=FALSE,message=FALSE}
#retrieving all the pvalues from the list 
matrix_pval1 <- sapply(l13, "[[", 2); matrix_pval1 <- as.data.frame(matrix_pval1)
df_pval1 <- apply(matrix_pval1, 2, mean)
dF1 <- as.data.frame(t(df_pval1))
c<-0; vec <- c(); vec1 <- c()
for(i in 1:dim(dF1)[2]){
  if(dF1[i]<0.05){
    c<-c+1 
    vec <- c(vec,names(dF1[i]))
    vec1 <- c(vec1,as.character(dF1)[i])
  }
}
```

```{r, warning=FALSE,echo=FALSE,message=FALSE}
o <- matrix(nrow = 3 ,ncol = 1); o[1,1] <- c; o[2,1]<-dim(dF1)[2]-c; o[3,1] <- dim(dF1)[2]
rownames(o)<-c("True Positive","False Positive","Total Number Of Genes"); colnames(o)<-c("Count")
var <- as.table(o); knitr::kable(var)
```

This table shows how many genes are statistically significants and how many are not based on p-values. A true positive is an outcome where the model correctly predicts the positive class; however, a false positive is an outcome where the model incorrectly predicts the positive class.</div> <br />

```{r, warning=FALSE,echo=FALSE,message=FALSE}
if(o[1,1] > 0){
  cat("Now let's zoom in and visualize which genes are statistically significant.\n")
  k<-matrix(nrow = length(vec),ncol = 2); k[,1]<-vec; k[,2]<-vec1
  colnames(k)<-c("Gene_Ids","P_value"); rownames(k)<-c(1:length(vec))
  backup_k <- k; var2 <- as.data.frame(backup_k) #max(as.character(var2$P_value))
  variable2 <- as.table(k); knitr::kable(variable2) }
```

<u>Using Bootsrapping:</u> 

```{r, message=FALSE, warning=FALSE}
BT27 <- function(data,Y,R,percent) { 
  set.seed(34)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  pval<-rep(1,R)
  l <- vector("list",1) #creation of empty list
  model<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    model=glm(Class~data[,gene]+data[,which(colnames(data)=="GA")],data=data, subset=new_train_indices, family=binomial)
    pval[i]= summary(model)$coef[2,4] #get the pvalue 
    glm.pred=predict(model,data[test_indices,],type="response")
    
    glm.prob=rep(0,nrow(data))
    glm.prob[glm.pred >.5]=1
    accuracy[i]=mean(glm.prob==Class[test_indices]) 
  }
  l <- list(model,pval,accuracy); return(l)
}

l14<-vector("list")

for(gene in 1:number)
  l14[[length(l14)+1]] <- BT27(DATASET,Class,100,30) 
names(l14) <- colnames(DATASET[1:number])

matrix_accuracy <- sapply(l14, "[[", 3)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means14 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means14)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means14)
```

<div style="text-align: justify"><u>P_value Interpretability</u><br />
In statistics, the p-value is the probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. A p-value less than or equal to 0.05 is statistically significant. It indicates a strong evidence against the null hypothesis. Therefore, I'll  reject the null hypothesis and accept the alternative hypothesis.<br />

```{r, warning=FALSE,message=FALSE}
#retrieving all the pvalues from the list 
matrix_pval1 <- sapply(l14, "[[", 2); matrix_pval1 <- as.data.frame(matrix_pval1)
df_pval1 <- apply(matrix_pval1, 2, mean)
dF1 <- as.data.frame(t(df_pval1))
c<-0; vec <- c(); vec1 <- c()
for(i in 1:dim(dF1)[2]){
  if(dF1[i]<0.05){
    c<-c+1 
    vec <- c(vec,names(dF1[i]))
    vec1 <- c(vec1,as.character(dF1)[i])
  }
}
```

```{r, warning=FALSE,echo=FALSE,message=FALSE}
o <- matrix(nrow = 3 ,ncol = 1); o[1,1] <- c; o[2,1]<-dim(dF1)[2]-c; o[3,1] <- dim(dF1)[2]
rownames(o)<-c("True Positive","False Positive","Total Number Of Genes"); colnames(o)<-c("Count")
var <- as.table(o); knitr::kable(var)
```

This table shows how many genes are statistically significants and how many are not based on p-values. A true positive is an outcome where the model correctly predicts the positive class; however, a false positive is an outcome where the model incorrectly predicts the positive class.</div> <br />

```{r, warning=FALSE,echo=FALSE,message=FALSE}
if(o[1,1] > 0){
  cat("Now let's zoom in and visualize which genes are statistically significant.\n")
  k<-matrix(nrow = length(vec),ncol = 2); k[,1]<-vec; k[,2]<-vec1
  colnames(k)<-c("Gene_Ids","P_value"); rownames(k)<-c(1:length(vec))
  backup_k <- k; var2 <- as.data.frame(backup_k) #max(as.character(var2$P_value))
  variable2 <- as.table(k); knitr::kable(variable2) }
```

#### Fitting LDA Models

<u>Using Cross-validation:</u>

```{r, message=FALSE, warning=FALSE}
CV8<-function(data, fold, output)
{
  set.seed(35)

  n=nrow(data)
  index=sample(n,n)
  l<-vector("list")
  model2<-c()

  group=cut(index, breaks = fold, labels =FALSE)
  accuracy=c()
  
  for( j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model2=lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=train, family=binomial)
    lda.pred=predict(model2,data[test,]) 
    
    #CLASS PREDICTION
    lda.class=lda.pred$class 
    #ACCURACY = TEST CORRECT RATE
    accuracy[j]<-mean(lda.class==Class[test])
  }
  
 l=list(model2,accuracy);return(l)
}

l15<-vector("list")

for(gene in 1:number)
  l15[[length(l15)+1]] <- CV8(DATASET,100,Class)
names(l15) <- colnames(DATASET[1:number])

matrix_accuracy <- sapply(l15, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means15 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means15)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means15)
```

<u>Using Bootsrapping:</u> 

```{r, warning=FALSE,message=FALSE}
BT28 <- function(data,Y,R,percent) { 
  set.seed(36)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  l<-vector("list")
  model2<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an lda model on train data
    model2 <- lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=new_train_indices, family=binomial)

    #5) How well does this model perform on the test data? 
    lda.pred=predict(model2,data[test_indices,]) 

    #6)In order to make a prediction, convert these predicted probabilities into class labels: 0 or 1 - CLASS PREDICTION
    lda.class=lda.pred$class 

    #7) calculate a new ESTIMATED TEST ERROR RATE using mean() - ACCURACY = TEST CORRECT RATE
    accuracy[i]<-mean(lda.class==Class[test_indices])
  }
  l <- list(model2,accuracy); return(l)
}

l16<-vector("list")

for(gene in 1:number)
  l16[[length(l16)+1]] <- BT28(DATASET,Class,100,30) 
names(l16) <- colnames(DATASET[1:number])

matrix_accuracy <- sapply(l16, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means16 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means16)*100, 2),nsmall=2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means16)
```

#### Fitting SVM Model Using Linear Kernel

<div style="text-align: justify">The support vector machine (SVM) is an extension of the support vector classifier that results from enlarging the feature space using kernels to accommodate a non-linear boundary between classes. Fitting svm model whereby the predictors are the following: ONLY one highly correlated gene, all the non highly correlated genes and the gestational age predictor.</div><br/>

```{r, warning=FALSE,message=FALSE}
BT29 <- function(data,Y,R,percent) { 
  set.seed(37)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out1 <- tune.svm(Class ~ . - `4317_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`-`932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`-`3493_at`- `710_at`- `3437_at`- `100288486_at`-`3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `677800_at`-`100033427_at`-`28526_at`- `219333_at`- `3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`, data=data[new_train_indices,],type="C-classification",kernel="linear",cost = 10^(-2:3))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out1$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out1,accuracy);return(l)
}

ans21 <- BT29(DATASET,Class,100,30) 
cat("The best cost value is equal to",ans21[[1]]$best.parameters$cost)
cat("The accuracy is equal to",format(round(mean(ans21[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Radial Kernel

```{r, warning=FALSE,message=FALSE}
BT30 <- function(data,Y,R,percent) { 
  set.seed(38)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out2 <- tune.svm(Class ~ . - `105377884_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`-`932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`-`3493_at`- `710_at`- `3437_at`- `100288486_at`-`3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `677800_at`-`100033427_at`-`28526_at`- `219333_at`- `3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`, data=data[new_train_indices,],type="C-classification",kernel="radial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out2$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out2,accuracy)
  return(l)
}

ans22 <- BT30(DATASET,Class,100,30) 
cat("The best cost value is equal to",ans22[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans22[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans22[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 2)

```{r, warning=FALSE,message=FALSE}
BT31 <- function(data,Y,R,percent) { 
  set.seed(39)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class ~ . - `105377884_at`- `4317_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`-`932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`-`3493_at`- `710_at`- `3437_at`- `100288486_at`-`3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `677800_at`-`100033427_at`-`28526_at`- `219333_at`- `3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`, data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 2)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy)
  return(l)
}

ans23 <- BT31(DATASET,Class,100,30) 
cat("The best cost value is equal to",ans23[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans23[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans23[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 3)

```{r, warning=FALSE,message=FALSE}
BT32 <- function(data,Y,R,percent) { 
  set.seed(40)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class ~ . - `105377884_at`- `4317_at`- `10964_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`-`932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`-`3493_at`- `710_at`- `3437_at`- `100288486_at`-`3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `677800_at`-`100033427_at`-`28526_at`- `219333_at`- `3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`, data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 3)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy);return(l)
}

ans24 <- BT32(DATASET,Class,100,30) 
cat("The best cost value is equal to",ans24[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans24[[1]]$best.parameters$gamma)
cat("The highest accuracy is equal to",format(round(mean(ans24[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Sigmoid Kernel

```{r, warning=FALSE,message=FALSE}
BT33 <- function(data,Y,R,percent) { 
  set.seed(41)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out4 <- tune.svm(Class ~ . - `105377884_at`- `4317_at`- `10964_at`- `3123_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`-`932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`-`3493_at`- `710_at`- `3437_at`- `100288486_at`-`3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `677800_at`-`100033427_at`-`28526_at`- `219333_at`- `3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`, data=data[new_train_indices,],type="C-classification",kernel="sigmoid",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out4$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out4,accuracy)
  return(l)
}

ans25 <- BT33(DATASET,Class,100,30) 
cat("The best cost value is equal to",ans25[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans25[[1]]$best.parameters$gamma)
cat("The highest accuracy is equal to",format(round(mean(ans25[[2]])*100, 2),nsmall=2),"\n")
```

### Choosing The Best Model

<div style="text-align: justify">I will now compare the accuracies between the models having highest accuracies.<br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x5 <- matrix(nrow = 9,ncol = 3,byrow = F)
colnames(x5) <- c("Highest Accuracy","Cost","Gamma")
rownames(x5) <- c("GLM using CV","GLM using BT","LDA using CV", "LDA using BT", "SVM with linear kernel", "SVM with radial kernel", "SVM with polynomial kernel (degree 2)", "SVM with polynomial kernel (degree 3)", "SVM with sigmoid kernel")
x5[1,1] <- max(col_means13)*100;x5[1,2] <-"-";x5[1,3] <-"-"
x5[2,1] <- max(col_means14)*100;x5[2,2] <-"-";x5[2,3] <-"-"
x5[3,1] <- max(col_means15)*100;x5[3,2] <-"-";x5[3,3] <-"-"
x5[4,1] <- max(col_means16)*100;x5[4,2] <-"-";x5[4,3] <-"-"
x5[5,1] <- mean(ans21[[2]])*100;x5[5,2] <-ans21[[1]]$best.parameters$cost;x5[5,3] <-"-"
x5[6,1] <- mean(ans22[[2]])*100;x5[6,2] <-ans22[[1]]$best.parameters$cost;x5[6,3] <-ans22[[1]]$best.parameters$gamma
x5[7,1] <- mean(ans23[[2]])*100;x5[7,2] <-ans23[[1]]$best.parameters$cost;x5[7,3] <-ans23[[1]]$best.parameters$gamma
x5[8,1] <- mean(ans24[[2]])*100;x5[8,2] <-ans24[[1]]$best.parameters$cost;x5[8,3] <-ans24[[1]]$best.parameters$gamma
x5[9,1] <- mean(ans25[[2]])*100;x5[9,2] <-ans25[[1]]$best.parameters$cost;x5[9,3] <-ans25[[1]]$best.parameters$gamma
var <- as.table(x5); knitr::kable(var)

names<-rownames(x5)   
m5<-names[which(x5==max(x5))]
a5<-max(x5[,1])
cat("The model(s) having the highest accuracy is(are)",m5,"\n")
cat("The highest accuracy is equal to",a5,"\n")
```

Now, I'll predict PTB on the test/predicting dataset.</div><br />

```{r, warning=FALSE,message=FALSE}
lda_probability <- predict(l15[[which.max(col_means15)]][[1]], newdata = prediction_dataset) 
```

## Binary Analysis (PPROM v/s Control)

```{r,warning=FALSE,echo=FALSE,message=FALSE}
train_dataset <- DF_2[DF_2$Train==1,-c(which(colnames(DF_2)=="Train"),which(colnames(DF_2)=="Individual"))] #This dataset contains mainly the observations present in the dataset classified as either sPTD, PPROM or control.
prediction_dataset <- DF_2[DF_2$Train==0,-c(which(colnames(DF_2)=="Train"),which(colnames(DF_2)=="Individual"))] #This dataset contains mainly the observations present in the dataset not classified in either class.
```

### Some Initial Statistics

```{r, message=FALSE, warning=FALSE}
#assign ur data frame to a new variable.
train_backup <- train_dataset 
cat("The dimension of this dataframe is",dim(train_backup),"\n")

#the type of each column
classes <- lapply(train_backup,class) 
cat("\nPrint the first six columns of the dataframe.\n")
head(classes)
cat("Print the last six predictors of the dataframe.\n")
tail(classes)

#With this dataset, the summary() function will not useful since I have a large number of predictors.
```

<div style="text-align: justify">This table summarizes the number of numerical/categorical/logical predictors.</div>

```{r, message=FALSE, echo=FALSE,warning=FALSE}
n=0;c=0; a <- sapply(train_backup, is.numeric); for (i in 1:dim(train_backup)[2]){if(a[i]==TRUE){n=n+1}else{c=c+1}}
#ct <- length(Filter(is.factor, train_backup))
lg <- length(Filter(is.logical, train_backup))

O <- matrix(nrow = 4,ncol = 1) #matrix 1
colnames(O) <- "Count"
rownames(O) <- c("Numeric Variable(s)","Factor Predictor(s)","Logical Column(s)","Total")
O[1,] <- n; O[2,] <- c; O[3,] <- lg; O[4,] <- c+n+lg
riable1 <- as.table(O); knitr::kable(riable1)
```

### Identification Of Missing Values

<div style="text-align: justify">Some columns may present missing values. What I need to do is to identify them first and if present, I need to remove them and replace them with real values.

```{r, message=FALSE,echo=FALSE,warning=FALSE}
question_marks <- which(train_backup=="?",arr.ind = T)  

NA_values <- which(is.na(train_backup), arr.ind=T)

NaN_values <- which(apply(train_backup, 2, function(x) all(is.nan(x))))

infinite_values <- which(apply(train_backup, 2, function(x) all(is.infinite(x))))

blanck_values <- function (x) {sum(x=="") }
bvalues <- apply(train_backup, 2,blanck_values); bvalues<-as.character(bvalues);count<-0
for(index in 1:length(bvalues)){
  if(bvalues[index]!=0){
    count=count+1 } }
```

This table summarizes the different types of missing values.</div><br />

```{r, message=FALSE, echo=FALSE,warning=FALSE}
x <- matrix(nrow = 5,ncol = 1,byrow = F)
colnames(x) <- c("Count")
rownames(x) <- c("Question marks","NA values","NaN values","Infinite values","Blank values")
tot <- dim(question_marks)[1]+dim(NA_values)[1]+length(NaN_values)+length(infinite_values)+count
x[1,1] <- dim(question_marks)[1]
x[2,1] <- dim(NA_values)[1]
x[3,1] <- length(NaN_values)
x[4,1] <- length(infinite_values)
x[5,1] <- tot
var <- as.table(x); knitr::kable(var)
```

### About The Class Predictor

```{r, message=FALSE, echo=FALSE,warning=FALSE}
#table of class
cat("The distribution of the 3 groups in the Class attribute")
table(train_backup$Class)
```

Removing the sPTD class.

```{r, message=FALSE, echo=FALSE,warning=FALSE}
train_backup <- train_backup[-which(train_backup$Class == "sPTD"),]
table(train_backup$Class)

train_backup$Class <- droplevels(train_backup$Class)
table(train_backup$Class) #nber of occurence in class

cat("The two groups are:",levels(train_backup$Class),"\nWhereby:\n 0 means Control\n 1 means PPROM (preterm premature rupture of membranes)\nLet's calculate the frequency of each subclass.")

control <- length(which(train_backup$Class=="Control"))
PPROM <- length(which(train_backup$Class=="PPROM"))

per_control <- control/length(train_backup$Class)*100
per_PPROM <- PPROM/length(train_backup$Class)*100

cat("The percentage of the control group is",format(round(per_control, 2), nsmall = 2),"\n")
cat("The percentage of the sPTD group is",format(round(per_PPROM, 2), nsmall = 2),"\n")
```

### Some Representative Plots

<div style="text-align: justify">The pairs plot cannot be done at all because the presence of at most 29k predictors will be invisible in such kind of plot.</div> 

#### Frequency Plot

<div style="text-align: justify">ggplot2 is a data visualization package for the statistical programming language R.</div> <br />

```{r, message=FALSE, echo=FALSE,warning=FALSE}
ggplot(data=train_backup, aes(x=Class,  fill=Class))  + geom_bar() +  scale_x_discrete(name = 'Class',labels=labs) + theme_bw() + ggtitle("The occurence of each level in the categorical variable")
```

#### Correlogram

<div style="text-align: justify">Let's examine the correlation between some continuous variables present in the same dataframe. This is conveniently implemented using the ggcorrplot package. Correlation coefficients are used to measure the strength of the relationship between two variables. When the value of correlation coefficient is close to zero, generally between -0.1 and +0.1, the variables are said to have no linear relationship or a very weak linear relationship.</div> 

```{r, message=FALSE, echo=FALSE,warning=FALSE}
ggcorrplot(round(cor(train_backup[c(1:16)]), 1), hc.order = TRUE,type = "full",lab = TRUE,lab_size = 3,method="circle",colors= c("tomato2", "white", "springgreen3"), title="Correlogram between the first 16 gene ids",ggtheme=theme_bw)
```

### Correlation Analysis

```{r, warning=FALSE,message=FALSE}
var <- cor(train_backup[1:300]) #correlation
var[lower.tri(var)] <- NA #replaces values in lower triangular matrix to NA
var[is.na(var)] <- 0 #then replace the NA to 0
diag(var)<-0 #replace values in the diagonal equals to 1 to 0
df <- as.data.frame(var) #change the class of df to a dataframe
df[df>=1] <- 0 #replace all values bigger than 1 to by 0
fct <- apply(df,2,max) #get the max value from each column
m <- as.matrix(fct) #save the fct as a matrix in a new variable called m
```

<div style="text-align: justify">Let's zoom in and visualize the highly correlated and the non highly correlated genes.</div><br />

```{r, warning=FALSE,,message=FALSE}
#get the highly correlated genes->having a correlation coefficient above 70%
highly_correlated_genes <- m[m[,1] > 0.70,]
highly_correlated_genes <- as.matrix(highly_correlated_genes)
cat("The number of highly correlated genes equals to",length(highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(highly_correlated_genes))

#get the non highly correlated genes->having a correlation coefficient below 70%
not_highly_correlated_genes <- m[m[,1] <= 0.70,]
not_highly_correlated_genes <- as.matrix(not_highly_correlated_genes)
cat("The number of non highly correlated genes equals to",length(not_highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(not_highly_correlated_genes))
```

### Building Models

<div style="text-align: justify">The categorical predictor has two levels: Control is the first level and PPROM is the second one.

```{r, message=FALSE, warning=FALSE}
DATASET2 <- train_backup
levels(DATASET2$Class)
levels(DATASET2$Class) <- c(0,1); levels(DATASET2$Class)
attach(DATASET2)
number<-dim(DATASET2)[2]-2 
```

<u>Analysis methods that I might consider for predicting preterm birth:</u><br />
Firstly, I will build generalized linear models.<br />
Secondly, I will move on to linear discriminant analysis.<br />
Thirdly, I will build several support vector machine models using different kernels.</div> <br />

#### Fitting GLM Models

<u>Using Cross-validation:</u> 

```{r, message=FALSE, warning=FALSE}
CV9<-function(data,fold,Y)
{
  n=nrow(data)
  
  set.seed(26)
  index=sample(n,n)
  l<-vector("list")
  model<-c()

  group=cut(index, breaks = fold, labels =FALSE)
  pval=c();accuracy=c()
  for( j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model=glm(Class~data[,gene]+data[,which(colnames(data)=="GA")],data=data, subset=train, family=binomial)
    pval[j]= summary(model)$coef[2,4] #get the pvalue 
    glm.pred=predict(model,data[test,],type="response")
    
    glm.prob=rep(0,nrow(data))
    glm.prob[glm.pred >.5]=1
    accuracy[j]=mean(glm.prob==Class[test]) 
  }
  
 l=list(model,pval,accuracy);return(l)
}

l17<-vector("list")

for(gene in 1:number)
  l17[[length(l17)+1]]<- CV9(DATASET2,100,Class)
names(l17) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l17, "[[", 3)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means17 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means17)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means17)
```

<div style="text-align: justify"><u>P_value Interpretability</u><br />
In statistics, the p-value is the probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. A p-value less than or equal to 0.05 is statistically significant. It indicates a strong evidence against the null hypothesis. Therefore, I will reject the null hypothesis and accept the alternative hypothesis.<br />

```{r, warning=FALSE,message=FALSE}
#retrieving all the pvalues from the list 
matrix_pval1 <- sapply(l17, "[[", 2); matrix_pval1 <- as.data.frame(matrix_pval1)
df_pval1 <- apply(matrix_pval1, 2, mean)
dF1 <- as.data.frame(t(df_pval1))
c<-0; vec <- c(); vec1 <- c()
for(i in 1:dim(dF1)[2]){
  if(dF1[i]<0.05){
    c<-c+1 
    vec <- c(vec,names(dF1[i]))
    vec1 <- c(vec1,as.character(dF1)[i])
  }
}
```

```{r, warning=FALSE,echo=FALSE,message=FALSE}
o <- matrix(nrow = 3,ncol = 1); o[1,1] <- c; o[2,1]<-dim(dF1)[2]-c; o[3,1] <- dim(dF1)[2]
rownames(o)<-c("True Positive","False Positive","Total Number Of Genes"); colnames(o)<-c("Count")
var <- as.table(o); knitr::kable(var)
```

This table shows how many genes are statistically significants and how many are not based on p-values. A true positive is an outcome where the model correctly predicts the positive class; however, a false positive is an outcome where the model incorrectly predicts the positive class.</div> <br />

```{r, warning=FALSE,echo=FALSE,message=FALSE}
if(o[1,1] > 0){
  cat("Now let's zoom in and visualize which genes are statistically significant.\n")
  k<-matrix(nrow = length(vec),ncol = 2); k[,1]<-vec; k[,2]<-vec1
  colnames(k)<-c("Gene_Ids","P_value"); rownames(k)<-c(1:length(vec))
  backup_k <- k; var2 <- as.data.frame(backup_k) #max(as.character(var2$P_value))
  variable2 <- as.table(k); knitr::kable(variable2) }
```

<u>Using Bootsrapping:</u>

```{r, message=FALSE, warning=FALSE}
BT34 <- function(data,Y,R,percent) { 
  set.seed(42)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  pval<-rep(1,R)
  l <- vector("list",1) #creation of empty list
  model<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    model=glm(Class~data[,gene]+data[,which(colnames(data)=="GA")],data=data, subset=new_train_indices, family=binomial)
    pval[i]= summary(model)$coef[2,4] #get the pvalue 
    glm.pred=predict(model,data[test_indices,],type="response")
    
    glm.prob=rep(0,nrow(data))
    glm.prob[glm.pred >.5]=1
    accuracy[i]=mean(glm.prob==Class[test_indices]) 
  }
  l <- list(model,pval,accuracy); return(l)
}

l18<-vector("list")

for(gene in 1:number)
  l18[[length(l18)+1]] <- BT34(DATASET2,Class,100,30) 
names(l18) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l18, "[[", 3)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means18 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means18)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means18)
```

<div style="text-align: justify"><u>P_value Interpretability</u><br />
In statistics, the p-value is the probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. A p-value less than or equal to 0.05 is statistically significant. It indicates a strong evidence against the null hypothesis. Therefore, I will reject the null hypothesis and accept the alternative hypothesis.<br />

```{r, warning=FALSE,message=FALSE}
#retrieving all the pvalues from the list 
matrix_pval1 <- sapply(l18, "[[", 2); matrix_pval1 <- as.data.frame(matrix_pval1)
df_pval1 <- apply(matrix_pval1, 2, mean)
dF1 <- as.data.frame(t(df_pval1))
c<-0; vec <- c(); vec1 <- c()
for(i in 1:dim(dF1)[2]){
  if(dF1[i]<0.05){
    c<-c+1 
    vec <- c(vec,names(dF1[i]))
    vec1 <- c(vec1,as.character(dF1)[i])
  }
}
```

```{r, warning=FALSE,echo=FALSE,message=FALSE}
o <- matrix(nrow = 3,ncol = 1); o[1,1] <- c; o[2,1]<-dim(dF1)[2]-c; o[3,1] <- dim(dF1)[2]
rownames(o)<-c("True Positive","False Positive","Total Number Of Genes"); colnames(o)<-c("Count")
var <- as.table(o); knitr::kable(var)
```

This table shows how many genes are statistically significants and how many are not based on p-values. A true positive is an outcome where the model correctly predicts the positive class; however, a false positive is an outcome where the model incorrectly predicts the positive class.</div> <br />

```{r, warning=FALSE,echo=FALSE,message=FALSE}
if(o[1,1] > 0){
  cat("Now let's zoom in and visualize which genes are statistically significant.\n")
  k<-matrix(nrow = length(vec),ncol = 2); k[,1]<-vec; k[,2]<-vec1
  colnames(k)<-c("Gene_Ids","P_value"); rownames(k)<-c(1:length(vec))
  backup_k <- k; var2 <- as.data.frame(backup_k) #max(as.character(var2$P_value))
  variable2 <- as.table(k); knitr::kable(variable2) }
```

#### Fitting LDA Models

<u>Using Cross-validation:</u>

```{r, message=FALSE, warning=FALSE}
CV10 <- function(data, fold, output)
{
  n=nrow(data)
  set.seed(27)
  index=sample(n,n)
  l<-vector("list")
  model2<-c()
  
  group=cut(index, breaks = fold, labels =FALSE)
  accuracy=c()
  
  for( j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model2=lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=train, family=binomial)
    lda.pred=predict(model2,data[test,]) 
    
    #CLASS PREDICTION
    lda.class=lda.pred$class 
    #ACCURACY = TEST CORRECT RATE
    accuracy[j]<-mean(lda.class==Class[test])
  }
  
 l=list(model2,accuracy);return(l)
}

l19<-vector("list")

for(gene in 1:number)
  l19[[length(l19)+1]] <- CV10(DATASET2,100,Class)
names(l19) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l19, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means19 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means19)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means19)
```

<u>Using Bootsrapping:</u>

```{r, warning=FALSE,message=FALSE}
BT35 <- function(data,Y,R,percent) { 
  set.seed(43)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  l<-vector("list")
  model2<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an lda model on train data
    model2 <- lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=new_train_indices, family=binomial)

    #5) How well does this model perform on the test data? 
    lda.pred=predict(model2,data[test_indices,]) 

    #6)In order to make a prediction, convert these predicted probabilities into class labels: 0 or 1 - CLASS PREDICTION
    lda.class=lda.pred$class 

    #7) calculate a new ESTIMATED TEST ERROR RATE using mean() - ACCURACY = TEST CORRECT RATE
    accuracy[i]<-mean(lda.class==Class[test_indices])
  }
  l <- list(model2,accuracy); return(l)
}

l20<-vector("list")

for(gene in 1:number)
  l20[[length(l20)+1]] <- BT35(DATASET2,Class,100,30) 
names(l20) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l20, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means20 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means20)*100, 2),nsmall=2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means20)
```

#### Fitting SVM Model Using Radial Kernel

```{r, warning=FALSE,message=FALSE}
bt37 <- function(data,Y,R,percent) { 
  set.seed(45)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out2 <- tune.svm(Class ~ . - `4317_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `343171_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at` -`28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`- `3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`, data=data[new_train_indices,],type="C-classification",kernel="radial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out2$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out2,accuracy);return(l)
}

ans27 <- bt37(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans27[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans27[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans27[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 2)

```{r, warning=FALSE,message=FALSE}
BT38 <- function(data,Y,R,percent) { 
  set.seed(46)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class  ~ . - `105377884_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `343171_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at` -`28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`- `3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`, data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 2)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy);return(l)
}

ans28 <- BT38(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans28[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans28[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans28[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 3)

```{r, warning=FALSE,message=FALSE}
BT39 <- function(data,Y,R,percent) { 
  set.seed(47)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class ~ . - `105377884_at`- `4317_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `343171_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at` -`28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`- `3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`, data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 3)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy);return(l)
}

ans29 <- BT39(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans29[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans29[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans29[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Sigmoid Kernel

```{r, warning=FALSE,message=FALSE}
BT40 <- function(data,Y,R,percent) { 
  set.seed(48)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out4 <- tune.svm(Class ~ . - `105377884_at`- `4317_at`- `10964_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `343171_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at` -`28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`- `3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`, data=data[new_train_indices,],type="C-classification",kernel="sigmoid",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out4$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out4,accuracy);return(l)
}

ans30 <- BT40(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans30[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans30[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans30[[2]])*100, 2),nsmall=2),"\n")
```

### Choosing The Best Model

<div style="text-align: justify">I will now compare the accuracies between the models having highest accuracies.<br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x6 <- matrix(nrow = 8,ncol = 3,byrow = F)
colnames(x6) <- c("Highest Accuracy","Cost","Gamma")
rownames(x6) <- c("GLM using CV","GLM using BT","LDA using CV", "LDA using BT", "SVM with radial kernel", "SVM with polynomial kernel (degree 2)", "SVM with polynomial kernel (degree 3)", "SVM with sigmoid kernel")
x6[1,1] <- max(col_means17)*100;x6[1,2] <- "-";x6[1,3] <- "-"
x6[2,1] <- max(col_means18)*100;x6[2,2] <- "-";x6[2,3] <- "-"
x6[3,1] <- max(col_means19)*100;x6[3,2] <- "-";x6[3,3] <- "-"
x6[4,1] <- max(col_means20)*100;x6[4,2] <- "-";x6[4,3] <- "-"
x6[5,1] <- mean(ans27[[2]])*100;x6[5,2] <- ans27[[1]]$best.parameters$cost;x6[5,3] <- ans27[[1]]$best.parameters$gamma
x6[6,1] <- mean(ans28[[2]])*100;x6[6,2] <- ans28[[1]]$best.parameters$cost;x6[6,3] <- ans28[[1]]$best.parameters$gamma
x6[7,1] <- mean(ans29[[2]])*100;x6[7,2] <- ans29[[1]]$best.parameters$cost;x6[7,3] <- ans29[[1]]$best.parameters$gamma
x6[8,1] <- mean(ans30[[2]])*100;x6[8,2] <- ans30[[1]]$best.parameters$cost;x6[8,3] <- ans30[[1]]$best.parameters$gamma
var <- as.table(x6); knitr::kable(var)

names<-rownames(x6)   
m6<-names[which(x6==max(x6))]
a6<-max(x6[,1])
cat("The model(s) having the highest accuracy is(are)",m6,"\n")
cat("The highest accuracy is equal to",a6,"\n")
```

Now, I'll predict PTB on the test/predicting dataset.</div><br />

```{r, warning=FALSE,,message=FALSE}
svm_probability <- predict(ans30[[1]]$best.model, newdata = prediction_dataset) 
```

## My Results

<div style="text-align: justify">I will find the best model between the 3 different set of prediction: Multiclass, sPTD v/s Control and PPROM v/s Control.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x3 <- matrix(nrow = 3,ncol = 2,byrow = F)
colnames(x3) <- c("Highest Accuracy","Best Model(s) Name")
rownames(x3) <- c("Multiclass Prediction","sPTD v/s Control Prediction","PPROM v/s Control Prediction")
x3[1,1] <- a4;x3[1,2]<-m4
x3[2,1] <- a5;x3[2,2]<-m5
x3[3,1] <- a6;x3[3,2]<-m6
var <- as.table(x3); knitr::kable(var)

names<-rownames(x3)
cat("The set of prediction having the highest accuracy is",names[which(x3[,1]==max(x3[,1]))],"\n")
cat("The highest accuracy is equal to",format(round(as.numeric(max(x3[,1])), 2),nsmall=2),"\n")
```

## The Project's Results

<div style="text-align: justify">This table shows in a decrease order the accuracies of the models of all participants as well as my best model's accuracy for predicting preterm birth in asymptomatic women.<br/>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
data1 <- read.table("/Users/oliverabinader/Desktop/acc_results.txt",header = T,sep=" ")

data1[100,] <- as.numeric(max(x3[,1]))/100
data1 <- apply(data1, 1, function(x) 100*x)

m <- sort(data1, decreasing = TRUE)
d <- as.data.frame(m)
colnames(d) <- "Accuracy"; rownames(d) <- 1:nrow(d)
rownames(d)[rownames(d) == which(d$Accuracy == as.numeric(max(x3[,1])))] <- "Oliver" 

knitr::kable(d)
```

**I can finally see that I am classified as the second participant in this project. Part B was taking a dataset that contains at most 300 gene ids.**

<u>**PART II C - PREDICTING PRETERM BIRTH using the first 500 columns.**</u></div><br/>

# Third Dataset

<div style="text-align: justify">*Third, I am going to use the dataset containing the first 500 columns from object number 1 with some additional columns(GA,Group,IndividualID and Train) from the second object.*</div>

## The Combined Dataset

```{r, message=FALSE, warning=FALSE}
data <- reduced_dat_500

#the additional columns
data$Class <- backup1$Group
data$GA <- backup1$GA
data$Individual <- backup1$IndividualID
data$Train <- backup1$Train

#indices of obvs (one sample per patient) to be used
odd <- seq(1,by=2, len=166)
dd=odd[1:166]
dd=c(dd,333,337,339,343,347,350,353,357,361,364,368,372,376,380,383,387,390,393,396,398,401,403,406,409,412,417,421,425,428,431)
DF1 <- data[dd,]
```

<div style="text-align: justify">I'll divide the original dataset into two datasets. The train_dataset is used to build models whereas the prediction_dataset is use to predict preterm birth.</div><br />

## Multiclass Analysis

```{r,warning=FALSE,echo=FALSE,message=FALSE}
train_dataset <- DF1[DF1$Train==1,-c(which(colnames(DF1)=="Train"),which(colnames(DF1)=="Individual"))] #This dataset contains mainly the observations present in the dataset classified as either sPTD, PPROM or control.
prediction_dataset <- DF1[DF1$Train==0,-c(which(colnames(DF1)=="Train"),which(colnames(DF1)=="Individual"))] #This dataset contains mainly the observations present in the dataset not classified in either class.
```

### Some Initial Statistics

```{r, message=FALSE, warning=FALSE}
#assign ur data frame to a new variable.
train_backup <- train_dataset 
cat("The dimension of this dataframe is",dim(train_backup),"\n")
cat("The number of rows is",dim(train_backup)[1],"\nThe number of attributes is",dim(train_backup)[2],"\n")
```

### Identification Of Missing Values

<div style="text-align: justify">Some columns may present missing values. What I need to do is to identify them first and if present, I need to remove them and replace them with real values.

```{r, message=FALSE, warning=FALSE}
question_marks <- which(train_backup=="?",arr.ind = T)  

NA_values <- which(is.na(train_backup), arr.ind=T)

NaN_values <- which(apply(train_backup, 2, function(x) all(is.nan(x))))

infinite_values <- which(apply(train_backup, 2, function(x) all(is.infinite(x))))

blanck_values <- function (x) {sum(x=="") }
bvalues <- apply(train_backup, 2,blanck_values); bvalues<-as.character(bvalues);count<-0
for(index in 1:length(bvalues)){
  if(bvalues[index]!=0){
    count=count+1 } }
```

This table summarizes the different types of missing values.</div><br />

```{r, message=FALSE, echo=FALSE,warning=FALSE}
x <- matrix(nrow = 5,ncol = 1,byrow = F)
colnames(x) <- c("Count")
rownames(x) <- c("Question marks","NA values","NaN values","Infinite values","Blank values")
tot <- dim(question_marks)[1]+dim(NA_values)[1]+length(NaN_values)+length(infinite_values)+count
x[1,1] <- dim(question_marks)[1]
x[2,1] <- dim(NA_values)[1]
x[3,1] <- length(NaN_values)
x[4,1] <- length(infinite_values)
x[5,1] <- tot
var <- as.table(x); knitr::kable(var)
```

### Checking Data Normalization

<div style="text-align: justify">I will do the shapiro test to check for normality, which can only be done on the numerical predictors.There are several methods for normality test such as Kolmogorov-Smirnov (K-S) normality test and Shapiro-Wilks test.</div><br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
numerical_predictor<-c() #a vector that will contain all the numerical predictors indicies
count2<-1 
for(i in 1:ncol(train_backup))  { # for loop to get all the numerical predictors indicies
  if(is.numeric(train_backup[,i])==TRUE) {
    numerical_predictor[count2]<-i
    count2<-count2+1 }
}

#if u apply the shapiro test on the numercical predictors, u'll then get their p_values and save them in a variable called p_val
p_val<-c()
test<-vector("list",1)
for(i in 1: length(numerical_predictor)) {
  test[[i]]<-shapiro.test(train_backup[,numerical_predictor[i]])
  p_val[i]<-test[[i]]$p.value
}

normal<-which(p_val<0.05) #Since pval is less than 5%, hence accepting the null hypothesis means the data is normally distributed. However, rejecting the null hypothesis means the data will not normally distributed.

n<-(dim(train_backup)[2])-length(normal)
d<-length(normal)

cat("The number of columns that are not normally distributed is:",n,"\n")
cat("The number of columns that are normally distributed is:",d,"\n")
```

### About The Class Predictor

```{r, message=FALSE,echo=FALSE,warning=FALSE}
#table of class
cat("The distribution of the 3 groups in the Class attribute")
table(train_backup$Class)

cat("The 3 groups are:",levels(train_backup$Class),"\nWhereby:\n 0 means Control\n 1 means PPROM (preterm premature rupture of membranes)\n 2 means sPTD (spontaneous preterm labor and delivery with intact membranes)\nLet's calculate the frequency of each subclass.")

control <- length(which(train_backup$Class=="Control"))
PPROM <- length(which(train_backup$Class=="PPROM"))
sPTD <- length(which(train_backup$Class=="sPTD"))

per_control <- control/length(train_backup$Class)*100
per_PPROM <- PPROM/length(train_backup$Class)*100
per_sPTD <- sPTD/length(train_backup$Class)*100

cat("The percentage of the control group is",format(round(per_control, 2), nsmall = 2),"\n")
cat("The percentage of the PPROM group is",format(round(per_PPROM, 2), nsmall = 2),"\n")
cat("The percentage of the sPTD group is",format(round(per_sPTD, 2), nsmall = 2),"\n")
```

### Some Representative Plots 
<div style="text-align: justify">The pairs plot cannot be done at all because the presence of at most 29k predictors will be invisible in such kind of plot.</div> 

#### Frequency Plot
<div style="text-align: justify">ggplot2 is a data visualization package for the statistical programming language R.</div> 

```{r, message=FALSE,echo=FALSE,warning=FALSE}
ggplot(data=train_backup, aes(x=Class,  fill=Class))  + geom_bar() +  scale_x_discrete(name = 'Class',labels=labs) + theme_bw() + ggtitle("The occurence of each level in the categorical variable")
```

#### Scatterplot
<div style="text-align: justify">A scatter plot is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data. This plot shows the distribution of gestational age in each of the classes.</div><br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
#plot class v/s GA
ggplot(train_backup,aes(Class,GA)) +labs(title = "Scatterplot of the class across the gestational ages as determined by the last menstrual period or ultrasound") +geom_point()
```

### Correlation Analysis

```{r, warning=FALSE,message=FALSE}
var <- cor(train_backup[1:500]) #correlation
var[lower.tri(var)] <- NA #replaces values in lower triangular matrix to NA
var[is.na(var)] <- 0 #then replace the NA to 0
diag(var)<-0 #replace values in the diagonal equals to 1 to 0
df <- as.data.frame(var) #change the class of df to a dataframe
df[df>=1] <- 0 #replace all values bigger than 1 to by 0
fct <- apply(df,2,max) #get the max value from each column
m <- as.matrix(fct) #save the fct as a matrix in a new variable called m
```

<div style="text-align: justify">Let's zoom in and visualize the highly correlated and the non highly correlated genes.</div><br/>

```{r, warning=FALSE,message=FALSE}
#get the highly correlated genes->having a correlation coefficient above 70%
highly_correlated_genes <- m[m[,1] > 0.70,]
highly_correlated_genes <- as.matrix(highly_correlated_genes)
cat("The number of highly correlated genes equals to",length(highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(highly_correlated_genes))

#get the non highly correlated genes->having a correlation coefficient below 70%
not_highly_correlated_genes <- m[m[,1] <= 0.70,]
not_highly_correlated_genes <- as.matrix(not_highly_correlated_genes)
cat("The number of non highly correlated genes equals to",length(not_highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(not_highly_correlated_genes))
```

### Building Models

<div style="text-align: justify">The categorical predictor has thrre levels: Control is the first level, PPROM is the second one and sPTD is the third one.

```{r, message=FALSE, warning=FALSE}
DATASET2 <- train_backup
levels(DATASET2$Class)
levels(DATASET2$Class) <- c(0,1,2); levels(DATASET2$Class)
attach(DATASET2)
number<-dim(DATASET2)[2]-2
```

<u>Analysis method that I might consider for predicting preterm birth:</u><br />
First, I will build linear discriminant analysis models.<br />
Second, I will build support vector machine models using distinct kernels.<br /></div>

#### Fitting LDA Models

<u>Using Cross-validation:</u> 

```{r, message=FALSE, warning=FALSE}
CV11 <- function(data, fold, output)
{
  set.seed(49)

  n=nrow(data)
  index=sample(n,n)
  l<-vector("list")
  model2<-c()

  group=cut(index, breaks = fold, labels =FALSE)
  accuracy=c()
  
  for( j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model2=lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=train, family=miltinomial)
    lda.pred=predict(model2,data[test,]) 
    
    #CLASS PREDICTION
    lda.class=lda.pred$class 
    #ACCURACY = TEST CORRECT RATE
    accuracy[j]<-mean(lda.class==Class[test])
  }
  
 l=list(model2,accuracy);return(l)
}

l21<-vector("list")

for(gene in 1:number)
  l21[[length(l21)+1]] <- CV11(DATASET2,100,Class)
names(l21) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l21, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means21 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means21)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means21)
```

<u>Using Bootsrapping:</u>

```{r, warning=FALSE,message=FALSE}
BT42 <- function(data,Y,R,percent) { 
  set.seed(51)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  l <- vector("list") #creation of empty list
  model2<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an lda model on train data
    model2 <- lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=new_train_indices, family=multinomial)

    #5) How well does this model perform on the test data? 
    lda.pred=predict(model2,data[test_indices,]) 

    #6)In order to make a prediction, convert these predicted probabilities into class labels: 0 or 1 - CLASS PREDICTION
    lda.class=lda.pred$class 

    #7) calculate a new ESTIMATED TEST ERROR RATE using mean() - ACCURACY = TEST CORRECT RATE
    accuracy[i]<-mean(lda.class==Class[test_indices])
  }
  l <- list(model2,accuracy); return(l)
}

l22<-vector("list")

for(gene in 1:number)
  l22[[length(l22)+1]] <- BT42(DATASET2,Class,100,30) 
names(l22) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l22, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means22 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means22)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means22)
```

#### Fitting SVM Model Using Radial Kernel

<div style="text-align: justify">The support vector machine (SVM) is an extension of the support vector classifier that results from enlarging the feature space using kernels to accommodate a non-linear boundary between classes. Fitting svm model whereby the predictors are the following: ONLY one highly correlated gene, all the non highly correlated genes and the gestational age predictor.</div><br/>

```{r, warning=FALSE,message=FALSE}
BT44 <- function(data,Y,R,percent) { 
  set.seed(53)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l <- vector("list") #creation of empty list
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out2 <- tune.svm(Class ~ . -`105377884_at`- `4317_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`- `3493_at`- `710_at`- `3437_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`-`644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`- `3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `25907_at`- `24138_at`- `28946_at`- `28702_at`- `23365_at`- `100134229_at`- `101929007_at`- `54739_at`- `301_at`- `3042_at`- `441864_at`- `3568_at`- `3514_at`- `10398_at`- `760_at`- `597_at`- `3792_at`- `28442_at`- `8638_at`- `101927752_at`- `80127_at`- `28793_at`- `8520_at`- `5440_at`- `7443_at`- `23762_at`- `246_at`- `140_at`- `729870_at`- `105375878_at`- `28468_at`- `28479_at`- `28885_at`- `259215_at`- `2633_at`- `692073_at`- `64135_at`- `3145_at`- `7001_at`- `7504_at`- `5685_at`- `28938_at`- `8727_at`- `10498_at`- `28481_at`- `105372323_at`- `28814_at`- `3646_at`- `26799_at`- `728577_at`- `669_at`- `938_at`- `25893_at`- `286_at`- `6536_at`- `28726_at`-`83699_at`- `6510_at`- `9829_at`, data=data[new_train_indices,],type="C-classification",kernel="radial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out2$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out2,accuracy)
  return(l)
}

ans32 <- BT44(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans32[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans32[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans32[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 2)

```{r, warning=FALSE,message=FALSE}
BT45 <- function(data,Y,R,percent) { 
  set.seed(54)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l <- vector("list") #creation of empty list
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class ~ . -`105377884_at`- `4317_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `2537_at`- `2993_at`- `3494_at`-`644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`- `3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `25907_at`- `24138_at`- `28946_at`- `28702_at`- `23365_at`- `100134229_at`- `101929007_at`- `54739_at`- `301_at`- `3042_at`- `441864_at`- `3568_at`- `3514_at`- `10398_at`- `760_at`- `597_at`- `3792_at`- `28442_at`- `8638_at`- `101927752_at`- `80127_at`- `28793_at`- `8520_at`- `5440_at`- `7443_at`- `23762_at`- `246_at`- `140_at`- `729870_at`- `105375878_at`- `28468_at`- `28479_at`- `28885_at`- `259215_at`- `2633_at`- `692073_at`- `64135_at`- `3145_at`- `7001_at`- `7504_at`- `5685_at`- `28938_at`- `8727_at`- `10498_at`- `28481_at`- `105372323_at`- `28814_at`- `3646_at`- `26799_at`- `728577_at`- `669_at`- `938_at`- `25893_at`- `286_at`- `6536_at`- `28726_at`-`83699_at`- `6510_at`- `9829_at`, data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 2)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy)
  return(l)
}

ans33 <- BT45(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans33[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans33[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans33[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 3)

```{r, warning=FALSE,message=FALSE}
BT46 <- function(data,Y,R,percent) { 
  set.seed(55)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l <- vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class ~ . -`105377884_at`- `4317_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2993_at`- `3494_at`-`644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`- `3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `25907_at`- `24138_at`- `28946_at`- `28702_at`- `23365_at`- `100134229_at`- `101929007_at`- `54739_at`- `301_at`- `3042_at`- `441864_at`- `3568_at`- `3514_at`- `10398_at`- `760_at`- `597_at`- `3792_at`- `28442_at`- `8638_at`- `101927752_at`- `80127_at`- `28793_at`- `8520_at`- `5440_at`- `7443_at`- `23762_at`- `246_at`- `140_at`- `729870_at`- `105375878_at`- `28468_at`- `28479_at`- `28885_at`- `259215_at`- `2633_at`- `692073_at`- `64135_at`- `3145_at`- `7001_at`- `7504_at`- `5685_at`- `28938_at`- `8727_at`- `10498_at`- `28481_at`- `105372323_at`- `28814_at`- `3646_at`- `26799_at`- `728577_at`- `669_at`- `938_at`- `25893_at`- `286_at`- `6536_at`- `28726_at`-`83699_at`- `6510_at`- `9829_at`, data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 3)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy);return(l)
}

ans34 <- BT46(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans34[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans34[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans34[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Sigmoid Kernel

```{r, warning=FALSE,message=FALSE}
BT47 <- function(data,Y,R,percent) { 
  set.seed(56)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l <- vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out4 <- tune.svm(Class ~ . -`105377884_at`- `4317_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `160364_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `3494_at`-`644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`- `3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `25907_at`- `24138_at`- `28946_at`- `28702_at`- `23365_at`- `100134229_at`- `101929007_at`- `54739_at`- `301_at`- `3042_at`- `441864_at`- `3568_at`- `3514_at`- `10398_at`- `760_at`- `597_at`- `3792_at`- `28442_at`- `8638_at`- `101927752_at`- `80127_at`- `28793_at`- `8520_at`- `5440_at`- `7443_at`- `23762_at`- `246_at`- `140_at`- `729870_at`- `105375878_at`- `28468_at`- `28479_at`- `28885_at`- `259215_at`- `2633_at`- `692073_at`- `64135_at`- `3145_at`- `7001_at`- `7504_at`- `5685_at`- `28938_at`- `8727_at`- `10498_at`- `28481_at`- `105372323_at`- `28814_at`- `3646_at`- `26799_at`- `728577_at`- `669_at`- `938_at`- `25893_at`- `286_at`- `6536_at`- `28726_at`-`83699_at`- `6510_at`- `9829_at`,data=data[new_train_indices,],type="C-classification",kernel="sigmoid",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out4$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out4,accuracy)
  return(l)
}

ans35 <- BT47(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans35[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans35[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans35[[2]])*100, 2),nsmall=2),"\n")
```

### Choosing The Best Model

<div style="text-align: justify">I will now compare the accuracies between the models having highest accuracies.<br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x7 <- matrix(nrow = 6,ncol = 3,byrow = F)
colnames(x7) <- c("Highest Accuracy","Cost","Gamma")
rownames(x7) <- c("LDA using CV", "LDA using BT", "SVM with radial kernel", "SVM with polynomial kernel (degree 2)", "SVM with polynomial kernel (degree 3)", "SVM with sigmoid kernel")
x7[1,1] <- max(col_means21)*100;x7[1,2] <- "-";x7[1,3] <- "-"
x7[2,1] <- max(col_means22)*100;x7[2,2] <- "-";x7[2,3] <- "-"
x7[3,1] <- mean(ans32[[2]])*100;x7[3,2] <- ans32[[1]]$best.parameters$cost;x7[3,3] <- ans32[[1]]$best.parameters$gamma
x7[4,1] <- mean(ans33[[2]])*100;x7[4,2] <- ans33[[1]]$best.parameters$cost;x7[4,3] <- ans33[[1]]$best.parameters$gamma
x7[5,1] <- mean(ans34[[2]])*100;x7[5,2] <- ans34[[1]]$best.parameters$cost;x7[5,3] <- ans34[[1]]$best.parameters$gamma
x7[6,1] <- mean(ans35[[2]])*100;x7[6,2] <- ans35[[1]]$best.parameters$cost;x7[6,3] <- ans35[[1]]$best.parameters$gamma
var <- as.table(x7); knitr::kable(var)

names<-rownames(x7)
m7<-names[which(x7==max(x7))]
a7<-max(x7[,1])
cat("The model(s) having the highest accuracy is(are)",m7,"\n")
cat("The highest accuracy is equal to",a7,"\n")
```

Now, I'll predict PTB on the test/predicting dataset using the newdata argument.</div><br />

```{r, warning=FALSE,message=FALSE}
svm_probability <- predict(ans35[[1]]$best.model, newdata = prediction_dataset) 
```

## Binary Analysis (sPTD v/s Control)

```{r,warning=FALSE,echo=FALSE,message=FALSE}
train_dataset <- DF1[DF1$Train==1,-c(which(colnames(DF1)=="Train"),which(colnames(DF1)=="Individual"))] #This dataset contains mainly the observations present in the dataset classified as either sPTD, PPROM or control.
prediction_dataset <- DF1[DF1$Train==0,-c(which(colnames(DF1)=="Train"),which(colnames(DF1)=="Individual"))] #This dataset contains mainly the observations present in the dataset not classified in either class.
```

### Some Initial Statistics

```{r, message=FALSE, warning=FALSE}
#assign ur data frame to a new variable.
train_backup <- train_dataset 
cat("The dimension of this dataframe is",dim(train_backup),"\n")
```

<div style="text-align: justify">This table summarizes the number of numerical/categorical/logical predictors.</div>

```{r, message=FALSE, echo=FALSE,warning=FALSE}
n=0;c=0; a <- sapply(train_backup, is.numeric); for (i in 1:dim(train_backup)[2]){if(a[i]==TRUE){n=n+1}else{c=c+1}}
#ct <- length(Filter(is.factor, train_backup))
lg <- length(Filter(is.logical, train_backup))

O <- matrix(nrow = 4,ncol = 1) #matrix 1
colnames(O) <- "Count"
rownames(O) <- c("Numeric Variable(s)","Factor Predictor(s)","Logical Column(s)","Total")
O[1,] <- n; O[2,] <- c; O[3,] <- lg; O[4,] <- c+n+lg
riable1 <- as.table(O); knitr::kable(riable1)
```

### Identification Of Missing Values

<div style="text-align: justify">Some columns may present missing values. What I need to do is to identify them first and if present, I need to remove them and replace them with real values.

```{r, message=FALSE,echo=FALSE,warning=FALSE}
question_marks <- which(train_backup=="?",arr.ind = T)  

NA_values <- which(is.na(train_backup), arr.ind=T)

NaN_values <- which(apply(train_backup, 2, function(x) all(is.nan(x))))

infinite_values <- which(apply(train_backup, 2, function(x) all(is.infinite(x))))

blanck_values <- function (x) {sum(x=="") }
bvalues <- apply(train_backup, 2,blanck_values); bvalues<-as.character(bvalues);count<-0
for(index in 1:length(bvalues)){
  if(bvalues[index]!=0){
    count=count+1 } }
```

This table summarizes the different types of missing values.</div><br />

```{r, message=FALSE, echo=FALSE,warning=FALSE}
x <- matrix(nrow = 5,ncol = 1,byrow = F)
colnames(x) <- c("Count")
rownames(x) <- c("Question marks","NA values","NaN values","Infinite values","Blank values")
tot <- dim(question_marks)[1]+dim(NA_values)[1]+length(NaN_values)+length(infinite_values)+count
x[1,1] <- dim(question_marks)[1]
x[2,1] <- dim(NA_values)[1]
x[3,1] <- length(NaN_values)
x[4,1] <- length(infinite_values)
x[5,1] <- tot
var <- as.table(x); knitr::kable(var)
```

### About The Class Predictor

```{r, message=FALSE,echo=FALSE,warning=FALSE}
#table of class
cat("The distribution of the 3 groups in the Class attribute")
table(train_backup$Class)
```

Removing the PPROM class.

```{r, message=FALSE,echo=FALSE,warning=FALSE}
train_backup <- train_backup[-which(train_backup$Class == "PPROM"),]
table(train_backup$Class)

train_backup$Class <- droplevels(train_backup$Class)
table(train_backup$Class) #nber of occurence in class

cat("The two groups are:",levels(train_backup$Class),"\nWhereby:\n 0 means Control\n 1 means sPTD (spontaneous preterm labor and delivery with intact membranes)\nLet's calculate the frequency of each subclass.")

control <- length(which(train_backup$Class=="Control"))
sPTD <- length(which(train_backup$Class=="sPTD"))

per_control <- control/length(train_backup$Class)*100
per_sPTD <- sPTD/length(train_backup$Class)*100

cat("The percentage of the control group is",format(round(per_control, 2), nsmall = 2),"\n")
cat("The percentage of the sPTD group is",format(round(per_sPTD, 2), nsmall = 2),"\n")
```

### Some Representative Plots
<div style="text-align: justify">The pairs plot cannot be done at all because the presence of at most 29k predictors will be invisible in such kind of plot.</div> 

#### Frequency Plot
<div style="text-align: justify">ggplot2 is a data visualization package for the statistical programming language R.</div> 

```{r, message=FALSE,echo=FALSE,warning=FALSE}
ggplot(data=train_backup, aes(x=Class,  fill=Class))  + geom_bar() +  scale_x_discrete(name = 'Class',labels=labs) + theme_bw() + ggtitle("The occurence of each level in the categorical variable")
```

#### Correlogram

<div style="text-align: justify">Let's examine the correlation between some continuous variables present in the same dataframe. This is conveniently implemented using the ggcorrplot package. Correlation coefficients are used to measure the strength of the relationship between two variables. When the value of correlation coefficient is close to zero, generally between -0.1 and +0.1, the variables are said to have no linear relationship or a very weak linear relationship.</div> 

```{r, message=FALSE,echo=FALSE,warning=FALSE}
ggcorrplot(round(cor(train_backup[c(1:16)]), 1), hc.order = TRUE,type = "full",lab = TRUE,lab_size = 3,method="circle",colors= c("tomato2", "white", "springgreen3"), title="Correlogram between the first 16 gene ids",ggtheme=theme_bw)
```

### Correlation Analysis

```{r, warning=FALSE,message=FALSE}
var <- cor(DATASET2[1:500]) #correlation
var[lower.tri(var)] <- NA #replaces values in lower triangular matrix to NA
var[is.na(var)] <- 0 #then replace the NA to 0
diag(var)<-0 #replace values in the diagonal equals to 1 to 0
df <- as.data.frame(var) #change the class of df to a dataframe
df[df>=1] <- 0 #replace all values bigger than 1 to by 0
fct <- apply(df,2,max) #get the max value from each column
m <- as.matrix(fct) #save the fct as a matrix in a new variable called m
```

<div style="text-align: justify">Let's zoom in and visualize the highly correlated and the non highly correlated genes.</div><br />

```{r, warning=FALSE,message=FALSE}
#get the highly correlated genes->having a correlation coefficient above 70%
highly_correlated_genes <- m[m[,1] > 0.70,]
highly_correlated_genes <- as.matrix(highly_correlated_genes)
cat("The number of highly correlated genes equals to",length(highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(highly_correlated_genes))

#get the non highly correlated genes->having a correlation coefficient below 70%
not_highly_correlated_genes <- m[m[,1] <= 0.70,]
not_highly_correlated_genes <- as.matrix(not_highly_correlated_genes)
cat("The number of non highly correlated genes equals to",length(not_highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(not_highly_correlated_genes))
```

### Building Models

<div style="text-align: justify">The categorical predictor has two levels: Control is the first level and sPTD is the second one.

```{r, message=FALSE, warning=FALSE}
DATASET2 <- train_backup
levels(DATASET2$Class)
levels(DATASET2$Class) <- c(0,1); levels(DATASET2$Class)
attach(DATASET2)
number<-dim(DATASET2)[2]-2 
```

<u>Analysis methods that I might consider for predicting preterm birth:</u><br />
Firstly, I will build generalized linear models.<br />
Secondly, I will move on to linear discriminant analysis.<br />
Thirdly, I will build several support vector machine models using different kernels.</div> <br />

#### Fitting GLM Models

<u>Using Cross-validation:</u>

```{r, message=FALSE, warning=FALSE}
CV12<-function(data,fold,Y)
{
  set.seed(57)

  n=nrow(data)
  index=sample(n,n)
  l<-vector("list")
  model<-c()

  group=cut(index, breaks = fold, labels =FALSE)
  pval=c();accuracy=c()
  for( j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model=glm(Class~data[,gene]+data[,which(colnames(data)=="GA")],data=data, subset=train, family=binomial)
    pval[j]= summary(model)$coef[2,4] #get the pvalue 
    glm.pred=predict(model,data[test,],type="response")
    
    glm.prob=rep(0,nrow(data))
    glm.prob[glm.pred >.5]=1
    accuracy[j]=mean(glm.prob==Class[test]) 
  }
  
 l=list(model,pval,accuracy);return(l)
}

l23<-vector("list")

for(gene in 1:number)
  l23[[length(l23)+1]] <- CV12(DATASET2,100,Class)
names(l23) <- colnames(DATASET2[1:number])
matrix_accuracy <- sapply(l23, "[[", 3)

df_accuracy <- as.data.frame(matrix_accuracy)
col_means23 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means23)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means23)
```

<u>P_value Interpretability</u><br />
In statistics, the p-value is the probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. A p-value less than or equal to 0.05 is statistically significant. It indicates a strong evidence against the null hypothesis. Therefore, I will reject the null hypothesis and accept the alternative hypothesis.<br />

```{r, warning=FALSE,message=FALSE}
#retrieving all the pvalues from the list 
matrix_pval1 <- sapply(l23, "[[", 2); matrix_pval1 <- as.data.frame(matrix_pval1)
df_pval1 <- apply(matrix_pval1, 2, mean)
dF1 <- as.data.frame(t(df_pval1))
c<-0; vec <- c(); vec1 <- c()
for(i in 1:dim(dF1)[2]){
  if(dF1[i]<0.05){
    c<-c+1 
    vec <- c(vec,names(dF1[i]))
    vec1 <- c(vec1,as.character(dF1)[i])
  }
}
```

```{r, warning=FALSE,echo=FALSE,message=FALSE}
o <- matrix(nrow = 3 ,ncol =1); o[1,1] <- c; o[2,1]<-dim(dF1)[2]-c; o[3,1] <- dim(dF1)[2]
rownames(o)<-c("True Positive","False Positive","Total Number Of Genes"); colnames(o)<-c("Count")
var <- as.table(o); knitr::kable(var)
```

This table shows how many genes are statistically significants and how many are not based on p-values. A true positive is an outcome where the model correctly predicts the positive class; however, a false positive is an outcome where the model incorrectly predicts the positive class.<br />

```{r, warning=FALSE,echo=FALSE,message=FALSE}
if(o[1,1] > 0){
  cat("Now let's zoom in and visualize which genes are statistically significant.\n")
  k<-matrix(nrow = length(vec),ncol = 2); k[,1]<-vec; k[,2]<-vec1
  colnames(k)<-c("Gene_Ids","P_value"); rownames(k)<-c(1:length(vec))
  backup_k <- k; var2 <- as.data.frame(backup_k) #max(as.character(var2$P_value))
  variable2 <- as.table(k); knitr::kable(variable2) }
```

<u>Using Bootsrapping:</u>

```{r, message=FALSE, warning=FALSE}
BT48 <- function(data,Y,R,percent) { 
  set.seed(58)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  pval<-rep(1,R)
  l <- vector("list",1) #creation of empty list
  model<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    model=glm(Class~data[,gene]+data[,which(colnames(data)=="GA")],data=data, subset=new_train_indices, family=binomial)
    pval[i]= summary(model)$coef[2,4] #get the pvalue 
    glm.pred=predict(model,data[test_indices,],type="response")
    
    glm.prob=rep(0,nrow(data))
    glm.prob[glm.pred >.5]=1
    accuracy[i]=mean(glm.prob==Class[test_indices]) 
  }
  l <- list(model,pval,accuracy); return(l)
}

l24<-vector("list")

for(gene in 1:number)
  l24[[length(l24)+1]] <- BT48(DATASET2,Class,100,30) 
names(l24) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l24, "[[", 3)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means24 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means24)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means24)
```

<u>P_value Interpretability</u><br />
In statistics, the p-value is the probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. A p-value less than or equal to 0.05 is statistically significant. It indicates a strong evidence against the null hypothesis. Therefore, I will reject the null hypothesis and accept the alternative hypothesis.<br />

```{r, warning=FALSE,message=FALSE}
#retrieving all the pvalues from the list 
matrix_pval1 <- sapply(l24, "[[", 2); matrix_pval1 <- as.data.frame(matrix_pval1)
df_pval1 <- apply(matrix_pval1, 2, mean)
dF1 <- as.data.frame(t(df_pval1))
c<-0; vec <- c(); vec1 <- c()
for(i in 1:dim(dF1)[2]){
  if(dF1[i]<0.05){
    c<-c+1 
    vec <- c(vec,names(dF1[i]))
    vec1 <- c(vec1,as.character(dF1)[i])
  }
}
```

```{r, warning=FALSE,echo=FALSE,message=FALSE}
o <- matrix(nrow = 3 ,ncol =1); o[1,1] <- c; o[2,1]<-dim(dF1)[2]-c; o[3,1] <- dim(dF1)[2]
rownames(o)<-c("True Positive","False Positive","Total Number Of Genes"); colnames(o)<-c("Count")
var <- as.table(o); knitr::kable(var)
```

This table shows how many genes are statistically significants and how many are not based on p-values. A true positive is an outcome where the model correctly predicts the positive class; however, a false positive is an outcome where the model incorrectly predicts the positive class.<br />

```{r, warning=FALSE,echo=FALSE,message=FALSE}
if(o[1,1] > 0){
  cat("Now let's zoom in and visualize which genes are statistically significant.\n")
  k<-matrix(nrow = length(vec),ncol = 2); k[,1]<-vec; k[,2]<-vec1
  colnames(k)<-c("Gene_Ids","P_value"); rownames(k)<-c(1:length(vec))
  backup_k <- k; var2 <- as.data.frame(backup_k) #max(as.character(var2$P_value))
  variable2 <- as.table(k); knitr::kable(variable2) }
```

#### Fitting LDA Models

<u>Using Cross-validation:</u>

```{r, message=FALSE, warning=FALSE}
CV13 <- function(data, fold, output)
{
  n=nrow(data)
  set.seed(36)
  index=sample(n,n)
  l<-vector("list")

  group=cut(index, breaks = fold, labels =FALSE)
  accuracy=c()
  model2<-c()
  
  for( j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model2=lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=train, family=binomial)
    lda.pred=predict(model2,data[test,]) 
    
    #CLASS PREDICTION
    lda.class=lda.pred$class 
    #ACCURACY = TEST CORRECT RATE
    accuracy[j]<-mean(lda.class==Class[test])
  }
  
 l=list(model2,accuracy);return(l)
}

l25<-vector("list")
for(gene in 1:number)
  l25[[length(l25)+1]] <- CV13(DATASET2,100,Class)
names(l25) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l25, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means25 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means25)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means25)
```

<u>Using Bootsrapping:</u>

```{r, warning=FALSE,message=FALSE}
BT49 <- function(data,Y,R,percent) { 
  set.seed(59)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  l<-vector("list")
  model2<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an lda model on train data
    model2 <- lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=new_train_indices, family=binomial)

    #5) How well does this model perform on the test data? 
    lda.pred=predict(model2,data[test_indices,]) 

    #6)In order to make a prediction, convert these predicted probabilities into class labels: 0 or 1 - CLASS PREDICTION
    lda.class=lda.pred$class 

    #7) calculate a new ESTIMATED TEST ERROR RATE using mean() - ACCURACY = TEST CORRECT RATE
    accuracy[i]<-mean(lda.class==Class[test_indices])
  }
  l <- list(model2,accuracy); return(l)
}

l26<-vector("list")

for(gene in 1:number)
  l26[[length(l26)+1]] <- BT49(DATASET2,Class,100,30) 
names(l26) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l26, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means26 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means26)*100, 2),nsmall=2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means26)
```

#### Fitting SVM Model Using Radial Kernel

```{r, warning=FALSE,message=FALSE}
BT51 <- function(data,Y,R,percent) { 
  set.seed(61)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out2 <- tune.svm(Class ~ . - `105377884_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`-`4057_at`-`6037_at`- `671_at`-`4940_at`- `4973_at`- `160364_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`-`28959_at`- `4599_at`-`1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`-`104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`-`4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `677800_at`- `100033427_at`- `28526_at`- `219333_at`- `3001_at`- `1870_at`-`63893_at`- `2235_at`- `28452_at`- `24138_at`-`28946_at`- `23365_at`- `100134229_at`- `101929007_at`- `54739_at`- `301_at`- `3042_at`- `441864_at`- `3568_at`- `3514_at`- `10398_at`- `760_at`- `597_at`-`3792_at`- `28442_at`- `8638_at`- `101927752_at`- `80127_at`- `28793_at`- `8520_at`- `5440_at`- `7443_at`- `23762_at`- `246_at`- `140_at`- `729870_at`- `105375878_at`- `28468_at`- `28479_at`- `28885_at`- `259215_at`- `2633_at`- `692073_at`- `64135_at`- `3145_at`- `7001_at`- `7504_at`- `5685_at`- `28938_at`- `8727_at`- `10498_at`- `28481_at`- `105372323_at`- `389860_at`- `28814_at`- `3646_at`- `26799_at`- `728577_at`- `669_at`- `938_at`- `25893_at`- `286_at`-`6536_at`-`28726_at`- `83699_at`- `6510_at`- `9829_at` ,data=data[new_train_indices,],type="C-classification",kernel="radial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out2$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out2,accuracy)
  return(l)
}

ans37 <- BT51(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans37[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans37[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans37[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 2)

```{r, warning=FALSE,message=FALSE}
BT52 <- function(data,Y,R,percent) { 
  set.seed(62)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class ~ . - `105377884_at`- `4317_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`-`4057_at`-`6037_at`- `671_at`-`4940_at`- `4973_at`- `160364_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`-`28959_at`- `4599_at`-`1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`-`104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`-`4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `677800_at`- `100033427_at`- `28526_at`- `219333_at`- `3001_at`- `1870_at`-`63893_at`- `2235_at`- `28452_at`- `24138_at`-`28946_at`- `23365_at`- `100134229_at`- `101929007_at`- `54739_at`- `301_at`- `3042_at`- `441864_at`- `3568_at`- `3514_at`- `10398_at`- `760_at`- `597_at`-`3792_at`- `28442_at`- `8638_at`- `101927752_at`- `80127_at`- `28793_at`- `8520_at`- `5440_at`- `7443_at`- `23762_at`- `246_at`- `140_at`- `729870_at`- `105375878_at`- `28468_at`- `28479_at`- `28885_at`- `259215_at`- `2633_at`- `692073_at`- `64135_at`- `3145_at`- `7001_at`- `7504_at`- `5685_at`- `28938_at`- `8727_at`- `10498_at`- `28481_at`- `105372323_at`- `389860_at`- `28814_at`- `3646_at`- `26799_at`- `728577_at`- `669_at`- `938_at`- `25893_at`- `286_at`-`6536_at`-`28726_at`- `83699_at`- `6510_at`- `9829_at`, data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 2)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy); return(l)
}

ans38 <- BT52(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans38[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans38[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(ans38[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 3)

```{r, warning=FALSE,message=FALSE}
BT53 <- function(data,Y,R,percent) { 
  set.seed(63)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class ~ . - `105377884_at`- `4317_at`- `10964_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`-`4057_at`-`6037_at`- `671_at`-`4940_at`- `4973_at`- `160364_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`-`28959_at`- `4599_at`-`1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`-`104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`-`4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `677800_at`- `100033427_at`- `28526_at`- `219333_at`- `3001_at`- `1870_at`-`63893_at`- `2235_at`- `28452_at`- `24138_at`-`28946_at`- `23365_at`- `100134229_at`- `101929007_at`- `54739_at`- `301_at`- `3042_at`- `441864_at`- `3568_at`- `3514_at`- `10398_at`- `760_at`- `597_at`-`3792_at`- `28442_at`- `8638_at`- `101927752_at`- `80127_at`- `28793_at`- `8520_at`- `5440_at`- `7443_at`- `23762_at`- `246_at`- `140_at`- `729870_at`- `105375878_at`- `28468_at`- `28479_at`- `28885_at`- `259215_at`- `2633_at`- `692073_at`- `64135_at`- `3145_at`- `7001_at`- `7504_at`- `5685_at`- `28938_at`- `8727_at`- `10498_at`- `28481_at`- `105372323_at`- `389860_at`- `28814_at`- `3646_at`- `26799_at`- `728577_at`- `669_at`- `938_at`- `25893_at`- `286_at`-`6536_at`-`28726_at`- `83699_at`- `6510_at`- `9829_at`,data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 3)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy)
  return(l)
}

ans39 <- BT53(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans39[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans39[[1]]$best.parameters$gamma)
cat("The highest accuracy is equal to",format(round(mean(ans39[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Sigmoid Kernel

```{r, warning=FALSE,message=FALSE}
BT54 <- function(data,Y,R,percent) { 
  set.seed(64)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out4 <- tune.svm(Class ~ . - `105377884_at`- `4317_at`- `10964_at`- `3123_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`-`4057_at`-`6037_at`- `671_at`-`4940_at`- `4973_at`- `160364_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`-`28959_at`- `4599_at`-`1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`-`104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`- `28448_at`-`4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`- `7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `677800_at`- `100033427_at`- `28526_at`- `219333_at`- `3001_at`- `1870_at`-`63893_at`- `2235_at`- `28452_at`- `24138_at`-`28946_at`- `23365_at`- `100134229_at`- `101929007_at`- `54739_at`- `301_at`- `3042_at`- `441864_at`- `3568_at`- `3514_at`- `10398_at`- `760_at`- `597_at`-`3792_at`- `28442_at`- `8638_at`- `101927752_at`- `80127_at`- `28793_at`- `8520_at`- `5440_at`- `7443_at`- `23762_at`- `246_at`- `140_at`- `729870_at`- `105375878_at`- `28468_at`- `28479_at`- `28885_at`- `259215_at`- `2633_at`- `692073_at`- `64135_at`- `3145_at`- `7001_at`- `7504_at`- `5685_at`- `28938_at`- `8727_at`- `10498_at`- `28481_at`- `105372323_at`- `389860_at`- `28814_at`- `3646_at`- `26799_at`- `728577_at`- `669_at`- `938_at`- `25893_at`- `286_at`-`6536_at`-`28726_at`- `83699_at`- `6510_at`- `9829_at`, data=data[new_train_indices,],type="C-classification",kernel="sigmoid",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out4$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out4,accuracy)
  return(l)
}

ans40 <- BT54(DATASET2,Class,100,30) 
cat("The best cost value is equal to",ans40[[1]]$best.parameters$cost,"however, the best gamma value is equal to",ans40[[1]]$best.parameters$gamma)
cat("The highest accuracy is equal to",format(round(mean(ans40[[2]])*100, 2),nsmall=2),"\n")
```

### Choosing The Best Model

<div style="text-align: justify">I will now compare the accuracies between the models having highest accuracies.<br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x8 <- matrix(nrow = 8,ncol = 3,byrow = F)
colnames(x8) <- c("Highest Accuracy","Cost","Gamma")
rownames(x8) <- c("GLM using CV","GLM using BT","LDA using CV", "LDA using BT", "SVM with radial kernel", "SVM with polynomial kernel (degree 2)", "SVM with polynomial kernel (degree 3)", "SVM with sigmoid kernel")
x8[1,1] <- max(col_means23)*100; x8[1,2] <- "-"; x8[1,3] <- "-"
x8[2,1] <- max(col_means24)*100; x8[2,2] <- "-"; x8[2,3] <- "-"
x8[3,1] <- max(col_means25)*100; x8[3,2] <- "-"; x8[3,3] <- "-"
x8[4,1] <- max(col_means26)*100; x8[4,2] <- "-"; x8[4,3] <- "-"
x8[5,1] <- mean(ans37[[2]])*100; x8[5,2] <- ans37[[1]]$best.parameters$cost; x8[5,3] <- ans37[[1]]$best.parameters$gamma
x8[6,1] <- mean(ans38[[2]])*100; x8[6,2] <- ans38[[1]]$best.parameters$cost; x8[6,3] <- ans38[[1]]$best.parameters$gamma
x8[7,1] <- mean(ans39[[2]])*100; x8[7,2] <- ans39[[1]]$best.parameters$cost; x8[7,3] <- ans39[[1]]$best.parameters$gamma
x8[8,1] <- mean(ans40[[2]])*100; x8[8,2] <- ans40[[1]]$best.parameters$cost; x8[8,3] <- ans40[[1]]$best.parameters$gamma
var <- as.table(x8); knitr::kable(var)

names<-rownames(x8)  
m8<-names[which(x8==max(x8))]
a8<-max(x8[,1])
cat("The model(s) having the highest accuracy is(are)",m8,"\n")
cat("The highest accuracy is equal to",a8,"\n")
```

Now, I'll predict PTB on the test/predicting dataset.</div><br />

```{r, warning=FALSE,message=FALSE}
glm_probability <- predict(l24[[which.max(col_means24)]][[1]], newdata = prediction_dataset, type = "response")
```

## Binary Analysis (PPROM v/s Control)

```{r,warning=FALSE,echo=FALSE,message=FALSE}
train_dataset <- DF1[DF1$Train==1,-c(which(colnames(DF1)=="Train"),which(colnames(DF1)=="Individual"))] #This dataset contains mainly the observations present in the dataset classified as either sPTD, PPROM or control.
prediction_dataset <- DF1[DF1$Train==0,-c(which(colnames(DF1)=="Train"),which(colnames(DF1)=="Individual"))] #This dataset contains mainly the observations present in the dataset not classified in either class.
```

### Some Initial Statistics

```{r, message=FALSE, warning=FALSE}
#assign ur data frame to a new variable.
train_backup <- train_dataset 
cat("The dimension of this dataframe is",dim(train_backup),"\n")

#With this dataset, the summary() function will not useful since there exist a large number of predictors.
```

<div style="text-align: justify">This table will summarize the number of numerical/categorical/logical predictors.</div><br />

```{r, message=FALSE, echo=FALSE,warning=FALSE}
n=0;c=0; a <- sapply(train_backup, is.numeric); for (i in 1:dim(train_backup)[2]){if(a[i]==TRUE){n=n+1}else{c=c+1}}
#ct <- length(Filter(is.factor, train_backup))
lg <- length(Filter(is.logical, train_backup))

O <- matrix(nrow = 4,ncol = 1) #matrix 1
colnames(O) <- "Count"
rownames(O) <- c("Numeric Variable(s)","Factor Predictor(s)","Logical Column(s)","Total")
O[1,] <- n; O[2,] <- c; O[3,] <- lg; O[4,] <- c+n+lg
riable1 <- as.table(O); knitr::kable(riable1)
```

None of the Missing Values (eg. question marks, NA or NaN values, blank values) are present in this dataset.

### About The Class Predictor

```{r, message=FALSE, warning=FALSE}
#table of class
cat("The distribution of the 3 groups in the Class attribute")
table(train_backup$Class)
```

Removing the sPTD class.

```{r, message=FALSE, warning=FALSE}
train_backup <- train_backup[-which(train_backup$Class == "sPTD"),]
table(train_backup$Class)

train_backup$Class <- droplevels(train_backup$Class)
table(train_backup$Class) #nber of occurence in class

cat("The two groups are:",levels(train_backup$Class),"\nWhereby:\n 0 means Control\n 1 means PPROM (preterm premature rupture of membranes)\nLet's calculate the frequency of each subclass.")

control <- length(which(train_backup$Class=="Control"))
PPROM <- length(which(train_backup$Class=="PPROM"))

per_control <- control/length(train_backup$Class)*100
per_PPROM <- PPROM/length(train_backup$Class)*100

cat("The percentage of the control group is",format(round(per_control, 2), nsmall = 2),"\n")
cat("The percentage of the sPTD group is",format(round(per_PPROM, 2), nsmall = 2),"\n")
```

### Some Representative Plots 
<div style="text-align: justify">The pairs plot cannot be done at all because the presence of at most 29k predictors will be invisible in such kind of plot.</div>

#### Frequency Plot
<div style="text-align: justify">ggplot2 is a data visualization package for the statistical programming language R.</div>

```{r, message=FALSE, echo=FALSE,warning=FALSE}
ggplot(data=train_backup, aes(x=Class,  fill=Class))  + geom_bar() +  scale_x_discrete(name = 'Class',labels=labs) + theme_bw() + ggtitle("The occurence of each level in the categorical variable")
```

#### Scatterplot

<div style="text-align: justify">A scatter plot is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data. This plot shows the distribution of gestational age in each of the classes.</div><br />

```{r, message=FALSE, warning=FALSE}
#plot class v/s GA
ggplot(train_backup,aes(Class,GA)) +labs(title = "Scatterplot of the class across the gestational ages as determined by the last menstrual period or ultrasound") +geom_point()
```

### Correlation Analysis

```{r, warning=FALSE,message=FALSE}
var <- cor(train_backup[1:500]) #correlation
var[lower.tri(var)] <- NA #replaces values in lower triangular matrix to NA
var[is.na(var)] <- 0 #then replace the NA to 0
diag(var)<-0 #replace values in the diagonal equals to 1 to 0
df <- as.data.frame(var) #change the class of df to a dataframe
df[df>=1] <- 0 #replace all values bigger than 1 to by 0
fct <- apply(df,2,max) #get the max value from each column
m <- as.matrix(fct) #save the fct as a matrix in a new variable called m
```

<div style="text-align: justify">Let's zoom in and visualize the highly correlated and the non highly correlated genes.</div><br />

```{r, warning=FALSE,message=FALSE}
#get the highly correlated genes->having a correlation coefficient above 70%
highly_correlated_genes <- m[m[,1] > 0.70,]
highly_correlated_genes <- as.matrix(highly_correlated_genes)
cat("The number of highly correlated genes equals to",length(highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(highly_correlated_genes))

#get the non highly correlated genes->having a correlation coefficient below 70%
not_highly_correlated_genes <- m[m[,1] <= 0.70,]
not_highly_correlated_genes <- as.matrix(not_highly_correlated_genes)
cat("The number of non highly correlated genes equals to",length(not_highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(not_highly_correlated_genes))
```

### Correlation Visualization

```{r, warning=FALSE,echo=FALSE,message=FALSE}
correlationMatrix <- cor(train_backup[,1:500])
heatmap.2(correlationMatrix,dendrogram=c("none"), trace = "none", col = as.vector(wes_palette(name = "FantasticFox1", n=15, type="continuous")))
```

### Building Models

<div style="text-align: justify">The categorical predictor has two levels: Control is the first level and PPROM is the second one.

```{r, message=FALSE, warning=FALSE}
DATASET2 <- train_backup
levels(DATASET2$Class)
levels(DATASET2$Class) <- c(0,1); levels(DATASET2$Class)
attach(DATASET2)
number<-dim(DATASET2)[2]-2
```

<u>Analysis methods that I might consider for predicting preterm birth:</u><br />
Firstly, I will build generalized linear models.<br />
Secondly, I will move on to linear discriminant analysis.<br />
Thirdly, I will build several support vector machine models using different kernels.</div> <br />

#### Fitting GLM Models

<u>Using Cross-validation:</u>

```{r, message=FALSE, warning=FALSE}
CV14<-function(data,fold,Y)
{
  set.seed(65)

  n=nrow(data)
  
  index=sample(n,n)
  l<-vector("list")

  group=cut(index, breaks = fold, labels =FALSE)
  pval=c();accuracy=c()
  for( j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model=glm(Class~data[,gene]+data[,which(colnames(data)=="GA")],data=data, subset=train, family=binomial)
    pval[j]= summary(model)$coef[2,4] #get the pvalue 
    glm.pred=predict(model,data[test,],type="response")
    
    glm.prob=rep(0,nrow(data))
    glm.prob[glm.pred >.5]=1
    accuracy[j]=mean(glm.prob==Class[test]) 
  }
  
 l=list(model,pval,accuracy);return(l)
}

l27<-vector("list")

for(gene in 1:number)
  l27[[length(l27)+1]] <- CV14(DATASET2,100,Class)
names(l27) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l27, "[[", 3)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means27 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means27)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means27)
```

<u>P_value Interpretability</u><br />
In statistics, the p-value is the probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. A p-value less than or equal to 0.05 is statistically significant. It indicates a strong evidence against the null hypothesis. Therefore, I'll reject the null hypothesis and accept the alternative hypothesis.<br />

```{r, warning=FALSE,message=FALSE}
#retrieving all the pvalues from the list 
matrix_pval1 <- sapply(l27, "[[", 2); matrix_pval1 <- as.data.frame(matrix_pval1)
df_pval1 <- apply(matrix_pval1, 2, mean)
dF1 <- as.data.frame(t(df_pval1))
c<-0; vec <- c(); vec1 <- c()
for(i in 1:dim(dF1)[2]){
  if(dF1[i]<0.05){
    c<-c+1 
    vec <- c(vec,names(dF1[i]))
    vec1 <- c(vec1,as.character(dF1)[i])
  }
}
```

```{r, warning=FALSE,echo=FALSE,message=FALSE}
o <- matrix(nrow = 3 ,ncol = 1); o[1,1] <- c; o[2,1]<-dim(dF1)[2]-c; o[3,1] <- dim(dF1)[2]
rownames(o)<-c("True Positive","False Positive","Total Number Of Genes"); colnames(o)<-c("Count")
var <- as.table(o); knitr::kable(var)
```

This table shows how many genes are statistically significants and how many are not based on p-values. A true positive is an outcome where the model correctly predicts the positive class; however, a false positive is an outcome where the model incorrectly predicts the positive class.<br />

```{r, warning=FALSE,echo=FALSE,message=FALSE}
if(o[1,1] > 0){
  cat("Now let's zoom in and visualize which genes are statistically significant.\n")
  k<-matrix(nrow = length(vec),ncol = 2); k[,1]<-vec; k[,2]<-vec1
  colnames(k)<-c("Gene_Ids","P_value"); rownames(k)<-c(1:length(vec))
  backup_k <- k; var2 <- as.data.frame(backup_k) #max(as.character(var2$P_value))
  variable2 <- as.table(k); knitr::kable(variable2) }
```

<u>Using Bootsrapping:</u>

```{r, message=FALSE, warning=FALSE}
BT55 <- function(data,Y,R,percent) { 
  set.seed(66)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  pval<-rep(1,R)
  l <- vector("list",1) #creation of empty list
  model<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    model=glm(Class~data[,gene]+data[,which(colnames(data)=="GA")],data=data, subset=new_train_indices, family=binomial)
    pval[i]= summary(model)$coef[2,4] #get the pvalue 
    glm.pred=predict(model,data[test_indices,],type="response")
    
    glm.prob=rep(0,nrow(data))
    glm.prob[glm.pred >.5]=1
    accuracy[i]=mean(glm.prob==Class[test_indices]) 
  }
  l <- list(model,pval,accuracy); return(l)
}

l28<-vector("list")

for(gene in 1:number)
  l28[[length(l28)+1]] <- BT55(DATASET2,Class,100,30) 
names(l28) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l28, "[[", 3)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means28 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means28)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means28)
```

<u>P_value Interpretability</u><br />
In statistics, the p-value is the probability of obtaining results as extreme as the observed results of a statistical hypothesis test, assuming that the null hypothesis is correct. A p-value less than or equal to 0.05 is statistically significant. It indicates a strong evidence against the null hypothesis. Therefore, I'll reject the null hypothesis and accept the alternative hypothesis.<br />

```{r, warning=FALSE,message=FALSE}
#retrieving all the pvalues from the list 
matrix_pval1 <- sapply(l28, "[[", 2); matrix_pval1 <- as.data.frame(matrix_pval1)
df_pval1 <- apply(matrix_pval1, 2, mean)
dF1 <- as.data.frame(t(df_pval1))
c<-0; vec <- c(); vec1 <- c()
for(i in 1:dim(dF1)[2]){
  if(dF1[i]<0.05){
    c<-c+1 
    vec <- c(vec,names(dF1[i]))
    vec1 <- c(vec1,as.character(dF1)[i])
  }
}
```

```{r, warning=FALSE,echo=FALSE,message=FALSE}
o <- matrix(nrow = 3 ,ncol = 1); o[1,1] <- c; o[2,1]<-dim(dF1)[2]-c; o[3,1] <- dim(dF1)[2]
rownames(o)<-c("True Positive","False Positive","Total Number Of Genes"); colnames(o)<-c("Count")
var <- as.table(o); knitr::kable(var)
```

This table shows how many genes are statistically significants and how many are not based on p-values. A true positive is an outcome where the model correctly predicts the positive class; however, a false positive is an outcome where the model incorrectly predicts the positive class.<br />

```{r, warning=FALSE,echo=FALSE,message=FALSE}
if(o[1,1] > 0){
  cat("Now let's zoom in and visualize which genes are statistically significant.\n")
  k<-matrix(nrow = length(vec),ncol = 2); k[,1]<-vec; k[,2]<-vec1
  colnames(k)<-c("Gene_Ids","P_value"); rownames(k)<-c(1:length(vec))
  backup_k <- k; var2 <- as.data.frame(backup_k) #max(as.character(var2$P_value))
  variable2 <- as.table(k); knitr::kable(variable2) }
```

#### Fitting LDA Models

<u>Using Cross-validation:</u>

```{r, message=FALSE, warning=FALSE}
CV15 <- function(data, fold, output)
{
  n=nrow(data)
  set.seed(67)
  index=sample(n,n)
  l<-vector("list")

  group=cut(index, breaks = fold, labels =FALSE)
  accuracy=c()
  
  for( j in 1:fold)
  {
    test=which(group==j)
    train= index[-test]
    
    model2=lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=train, family=binomial)
    lda.pred=predict(model2,data[test,]) 
    
    #CLASS PREDICTION
    lda.class=lda.pred$class 
    #ACCURACY = TEST CORRECT RATE
    accuracy[j]<-mean(lda.class==Class[test])
  }
  
 l=list(model2,accuracy);return(l)
}

l29<-vector("list")

for(gene in 1:number)
  l29[[length(l29)+1]] <- CV15(DATASET2,100,Class)
names(l29) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l29, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means29 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means29)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means29)
```

<u>Using Bootsrapping:</u>

```{r, warning=FALSE,message=FALSE}
BT56 <- function(data,Y,R,percent) { 
  set.seed(68)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  l<-vector("list")

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an lda model on train data
    model2 <- lda(Class~data[,gene]+data[,which(colnames(data)=="GA")],data, subset=new_train_indices, family=binomial)

    #5) How well does this model perform on the test data? 
    lda.pred=predict(model2,data[test_indices,]) 

    #6)In order to make a prediction, convert these predicted probabilities into class labels: 0 or 1 - CLASS PREDICTION
    lda.class=lda.pred$class 

    #7) calculate a new ESTIMATED TEST ERROR RATE using mean() - ACCURACY = TEST CORRECT RATE
    accuracy[i]<-mean(lda.class==Class[test_indices])
  }
  l <- list(model2,accuracy); return(l)
}

l30<-vector("list")

for(gene in 1:number)
  l30[[length(l30)+1]] <- BT56(DATASET2,Class,100,30) 
names(l30) <- colnames(DATASET2[1:number])

matrix_accuracy <- sapply(l30, "[[", 2)
df_accuracy <- as.data.frame(matrix_accuracy)
col_means30 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_means30)*100, 2),nsmall=2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_means30)
```

#### Fitting SVM Model Using Linear Kernel

<div style="text-align: justify">The support vector machine (SVM) is an extension of the support vector classifier that results from enlarging the feature space using kernels to accommodate a non-linear boundary between classes. Fitting svm model whereby the predictors are the following: ONLY one highly correlated gene, all the non highly correlated genes and the gestational age predictor.</div><br/>

```{r, warning=FALSE,message=FALSE}
BT57 <- function(data,Y,R,percent) { 
  set.seed(69)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out1 <- tune.svm(Class ~ . - `4317_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `343171_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`-`7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`-`3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`-`28702_at`- `23365_at`- `100134229_at`- `101929007_at`- `54739_at`- `301_at`- `3042_at`- `441864_at`- `3568_at`- `3514_at`- `10398_at`- `760_at`- `597_at`- `3792_at`- `28442_at`- `8638_at`- `101927752_at`- `80127_at`- `28793_at`- `8520_at`- `5440_at`- `7443_at`- `23762_at`- `246_at`- `140_at`- `729870_at`- `105375878_at`- `28468_at`-`28479_at`- `28885_at`- `259215_at`- `2633_at`- `692073_at`- `64135_at`- `3145_at`- `7001_at`- `7504_at`- `5685_at`- `28938_at`- `8727_at`- `10498_at`- `28481_at`- `105372323_at`- `28814_at`- `3646_at`- `26799_at`- `728577_at`- `669_at`- `938_at`- `25893_at`- `286_at`- `6536_at`- `28726_at`- `83699_at`- `6510_at`- `9829_at`, data=data[new_train_indices,],type="C-classification",kernel="linear",cost = 10^(-2:3))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out1$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out1,accuracy)
  return(l)
}

answer1 <- BT57(DATASET2,Class,100,30) 
cat("The best cost value is equal to",answer1[[1]]$best.parameters$cost)
cat("The accuracy is equal to",format(round(mean(answer1[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Radial Kernel

```{r, warning=FALSE,message=FALSE}
BT58 <- function(data,Y,R,percent) { 
  set.seed(70)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out2 <- tune.svm(Class ~ . - `105377884_at`- `10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `343171_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`-`7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`-`3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`-`28702_at`- `23365_at`- `100134229_at`- `101929007_at`- `54739_at`- `301_at`- `3042_at`- `441864_at`- `3568_at`- `3514_at`- `10398_at`- `760_at`- `597_at`- `3792_at`- `28442_at`- `8638_at`- `101927752_at`- `80127_at`- `28793_at`- `8520_at`- `5440_at`- `7443_at`- `23762_at`- `246_at`- `140_at`- `729870_at`- `105375878_at`- `28468_at`-`28479_at`- `28885_at`- `259215_at`- `2633_at`- `692073_at`- `64135_at`- `3145_at`- `7001_at`- `7504_at`- `5685_at`- `28938_at`- `8727_at`- `10498_at`- `28481_at`- `105372323_at`- `28814_at`- `3646_at`- `26799_at`- `728577_at`- `669_at`- `938_at`- `25893_at`- `286_at`- `6536_at`- `28726_at`- `83699_at`- `6510_at`- `9829_at`, data=data[new_train_indices,],type="C-classification",kernel="radial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out2$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out2,accuracy)
  return(l)
}

answer2 <- BT58(DATASET2,Class,100,30) 
cat("The best cost value is equal to",answer2[[1]]$best.parameters$cost,"however, the best gamma value is equal to",answer2[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(answer2[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using polynomial kernel (Degree 2)

```{r, warning=FALSE,message=FALSE}
BT59 <- function(data,Y,R,percent) { 
  set.seed(71)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class ~ . - `105377884_at`- `4317_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `343171_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`-`7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`-`3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`-`28702_at`- `23365_at`- `100134229_at`- `101929007_at`- `54739_at`- `301_at`- `3042_at`- `441864_at`- `3568_at`- `3514_at`- `10398_at`- `760_at`- `597_at`- `3792_at`- `28442_at`- `8638_at`- `101927752_at`- `80127_at`- `28793_at`- `8520_at`- `5440_at`- `7443_at`- `23762_at`- `246_at`- `140_at`- `729870_at`- `105375878_at`- `28468_at`-`28479_at`- `28885_at`- `259215_at`- `2633_at`- `692073_at`- `64135_at`- `3145_at`- `7001_at`- `7504_at`- `5685_at`- `28938_at`- `8727_at`- `10498_at`- `28481_at`- `105372323_at`- `28814_at`- `3646_at`- `26799_at`- `728577_at`- `669_at`- `938_at`- `25893_at`- `286_at`- `6536_at`- `28726_at`- `83699_at`- `6510_at`- `9829_at`, data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 2)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy)
  return(l)
}

answer3 <- BT59(DATASET2,Class,100,30) 
cat("The best cost value is equal to",answer3[[1]]$best.parameters$cost,"however, the best gamma value is equal to",answer3[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(answer3[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 3)

```{r, warning=FALSE,message=FALSE}
BT60 <- function(data,Y,R,percent) { 
  set.seed(72)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class ~ . - `105377884_at`- `4317_at`- `10964_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `343171_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`-`7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`-`3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`-`28702_at`- `23365_at`- `100134229_at`- `101929007_at`- `54739_at`- `301_at`- `3042_at`- `441864_at`- `3568_at`- `3514_at`- `10398_at`- `760_at`- `597_at`- `3792_at`- `28442_at`- `8638_at`- `101927752_at`- `80127_at`- `28793_at`- `8520_at`- `5440_at`- `7443_at`- `23762_at`- `246_at`- `140_at`- `729870_at`- `105375878_at`- `28468_at`-`28479_at`- `28885_at`- `259215_at`- `2633_at`- `692073_at`- `64135_at`- `3145_at`- `7001_at`- `7504_at`- `5685_at`- `28938_at`- `8727_at`- `10498_at`- `28481_at`- `105372323_at`- `28814_at`- `3646_at`- `26799_at`- `728577_at`- `669_at`- `938_at`- `25893_at`- `286_at`- `6536_at`- `28726_at`- `83699_at`- `6510_at`- `9829_at`, data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 3)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l<- list(tune.out3,accuracy);return(l)
}

answer4 <- BT60(DATASET2,Class,100,30) 
cat("The best cost value is equal to",answer4[[1]]$best.parameters$cost,"however, the best gamma value is equal to",answer4[[1]]$best.parameters$gamma)
cat("The highest accuracy is equal to",format(round(mean(answer4[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Sigmoid Kernel

```{r, warning=FALSE,message=FALSE}
BT61 <- function(data,Y,R,percent) { 
  set.seed(73)
  
  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out4 <- tune.svm(Class ~ . - `105377884_at`- `4317_at`- `10964_at`- `3123_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `284486_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `6036_at`- `104326052_at`- `102724297_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `343171_at`- `154664_at`- `3045_at`- `28448_at`- `4939_at`- `110091776_at`- `28948_at`- `105377068_at`- `9318_at`- `4938_at`- `28521_at`- `7264_at`-`7102_at`- `57095_at`- `8140_at`- `28834_at`- `102723828_at`- `100033427_at`- `28526_at`- `219333_at`-`3001_at`- `1870_at`- `63893_at`- `2235_at`- `28452_at`- `24138_at`- `28946_at`-`28702_at`- `23365_at`- `100134229_at`- `101929007_at`- `54739_at`- `301_at`- `3042_at`- `441864_at`- `3568_at`- `3514_at`- `10398_at`- `760_at`- `597_at`- `3792_at`- `28442_at`- `8638_at`- `101927752_at`- `80127_at`- `28793_at`- `8520_at`- `5440_at`- `7443_at`- `23762_at`- `246_at`- `140_at`- `729870_at`- `105375878_at`- `28468_at`-`28479_at`- `28885_at`- `259215_at`- `2633_at`- `692073_at`- `64135_at`- `3145_at`- `7001_at`- `7504_at`- `5685_at`- `28938_at`- `8727_at`- `10498_at`- `28481_at`- `105372323_at`- `28814_at`- `3646_at`- `26799_at`- `728577_at`- `669_at`- `938_at`- `25893_at`- `286_at`- `6536_at`- `28726_at`- `83699_at`- `6510_at`- `9829_at`, data=data[new_train_indices,],type="C-classification",kernel="sigmoid",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out4$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out4,accuracy)
  return(l)
}

answer5 <- BT61(DATASET2,Class,100,30) 
cat("The best cost value is equal to",answer5[[1]]$best.parameters$cost,"however, the best gamma value is equal to",answer5[[1]]$best.parameters$gamma)
cat("The highest accuracy is equal to",format(round(mean(answer5[[2]])*100, 2),nsmall=2),"\n")
```

### Choosing The Best Model

<div style="text-align: justify">I will now compare the accuracies between the models having highest accuracies.<br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x9 <- matrix(nrow = 9,ncol = 3,byrow = F)
colnames(x9) <- c("Highest Accuracy","Cost","Gamma")
rownames(x9) <- c("GLM using CV","GLM using BT","LDA using CV", "LDA using BT", "SVM with linear kernel", "SVM with radial kernel", "SVM with polynomial kernel (degree 2)", "SVM with polynomial kernel (degree 3)", "SVM with sigmoid kernel")
x9[1,1] <- max(col_means27)*100; x9 [1,2] <- "-"; x9 [1,3] <- "-"
x9[2,1] <- max(col_means28)*100; x9 [2,2] <- "-"; x9 [2,3] <- "-"
x9[3,1] <- max(col_means29)*100; x9 [3,2] <- "-"; x9 [3,3] <- "-"
x9[4,1] <- max(col_means30)*100; x9 [4,2] <- "-"; x9 [4,3] <- "-"
x9[5,1] <- mean(answer1[[2]])*100; x9 [5,2] <- answer1[[1]]$best.parameters$cost; x9 [5,3] <- "-"
x9[6,1] <- mean(answer2[[2]])*100; x9 [6,2] <- answer2[[1]]$best.parameters$cost; x9 [6,3] <- answer2[[1]]$best.parameters$gamma
x9[7,1] <- mean(answer3[[2]])*100; x9 [7,2] <- answer3[[1]]$best.parameters$cost; x9 [7,3] <- answer3[[1]]$best.parameters$gamma
x9[8,1] <- mean(answer4[[2]])*100; x9 [8,2] <- answer4[[1]]$best.parameters$cost; x9 [8,3] <- answer4[[1]]$best.parameters$gamma
x9[9,1] <- mean(answer5[[2]])*100; x9 [9,2] <- answer5[[1]]$best.parameters$cost; x9 [9,3] <- answer5[[1]]$best.parameters$gamma
var <- as.table(x9); knitr::kable(var)

names<-rownames(x9)   
m9<-names[which(x9==max(x9))]
a9<-max(x9[,1])
cat("The set of prediction having the highest accuracy is",m9,"\n")
cat("The highest accuracy is equal to",a9,"\n")
```

Now, I'll predict PTB on the test/predicting dataset.</div><br />

```{r, warning=FALSE,message=FALSE}
glm_probability <- predict(l28[[which.max(col_means28)]][[1]], newdata = prediction_dataset, type = "response")
```

## My Results

<div style="text-align: justify">I will find the best model between the 3 different set of prediction: Multiclass, sPTD v/s Control and PPROM v/s Control.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x10 <- matrix(nrow = 3,ncol = 2,byrow = F)
colnames(x10) <- c("Highest Accuracy","Best Model(s) Name")
rownames(x10) <- c("Multiclass Prediction","sPTD v/s Control Prediction","PPROM v/s Control Prediction")
x10[1,1] <- a7;x10[1,2]<-m7
x10[2,1] <- a8;x10[2,2]<-m8
x10[3,1] <- a9;x10[3,2]<-m9
var <- as.table(x10); knitr::kable(var)

names<-rownames(x10)
cat("The set of prediction having the highest accuracy is",names[which(x10[,1]==max(x10[,1]))],"\n")
cat("The highest accuracy is equal to",format(round(max(as.numeric(x10[,1])), 2),nsmall=2),"\n")
```

## The Project's Results

<div style="text-align: justify">This table shows in a decrease order the accuracies of the models of all the participants who entered this project as well as my best model's accuracy for predicting preterm birth in asymptomatic women.<br/>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
data1 <- read.table("/Users/oliverabinader/Desktop/acc_results.txt",header = T,sep=" ")

data1[100,] <- as.numeric(max(x10[,1]))/100
data1 <- apply(data1, 1, function(x) 100*x)

m <- sort(data1, decreasing = TRUE)
d <- as.data.frame(m)
colnames(d) <- "Accuracy"; rownames(d) <- 1:nrow(d)
rownames(d)[rownames(d) == which(d$Accuracy == as.numeric(max(x10[,1])))] <- "Oliver" 

knitr::kable(d)
```

**I can finally see that I am classified as the second participant in this project. Part C was taking a dataset that contains at most 500 gene ids.**

<u>**PART II D - PREDICTING PRETERM BIRTH using the first 200 columns & ALL THE SAMPLES for each patient.**</u></div><br/>

# Forth Datatset

<div style="text-align: justify">I am required to develop models in order to make two sets of predictions for all individuals in the test set. The first set of predictions will classify individuals in the test set as sPTD vs Control, while the second prediction will classify individuals as PPROM vs Control. In this section I will use ALL THE SAMPLES collected from 17-36 weeks of gestation for a given patient when predicting that delivery occurred before 37 weeks by sPTD or PPROM.</div><br />

## The Combined Dataset

<div style="text-align: justify">This dataset contains the first 200 columns from object number 1 with some additional columns (Group, GA, IndividualID and Train) from the second object.<br />

```{r, message=FALSE, warning=FALSE}
DATA <- reduced_dat_200

#the additional columns
DATA$Class <- backup1$Group
DATA$GA <- backup1$GA
DATA$Individual <- backup1$IndividualID
DATA$Train <- backup1$Train
```

I'll divide the original dataset into two datasets. The train_dataset is used to build models whereas the prediction_dataset is use to predict preterm birth.</div><br />

## Binary Analysis (sPTD v/s Control)

```{r,warning=FALSE,echo=FALSE,message=FALSE}
train_dataset <- DATA[DATA$Train==1,-which(colnames(DATA)=="Train")] #This dataset contains mainly the observations present in the dataset classified as either sPTD, PPROM or control.
prediction_dataset <- DATA[DATA$Train==0,-which(colnames(DATA)=="Train")] #This dataset contains mainly the observations present in the dataset not classified in either class.
```

### Some Initial Statistics

```{r, message=FALSE, warning=FALSE}
#assign ur data frame to a new variable.
train_backup <- train_dataset 
cat("The dimension of this dataframe is",dim(train_backup),"\n")

#the type of each column
classes <- lapply(train_backup,class) 
cat("\nPrint the first six columns of the dataframe.\n")
head(classes)
cat("Print the last six predictors of the dataframe.\n")
tail(classes)

#With this dataset, the summary() function will not useful since I have a large number of predictors.
```

<div style="text-align: justify">This table summarizes the different types of variables.</div><br />

```{r, message=FALSE, echo=FALSE,warning=FALSE}
n=0;c=0; a <- sapply(train_backup, is.numeric); for (i in 1:dim(train_backup)[2]){if(a[i]==TRUE){n=n+1}else{c=c+1}}
#ct <- length(Filter(is.factor, train_backup))
lg <- length(Filter(is.logical, train_backup))

O <- matrix(nrow = 4,ncol = 1) #matrix 1
colnames(O) <- "Count"
rownames(O) <- c("Numeric Variable(s)","Factor Predictor(s)","Logical Column(s)","Total")
O[1,] <- n; O[2,] <- c; O[3,] <- lg; O[4,] <- c+n+lg
riable1 <- as.table(O); knitr::kable(riable1)
```

### Identification Of Missing Values

<div style="text-align: justify">Some columns present missing values. What I need to do is to identify them.

```{r, message=FALSE, warning=FALSE}
question_marks <- which(train_backup=="?",arr.ind = T)  

NA_values <- which(is.na(train_backup), arr.ind=T)

NaN_values <- which(apply(train_backup, 2, function(x) all(is.nan(x))))

infinite_values <- which(apply(train_backup, 2, function(x) all(is.infinite(x))))

blanck_values <- function (x) {sum(x=="") }
bvalues <- apply(train_backup, 2,blanck_values); bvalues<-as.character(bvalues);count<-0
for(index in 1:length(bvalues)){
  if(bvalues[index]!=0){
    count=count+1 } }
```

This table summarizes the different types of missing values.</div><br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x <- matrix(nrow = 5,ncol = 1,byrow = F)
colnames(x) <- c("Count")
rownames(x) <- c("Question marks","NA values","NaN values","Infinite values","Blank values")
tot <- dim(question_marks)[1]+dim(NA_values)[1]+length(NaN_values)+length(infinite_values)+count
x[1,1] <- dim(question_marks)[1]
x[2,1] <- dim(NA_values)[1]
x[3,1] <- length(NaN_values)
x[4,1] <- length(infinite_values)
x[5,1] <- tot
var <- as.table(x); knitr::kable(var)
```

### Checking Data Normalization

<div style="text-align: justify">I will do the shapiro test to check for normality, which can only be done on the numerical predictors.There are several methods for normality test such as Kolmogorov-Smirnov (K-S) normality test and Shapiro-Wilks test.</div><br />

```{r, message=FALSE, echo=FALSE,warning=FALSE}
numerical_predictor<-c() #a vector that will contain all the numerical predictors indicies
count2<-1 
for(i in 1:ncol(train_backup))  { # for loop to get all the numerical predictors indicies
  if(is.numeric(train_backup[,i])==TRUE) {
    numerical_predictor[count2]<-i
    count2<-count2+1 }
}

#if u apply the shapiro test on the numercical predictors, u'll then get their p_values and save them in a variable called p_val
p_val<-c()
test<-vector("list",1)
for(i in 1: length(numerical_predictor)) {
  test[[i]]<-shapiro.test(train_backup[,numerical_predictor[i]])
  p_val[i]<-test[[i]]$p.value
}
#p-value is a vector of all the p-values for all genes

normal<-which(p_val<0.05) #Since pval is less than 5%, hence accepting the null hypothesis means the data is normally distributed. However, rejecting the null hypothesis means the data will not normally distributed.

n<-(dim(train_backup)[2])-length(normal)
d<-length(normal)

cat("The number of columns that are not normally distributed is:",n,"\n")
cat("The number of columns that are normally distributed is:",d,"\n")
```

### About The Class Predictor

```{r, message=FALSE,echo=FALSE,warning=FALSE}
#table of class
cat("The distribution of the 3 groups in the Class attribute")
table(train_backup$Class)
```

Removing the PPROM class.

```{r, message=FALSE,echo=FALSE,warning=FALSE}
train_backup <- train_backup[-which(train_backup$Class == "PPROM"),]
table(train_backup$Class)

train_backup$Class <- droplevels(train_backup$Class)
table(train_backup$Class) #nber of occurence in class

cat("The two groups are:",levels(train_backup$Class),"\nWhereby:\n 0 means Control\n 1 means sPTD (spontaneous preterm labor and delivery with intact membranes)\nLet's calculate the frequency of each subclass.")

control <- length(which(train_backup$Class=="Control"))
sPTD <- length(which(train_backup$Class=="sPTD"))

per_control <- control/length(train_backup$Class)*100
per_sPTD <- sPTD/length(train_backup$Class)*100

cat("The percentage of the control group is",format(round(per_control, 2), nsmall = 2),"\n")
cat("The percentage of the sPTD group is",format(round(per_sPTD, 2), nsmall = 2),"\n")
```

### Some Representative Plots

<div style="text-align: justify">The pairs plot cannot be done at all because the presence of at most 29k predictors will be invisible in such kind of plot.</div>

#### Frequency Plot
<div style="text-align: justify">ggplot2 is a data visualization package for the statistical programming language R.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
ggplot(data=train_backup, aes(x=Class,  fill=Class))  + geom_bar() +  scale_x_discrete(name = 'Class',labels=labs) + theme_bw() + ggtitle("The occurence of each level in the categorical variable")
```

#### Correlogram

<div style="text-align: justify">Let's examine the correlation between some continuous variables present in the same dataframe. This is conveniently implemented using the ggcorrplot package. Correlation coefficients are used to measure the strength of the relationship between two variables. When the value of correlation coefficient is close to zero, generally between -0.1 and +0.1, the variables are said to have no linear relationship or a very weak linear relationship.</div> 

```{r, message=FALSE,echo=FALSE,warning=FALSE}
ggcorrplot(round(cor(train_backup[c(1:16)]), 1), hc.order = TRUE,type = "full",lab = TRUE,lab_size = 3,method="circle",colors= c("tomato2", "white", "springgreen3"), title="Correlogram between the first 16 gene ids",ggtheme=theme_bw)
cat("\n")
```

### Correlation Analysis

```{r, warning=FALSE,message=FALSE}
var <- cor(train_backup[1:200]) #correlation
var[lower.tri(var)] <- NA #replaces values in lower triangular matrix to NA
var[is.na(var)] <- 0 #then replace the NA to 0
diag(var)<-0 #replace values in the diagonal equals to 1 to 0
df <- as.data.frame(var) #change the class of df to a dataframe
df[df>=1] <- 0 #replace all values bigger than 1 to by 0
fct <- apply(df,2,max) #get the max value from each column
m <- as.matrix(fct) #save the fct as a matrix in a new variable called m
```

<div style="text-align: justify">Let's zoom in and visualize the highly correlated and the non highly correlated genes.</div><br />

```{r, warning=FALSE,message=FALSE}
#get the highly correlated genes->having a correlation coefficient above 70%
highly_correlated_genes <- m[m[,1] > 0.70,]
highly_correlated_genes <- as.matrix(highly_correlated_genes)
cat("The number of highly correlated genes equals to",length(highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(highly_correlated_genes))

#get the non highly correlated genes->having a correlation coefficient below 70%
not_highly_correlated_genes <- m[m[,1] <= 0.70,]
not_highly_correlated_genes <- as.matrix(not_highly_correlated_genes)
cat("The number of non highly correlated genes equals to",length(not_highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(not_highly_correlated_genes))
```

### Correlation Visualization

```{r, warning=FALSE,echo=FALSE,message=FALSE}
correlationMatrix <- cor(train_backup[,1:200])
heatmap.2(correlationMatrix,dendrogram=c("none"), trace = "none", col = as.vector(wes_palette(name = "FantasticFox1", n=15, type="continuous")))
```

### Building Models

<div style="text-align: justify">The categorical predictor has two levels: Control is the first level and sPTD is the second one.

```{r, message=FALSE, warning=FALSE}
DATAS <- train_backup
levels(DATAS$Class)
levels(DATAS$Class) <- c(0,1); levels(DATAS$Class)
attach(DATAS)
number <- ncol(DATAS)-3
```

<u>Analysis method that I might consider for predicting preterm birth:</u><br />
First, I will decide between generalized linear model and generalized linear mixed effect model.<br />
Second, I will build generalized linear mixed effect models(GLMER).<br />
Third, I will build several support vector machine models using different kernel.</div><br />

#### Fixed OR Mixed Effect Model?

<div style="text-align: justify">Now, I'll generate fixed-effects minimal base-line models and a base-line mixed-model using the glmer function with a random intercept for the Individual ID.</div><br />

```{r, warning=FALSE,message=FALSE}
# baseline model glm
m0.glm = glm(Class ~ 1, family = binomial, data = DATAS) 
# base-line mixed-model
m0.glmer = glmer(Class ~ (1|Individual), data = DATAS, family = binomial,control = glmerControl(optimizer = "bobyqa")) 
```

#### Testing the Random Effect

<div style="text-align: justify">Now, I'll check if including the random effect is permitted by comparing the AICs from the glm to AIC from the glmer model. If the AIC of the glmer object is smaller than the AIC of the glm object, then this indicates that including random intercepts is justified.

```{r, warning=FALSE,message=FALSE}
aic.glmer <- AIC(logLik(m0.glmer))
aic.glm <- AIC(logLik(m0.glm))
aic.glmer; aic.glm
```

The AIC of the glmer object is smaller which shows that including the random intercepts is justified. To confirm whether the AIC reduction is sufficient for justifying the inclusion of a random-effect structure, I'll also test whether the mixed-effects minimal base-line model explains significantly more variance by applying a Model Likelihood Ratio Test to the fixed- and the mixed effects minimal base-line models.

```{r, warning=FALSE,message=FALSE}
# test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmer)
pchisq(as.numeric(null.id), df=1, lower.tail=F) 
```

The p-value of the Model Likelihood Ratio Test is lower than 5% which shows that the inclusion of the random-effects structure is WARRANTED. I'll can now continue with the model fitting process.</div><br />

#### Fitting GLMER Models 

<div style="text-align: justify">The next step is to fit the model which means that I aim to find the best model. Before I begin with the model fitting process I need to add 'control = glmerControl(optimizer = "bobyqa")' to avoid unnecessary failures to converge.

k-fold CV involves randomly dividing the set of observations into k groups, or folds, of approximately equal size. The first fold is treated as a validation set, and the method is fit on the remaining k-1 folds. The classification error is then computed on the observations in the held-out fold group. This procedure is repeated k times; each time, a different group of observations is treated as a validation set. This process results in k estimates of the number of misclassified observations. And I will get what its called the k-fold CV estimate.

<u>Using Cross-validation:</u>

```{r, warning=FALSE,message=FALSE}
cv1 <- function(data,Y,fold){ 
  #fold=K

  #1)shuffle the data.
  indices <- sample(nrow(data),nrow(data))
  
  #Initialization of some empty vectors and a list.
  glmm_SE1 <- rep(1,fold)
  glmm_p_value1 <- rep(1,fold)
  glmm_accuracy1 <- rep(1,fold)
  l0 <- vector("list",1) #creation of empty list
  model1<-c()

  #2)split the data into x groups.
  vector1 <- cut(indices, breaks = fold, labels = FALSE)
  table(vector1) #the occurences of each fold.
  
  for(i in 1:fold){  
  
    test_set1 <- which(vector1==i)
    train_set1 <- indices[-test_set1]
    
    #5)build a generalized linear mixed-effects model.
    model1 <- glmer(Y ~ data[,gene]+data[,202]+(1|Individual), data = data, subset = train_set1, family = "binomial",control = glmerControl(optimizer = "bobyqa"))
    
    #6)get the model's coefficients.
    coefs1 <- data.frame(coef(summary(model1)))
    glmm_SE1[i] <- coefs1[2][[1]][2] #retrieve the SE of the gene-ids.
    glmm_p_value1[i] <- coefs1[4][[1]][2] #retrieve the p_value of the gene-ids.
    
    #7)predict the class labels of these observations.
    glmm_probability1 <- predict(model1,data[test_set1,],type="response",allow.new.levels = TRUE)
    
    #8)In order to make a prediction, convert these predicted probabilities into class labels: 0 or 1.
    glmm_prediction1 <- rep(0,nrow(data)); glmm_prediction1[glmm_probability1 > 0.50] <- 1

    #9)The mean() function will tell us about the model's accuracy.
    glmm_class1 <- Y[test_set1]
    glmm_accuracy1[i] <- mean(glmm_prediction1==glmm_class1) #the correct prediction.
  }
  #8)add the results to an empty list
  l0 <- list(glmm_SE1,glmm_p_value1,glmm_accuracy1,model1); return(l0)
}
list1<-vector("list")

for(gene in 1:number)
  list1[[length(list1)+1]] <- cv1(DATAS,Class,10) 
names(list1) <- colnames(DATAS[,1:number])

matrix_accuracy1 <- sapply(list1, "[[", 3)
df_accuracy1 <- as.data.frame(matrix_accuracy1)
col_m1 <- apply(df_accuracy1, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_m1)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_m1)
```

<u>Using Bootsrapping:</u> 

```{r, message=FALSE, warning=FALSE}
bt1 <- function(data,Y,R,percent) { 

  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  glmm_p_value1<-rep(1,R)
  glmm_SE1<-rep(1,R)
  glmm_accuracy1<-rep(1,R)
  l <- vector("list",1) #creation of empty list
  model1<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
   #5)build a generalized linear mixed-effects model.
    model1 <- glmer(Y ~ data[,gene]+data[,202]+(1|Individual), data = data, subset = new_train_indices, family = "binomial",control = glmerControl(optimizer = "bobyqa"))
    
    #6)get the model's coefficients.
    coefs1 <- data.frame(coef(summary(model1)))
    glmm_SE1[i] <- coefs1[2][[1]][2] #retrieve the SE of the gene-ids.
    glmm_p_value1[i] <- coefs1[4][[1]][2] #retrieve the p_value of the gene-ids.
    
    #7)predict the class labels of these observations.
    glmm_probability1 <- predict(model1,data[test_indices,],type="response",allow.new.levels = TRUE)
    
    #8)In order to make a prediction, convert these predicted probabilities into class labels: 0 or 1.
    glmm_prediction1 <- rep(0,nrow(data)); glmm_prediction1[glmm_probability1 > 0.50] <- 1

    #9)The mean() function will tell us about the model's accuracy.
    glmm_class1 <- Y[test_indices]
    glmm_accuracy1[i] <- mean(glmm_prediction1==glmm_class1) #the correct prediction.
  }
  #8)add the results to an empty list
  l <- list(glmm_SE1,glmm_p_value1,glmm_accuracy1,model1); return(l)
}

list2<-vector("list")

for(gene in 1:number)
  list2[[length(list2)+1]] <- bt1(DATAS,Class,10,30) 
names(list2) <- colnames(DATAS[1:number])

matrix_accuracy <- sapply(list2, "[[", 3)
df_accuracy <- as.data.frame(matrix_accuracy)
col_m2 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_m2)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_m2)
```

#### Fitting SVM Model Using Linear Kernel

<div style="text-align: justify">The support vector machine (SVM) is an extension of the support vector classifier that results from enlarging the feature space using kernels to accommodate a non-linear boundary between classes. Fitting svm model whereby the predictors are the following: ONLY one highly correlated gene, all the non highly correlated genes and the gestational age predictor.</div><br/>

```{r, warning=FALSE,message=FALSE}
bt2 <- function(data,Y,R,percent) { 

  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out1 <- tune.svm(Class ~ . - `4317_at`-`10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `1178_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `104326052_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28937_at`- `28825_at`- `9349_at`-`820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`, data=data[new_train_indices,],type="C-classification",kernel="linear",cost = 10^(-2:3))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out1$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out1,accuracy); return(l)
}

rep1 <- bt2(DATAS,Class,10,30) 
cat("The best cost value is equal to",rep1[[1]]$best.parameters$cost)
cat("The accuracy is equal to",format(round(mean(rep1[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Radial Kernel

```{r, warning=FALSE,message=FALSE}
bt3 <- function(data,Y,R,percent) { 

  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out2 <- tune.svm(Class ~ . - `105377884_at`-`10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `1178_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `104326052_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`, data=data[new_train_indices,],type="C-classification",kernel="radial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out2$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out2,accuracy)
  return(l)
}

rep2 <- bt3(DATAS,Class,10,30) 
cat("The best cost value is equal to",rep2[[1]]$best.parameters$cost,"however, the best gamma value is equal to",rep2[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(rep2[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 2)

```{r, warning=FALSE,message=FALSE}
bt4 <- function(data,Y,R,percent) { 

  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class ~ . - `105377884_at`-`4317_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `1178_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `104326052_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`, data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 2)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy)
  return(l)
}

rep3 <- bt4(DATAS,Class,10,30) 
cat("The best cost value is equal to",rep3[[1]]$best.parameters$cost,"however, the best gamma value is equal to",rep3[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(rep3[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Sigmoid Kernel

```{r, warning=FALSE,message=FALSE}
bt5 <- function(data,Y,R,percent) { 

  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out4 <- tune.svm(Class ~ . - `105377884_at`-`4317_at`- `10964_at`- `3123_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `1178_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `104326052_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`, data=data[new_train_indices,],type="C-classification",kernel="sigmoid",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out4$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out4,accuracy)
  return(l)
}

rep4 <- bt5(DATAS,Class,10,30) 
cat("The best cost value is equal to",rep4[[1]]$best.parameters$cost,"however, the best gamma value is equal to",rep4[[1]]$best.parameters$gamma)
cat("The accuracy is equal to",format(round(mean(rep4[[2]])*100, 2),nsmall=2),"\n")
```

### Choosing The Best Model

<div style="text-align: justify">I will now compare the accuracies between the models having highest accuracies.<br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x11<- matrix(nrow = 6,ncol = 3,byrow = F)
colnames(x11) <- c("Highest Accuracy","Cost","Gamma")
rownames(x11) <- c("GLMER using CV","GLMER using BT", "SVM with linear kernel", "SVM with radial kernel", "SVM with polynomial kernel (degree 2)", "SVM with sigmoid kernel")
x11[1,1] <- max(col_m1)*100; x11[1,2] <- "-"; x11[1,3] <- "-"
x11[2,1] <- max(col_m2)*100; x11[2,2] <- "-"; x11[2,3] <- "-"
x11[3,1] <- mean(rep1[[2]])*100; x11[3,2] <- rep1[[1]]$best.parameters$cost; x11[3,3] <- "-"
x11[4,1] <- mean(rep2[[2]])*100; x11[4,2] <- rep2[[1]]$best.parameters$cost; x11[4,3] <- rep2[[1]]$best.parameters$gamma
x11[5,1] <- mean(rep3[[2]])*100; x11[5,2] <- rep3[[1]]$best.parameters$cost; x11[5,3] <- rep3[[1]]$best.parameters$gamma
x11[6,1] <- mean(rep4[[2]])*100; x11[6,2] <- rep4[[1]]$best.parameters$cost; x11[6,3] <- rep4[[1]]$best.parameters$gamma
var <- as.table(x11); knitr::kable(var)

cat("The set of prediction having the highest accuracy is GLMER using CV.\n")
cat("The highest accuracy is equal to 100.\n")
```

Now, I'll predict PTB on the test/predicting dataset using the newdata argument.</div><br />

```{r, warning=FALSE,message=FALSE}
glmer_probability <- predict(list1[[which.max(col_m1)]][[4]], newdata = prediction_dataset, type = "response", allow.new.levels = TRUE) 
```

## Binary Analysis (PPROM v/s Control)

```{r,warning=FALSE,echo=FALSE,message=FALSE}
train_dataset <- DATA[DATA$Train==1,-which(colnames(DATA)=="Train")] #This dataset contains mainly the observations present in the dataset classified as either sPTD, PPROM or control.
prediction_dataset <- DATA[DATA$Train==0,-which(colnames(DATA)=="Train")] #This dataset contains mainly the observations present in the dataset not classified in either class.
```

### Some Initial Statistics

```{r, message=FALSE, warning=FALSE}
#assign ur data frame to a new variable.
train_backup <- train_dataset 
cat("The dimension of this dataframe is",dim(train_backup),"\n")
cat("The number of this samples is",dim(train_backup)[1],"\nThe number of variables is",dim(train_backup)[2],"\n")
```

<div style="text-align: justify">This table will summarize the different types of variables.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
n=0;c=0; a <- sapply(train_backup, is.numeric); for (i in 1:dim(train_backup)[2]){if(a[i]==TRUE){n=n+1}else{c=c+1}}
#ct <- length(Filter(is.factor, train_backup))
lg <- length(Filter(is.logical, train_backup))

O <- matrix(nrow = 4,ncol = 1) #matrix 1
colnames(O) <- "Count"
rownames(O) <- c("Numeric Variable(s)","Factor Predictor(s)","Logical Column(s)","Total")
O[1,] <- n; O[2,] <- c; O[3,] <- lg; O[4,] <- c+n+lg
riable1 <- as.table(O); knitr::kable(riable1)
```

### About The Class Predictor

```{r, message=FALSE, warning=FALSE}
#table of class
cat("The distribution of the 3 groups in the Class attribute")
table(train_backup$Class)
```

Removing the sPTD class.

```{r, message=FALSE, warning=FALSE}
train_backup <- train_backup[-which(train_backup$Class == "sPTD"),]
table(train_backup$Class)

train_backup$Class <- droplevels(train_backup$Class)
table(train_backup$Class) #nber of occurence in class

cat("The two groups are:",levels(train_backup$Class),"\nWhereby:\n 0 means Control\n 1 means PPROM \nLet's calculate the frequency of each subclass.")

control <- length(which(train_backup$Class=="Control"))
PPROM <- length(which(train_backup$Class=="PPROM"))

per_control <- control/length(train_backup$Class)*100
per_PPROM <- PPROM/length(train_backup$Class)*100

cat("The percentage of the control group is",format(round(per_control, 2), nsmall = 2),"\n")
cat("The percentage of the PPROM group is",format(round(per_PPROM, 2), nsmall = 2),"\n")
```

### Some Representative Plots
<div style="text-align: justify">The pairs plot cannot be done at all because the presence of at most 29k predictors will be invisible in such kind of plot.</div>

#### Frequency Plot
<div style="text-align: justify">ggplot2 is a data visualization package for the statistical programming language R.</div>

```{r, message=FALSE, echo=FALSE,warning=FALSE}
ggplot(data=train_backup, aes(x=Class,  fill=Class))  + geom_bar() +  scale_x_discrete(name = 'Class',labels=labs) + scale_fill_discrete(name = 'Class',labels=labs) + labs(x='Class') + theme_bw() + ggtitle("The occurence of each level in the categorical variable")
```

#### Correlogram
<div style="text-align: justify">Let's examine the correlation between some continuous variables present in the same dataframe. This is conveniently implemented using the ggcorrplot package. Correlation coefficients are used to measure the strength of the relationship between two variables. When the value of correlation coefficient is close to zero, generally between -0.1 and +0.1, the variables are said to have no linear relationship or a very weak linear relationship.</div> 

```{r, message=FALSE, echo=FALSE,warning=FALSE}
ggcorrplot(round(cor(train_backup[c(1:16)]), 1), hc.order = TRUE,type = "full",lab = TRUE,lab_size = 3,method="circle",colors= c("tomato2", "white", "springgreen3"), title="Correlogram between the first 16 gene ids",ggtheme=theme_bw)
```

#### Scatterplot
<div style="text-align: justify">A scatter plot is a type of plot or mathematical diagram using Cartesian coordinates to display values for typically two variables for a set of data. This plot shows the distribution of gestational age in each of the classes.</div> 

```{r, message=FALSE,echo=FALSE,warning=FALSE}
#plot between class and GA
ggplot(train_backup,aes(Class,GA)) +labs(title = "Scatterplot of the class across the gestational ages as determined by the last menstrual period or ultrasound") +geom_point()
```

### Correlation Analysis

```{r, warning=FALSE,message=FALSE}
var <- cor(train_backup[1:200]) #correlation
var[lower.tri(var)] <- NA #replaces values in lower triangular matrix to NA
var[is.na(var)] <- 0 #then replace the NA to 0
diag(var)<-0 #replace values in the diagonal equals to 1 to 0
df <- as.data.frame(var) #change the class of df to a dataframe
df[df>=1] <- 0 #replace all values bigger than 1 to by 0
fct <- apply(df,2,max) #get the max value from each column
m <- as.matrix(fct) #save the fct as a matrix in a new variable called m
```

<div style="text-align: justify">Let's zoom in and visualize the highly correlated and the non highly correlated genes.</div><br />

```{r, warning=FALSE,message=FALSE}
#get the highly correlated genes->having a correlation coefficient above 70%
highly_correlated_genes <- m[m[,1] > 0.70,]
highly_correlated_genes <- as.matrix(highly_correlated_genes)
cat("The number of highly correlated genes equals to",length(highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(highly_correlated_genes))

#get the non highly correlated genes->having a correlation coefficient below 70%
not_highly_correlated_genes <- m[m[,1] <= 0.70,]
not_highly_correlated_genes <- as.matrix(not_highly_correlated_genes)
cat("The number of non highly correlated genes equals to",length(not_highly_correlated_genes),"\nThe gene ids are the following:\n",rownames(not_highly_correlated_genes))
```

### Correlation Visualization

```{r, warning=FALSE,echo=FALSE,message=FALSE}
correlationMatrix <- cor(train_backup[,1:200])
heatmap.2(correlationMatrix,dendrogram=c("none"), trace = "none", col = as.vector(wes_palette(name = "FantasticFox1", n=15, type="continuous")))
```

### Building Models

<div style="text-align: justify">The categorical predictor has two levels: Control is the first level and PPROM is the second one.

```{r, message=FALSE, warning=FALSE}
DATS <- train_backup
levels(DATS$Class)
levels(DATS$Class) <- c(0,1); levels(DATS$Class)
attach(DATS)
number <- ncol(DATS)-3
```

<u>Analysis method that I might consider for predicting preterm birth:</u><br />
First, I will decide between generalized linear model and generalized linear mixed effect model.<br />
Second, I will build generalized linear mixed effect models(GLMER).<br />
Third, I will build several support vector machine models using different kernel.</div><br />

#### Fixed OR Mixed Effect Model?

<div style="text-align: justify">Now, I'll generate fixed-effects minimal base-line models and a base-line mixed-model using the glmer function with a random intercept for the Individual ID.</div> <br />

```{r, message=FALSE, warning=FALSE}
# baseline model glm
m0.glm = glm(Class ~ 1, family = binomial, data = DATS) 
# base-line mixed-model
m0.glmer = glmer(Class ~ (1|Individual), data = DATS, family = binomial,control = glmerControl(optimizer = "bobyqa")) 
```

#### Testing the Random Effect

<div style="text-align: justify">Now, I'll check if including the random effect is permitted by comparing the AICs from the glm to AIC from the glmer model. If the AIC of the glmer object is smaller than the AIC of the glm object, then this indicates that including random intercepts is justified.

```{r, message=FALSE, warning=FALSE}
aic.glmer <- AIC(logLik(m0.glmer))
aic.glm <- AIC(logLik(m0.glm))
aic.glmer; aic.glm
```

The AIC of the glmer object is smaller which shows that including the random intercepts is justified. To confirm whether the AIC reduction is sufficient for justifying the inclusion of a random-effect structure, I'll also test whether the mixed-effects minimal base-line model explains significantly more variance by applying a Model Likelihood Ratio Test to the fixed- and the mixed effects minimal base-line models.

```{r, message=FALSE, warning=FALSE}
# test random effects
null.id = -2 * logLik(m0.glm) + 2 * logLik(m0.glmer)
pchisq(as.numeric(null.id), df=1, lower.tail=F) 
```

The p-value of the Model Likelihood Ratio Test is lower than 5% which shows that the inclusion of the random-effects structure is WARRANTED. I can now continue with the model fitting process.</div><br />

#### Fitting GLMER Models 

<div style="text-align: justify">The next step is to fit the model which means that I aim to find the best model. Before I begin with the model fitting process I need to add 'control = glmerControl(optimizer = "bobyqa")' to avoid unnecessary failures to converge.

<u>Using Cross-validation:</u>

```{r, warning=FALSE,message=FALSE}
cross_validation1 <- function(data,Y,fold){ 
  #fold=K

  #1)shuffle the data.
  indices <- sample(nrow(data),nrow(data))
  
  #Initialization of some empty vectors and a list.
  glmm_SE1 <- rep(1,fold)
  glmm_p_value1 <- rep(1,fold)
  glmm_accuracy1 <- rep(1,fold)
  l0 <- vector("list",1) #creation of empty list

  #2)split the data into x groups.
  vector1 <- cut(indices, breaks = fold, labels = FALSE)
  table(vector1) #the occurences of each fold.
  
  for(i in 1:fold){  
  
    test_set1 <- which(vector1==i)
    train_set1 <- indices[-test_set1]
    
    #5)build a generalized linear mixed-effects model.
    model1 <- glmer(Y ~ data[,gene]+data[,202]+(1|Individual), data = data, subset = train_set1, family = "binomial",control = glmerControl(optimizer = "bobyqa"))
    
    #6)get the model's coefficients.
    coefs1 <- data.frame(coef(summary(model1)))
    glmm_SE1[i] <- coefs1[2][[1]][2] #retrieve the SE of the gene-ids.
    glmm_p_value1[i] <- coefs1[4][[1]][2] #retrieve the p_value of the gene-ids.
    
    #7)predict the class labels of these observations.
    glmm_probability1 <- predict(model1,data[test_set1,],type="response",allow.new.levels = TRUE)
    
    #8)In order to make a prediction, convert these predicted probabilities into class labels: 0 or 1.
    glmm_prediction1 <- rep(0,nrow(data)); glmm_prediction1[glmm_probability1 > 0.50] <- 1

    #9)The mean() function will tell us about the model's accuracy.
    glmm_class1 <- Y[test_set1]
    glmm_accuracy1[i] <- mean(glmm_prediction1==glmm_class1) #the correct prediction.
  }
  #8)add the results to an empty list
  l0 <- list(glmm_SE1,glmm_p_value1,glmm_accuracy1,model1); return(l0)
}

L1<-vector("list")

for(gene in 1:number)
  L1[[length(L1)+1]] <- cross_validation1(DATS,Class,10) 
names(L1) <- colnames(DATS[,1:number])

matrix_accuracy1 <- sapply(L1, "[[", 3)
df_accuracy1 <- as.data.frame(matrix_accuracy1)
col_acc1 <- apply(df_accuracy1, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_acc1)*100, 2), nsmall = 2),"percent.\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_acc1)
```

<u>Using Bootsrapping:</u>

```{r, message=FALSE, warning=FALSE}
bootstrap1 <- function(data,Y,R,percent) { 

  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  accuracy <- rep(1,R)
  glmm_p_value1<-rep(1,R)
  glmm_SE1<-rep(1,R)
  glmm_accuracy1<-rep(1,R)
  l <- vector("list",1) #creation of empty list
  model1<-c()

  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
   #5)build a generalized linear mixed-effects model.
    model1 <- glmer(Y ~ data[,gene]+data[,202]+(1|Individual), data = data, subset = new_train_indices, family = "binomial",control = glmerControl(optimizer = "bobyqa"))
    
    #6)get the model's coefficients.
    coefs1 <- data.frame(coef(summary(model1)))
    glmm_SE1[i] <- coefs1[2][[1]][2] #retrieve the SE of the gene-ids.
    glmm_p_value1[i] <- coefs1[4][[1]][2] #retrieve the p_value of the gene-ids.
    
    #7)predict the class labels of these observations.
    glmm_probability1 <- predict(model1,data[test_indices,],type="response",allow.new.levels = TRUE)
    
    #8)In order to make a prediction, convert these predicted probabilities into class labels: 0 or 1.
    glmm_prediction1 <- rep(0,nrow(data)); glmm_prediction1[glmm_probability1 > 0.50] <- 1

    #9)The mean() function will tell us about the model's accuracy.
    glmm_class1 <- Y[test_indices]
    glmm_accuracy1[i] <- mean(glmm_prediction1==glmm_class1) #the correct prediction.
  }
  #8)add the results to an empty list
  l <- list(glmm_SE1,glmm_p_value1,glmm_accuracy1,model1); return(l)
}

L2<-vector("list")

for(gene in 1:number)
  L2[[length(L2)+1]] <- bootstrap1(DATS,Class,10,30) 
names(L2) <- colnames(DATS[1:number])

matrix_accuracy <- sapply(L2, "[[", 3)
df_accuracy <- as.data.frame(matrix_accuracy)
col_acc2 <- apply(df_accuracy, 2, mean)
cat("The highest accuracy is equal to",format(round(max(col_acc2)*100, 2), nsmall = 2),"\n")
```

The gene id having highest mean with its index:
```{r, warning=FALSE,message=FALSE}
which.max(col_acc2)
```

#### Fitting SVM Model Using Linear Kernel

```{r, warning=FALSE,message=FALSE}
bootstrap2 <- function(data,Y,R,percent) { 

  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out1 <- tune.svm(Class ~ . - `4317_at`-`10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `1178_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `104326052_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`, data=data[new_train_indices,],type="C-classification",kernel="linear",cost = 10^(-2:3))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out1$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out1,accuracy)
  return(l)
}

rep5 <- bootstrap2(DATS,Class,10,30) 
cat("The best cost value is equal to",rep5[[1]]$best.parameters$cost)
cat("The highest accuracy is equal to",format(round(mean(rep5[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Radial Kernel

```{r, warning=FALSE,message=FALSE}
bootstrap3 <- function(data,Y,R,percent) { 

  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out2 <- tune.svm(Class ~ . - `105377884_at`-`10964_at`- `3123_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `1178_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `104326052_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`, data=data[new_train_indices,],type="C-classification",kernel="radial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out2$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out2,accuracy)
  return(l)
}

rep6 <- bootstrap3(DATS,Class,10,30) 
cat("The best cost value is equal to",rep6[[1]]$best.parameters$cost,"however, the best gamma value is equal to",rep6[[1]]$best.parameters$gamma)
cat("The highest accuracy is equal to",format(round(mean(rep6[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Polynomial Kernel (Degree 3)

```{r, warning=FALSE,message=FALSE}
bootstrap4 <- function(data,Y,R,percent) { 

  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out3 <- tune.svm(Class ~ . - `105377884_at`-`4317_at`- `10964_at`- `3429_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `1178_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `104326052_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`, data=data[new_train_indices,],type="C-classification",kernel="polynomial",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4),degree = 3)

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out3$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out3,accuracy)
  return(l)
}

rep7 <- bootstrap4(DATS,Class,10,30) 
cat("The best cost value is equal to",rep7[[1]]$best.parameters$cost,"however, the best gamma value is equal to",rep7[[1]]$best.parameters$gamma)
cat("The highest accuracy is equal to",format(round(mean(rep7[[2]])*100, 2),nsmall=2),"\n")
```

#### Fitting SVM Model Using Sigmoid Kernel

```{r, warning=FALSE,message=FALSE}
bootstrap5 <- function(data,Y,R,percent) { 

  #R is the # of bootstrap estimates 
  indices <- c(1:nrow(data)) 

  #1)some initiation vectors.
  best_parameters<- rep(1,R)
  accuracy <- rep(1,R)
  l<-vector("list")
  
  for(i in 1:R){
    #2)extract a certain percentange from the original data
    test_indices <- sample(nrow(data), size = nrow(data)*percent/100,replace = FALSE)
    remaining_indices <- indices[-test_indices]
  
    #3)from remaining indices, obtain a percentage with replacement
    var <- sample(remaining_indices, size = nrow(data)*percent/100, replace = TRUE)
  
    #4)merge the test indices with the new train indices. 
    new_train_indices <- c(remaining_indices, var)
    new_train_indices #train = equals to nrow(data)
  
    #5)fit an svm model on train data
    tune.out4 <- tune.svm(Class ~ . - `105377884_at`-`4317_at`- `10964_at`- `3123_at`- `3434_at`- `1088_at`- `10561_at`- `10321_at`- `51191_at`- `1669_at`- `105370807_at`- `3934_at`- `932_at`- `1178_at`- `4057_at`- `6037_at`- `671_at`- `4940_at`- `4973_at`- `3493_at`- `710_at`- `3437_at`- `100288486_at`- `3119_at`- `2537_at`- `2993_at`- `3494_at`- `644172_at`- `28908_at`- `3538_at`- `51327_at`- `6947_at`- `28912_at`- `28959_at`- `4599_at`- `1193_at`- `387837_at`- `107984755_at`- `129607_at`- `55601_at`- `342618_at`- `94240_at`- `2994_at`- `4680_at`- `28943_at`- `3240_at`- `100033431_at`- `4061_at`- `104326052_at`- `2996_at`- `6423_at`- `6563_at`- `83483_at`- `5273_at`- `28825_at`- `820_at`- `150000_at`- `1991_at`- `154664_at`- `3045_at`, data=data[new_train_indices,],type="C-classification",kernel="sigmoid",cost = 10^(-2:2),gamma = c(0.5,1,2,3,4))

   #6) predict the class labels of these test observations
    ypred_1<-predict(tune.out4$best.model ,data[test_indices,]) 
    accuracy[i] <- mean(ypred_1==data[test_indices,"Class"]) 
  }
  l <- list(tune.out4,accuracy)
  return(l)
}

rep8 <- bootstrap5(DATS,Class,10,30) 
cat("The best cost value is equal to",rep8[[1]]$best.parameters$cost,"however, the best gamma value is equal to",rep8[[1]]$best.parameters$gamma)
cat("The highest accuracy is equal to",format(round(mean(rep8[[2]])*100, 2),nsmall=2),"\n")
```

### Choosing The Best Model

<div style="text-align: justify">I will now compare the accuracies between the models having highest accuracies.<br />

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x12 <- matrix(nrow = 6,ncol = 3,byrow = F)
colnames(x12) <- c("Highest Accuracy","Cost","Gamma")
rownames(x12) <- c("GLMER using CV","GLMER using BT", "SVM with linear kernel", "SVM with radial kernel", "SVM with polynomial kernel (degree 3)", "SVM with sigmoid kernel")
x12[1,1] <- max(col_acc1)*100; x12[1,2] <- "-"; x12[1,3] <- "-"
x12[2,1] <- max(col_acc2)*100; x12[2,2] <- "-"; x12[2,3] <- "-"
x12[3,1] <- mean(rep5[[2]])*100; x12[3,2] <- rep5[[1]]$best.parameters$cost; x12[3,3] <- "-"
x12[4,1] <- mean(rep6[[2]])*100; x12[4,2] <- rep6[[1]]$best.parameters$cost; x12[4,3] <- rep6[[1]]$best.parameters$gamma
x12[5,1] <- mean(rep7[[2]])*100; x12[5,2] <- rep7[[1]]$best.parameters$cost; x12[5,3] <- rep7[[1]]$best.parameters$gamma
x12[6,1] <- mean(rep8[[2]])*100; x12[6,2] <- rep8[[1]]$best.parameters$cost; x12[6,3] <- rep8[[1]]$best.parameters$gamma
var <- as.table(x12); knitr::kable(var)

names<-rownames(x12)   
m12<-names[which.max(x12)]
a12<-max(x12[,1])
cat("The model having the highest accuracy is",m12,"\n")
cat("The highest accuracy is equal to",a12,"\n")
```

Now, I'll predict PTB on the test/predicting dataset.</div><br />

```{r, warning=FALSE,message=FALSE}
glmer_probability <- predict(L1[[which.max(col_acc1)]][[4]], newdata = prediction_dataset, type = "response", allow.new.levels = TRUE) 
```

## My Results

<div style="text-align: justify">I will find the best model between the 3 different set of prediction: Multiclass, sPTD v/s Control and PPROM v/s Control.</div>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
x13 <- matrix(nrow = 2,ncol = 2,byrow = F)
colnames(x13) <- c("Highest Accuracy","Best Model(s) Name")
rownames(x13) <- c("sPTD v/s Control Prediction","PPROM v/s Control Prediction")
x13[1,1] <- 100;x13[1,2]<-"GLMER using CV"
x13[2,1] <- a12;x13[2,2]<-m12
var <- as.table(x13); knitr::kable(var)

cat("The set of prediction having the highest accuracy is sPTD v/s Control Prediction.\n")
cat("The highest accuracy is equal to 100.\n")
```

## The Project's Results

<div style="text-align: justify">This table shows in a decrease order the accuracies of the models of all participants as well as my best model's accuracy for predicting preterm birth in asymptomatic women.<br/>

```{r, message=FALSE,echo=FALSE,warning=FALSE}
data1 <- read.table("/Users/oliverabinader/Desktop/acc_results.txt",header = T,sep=" ")

data1[100,] <- 100/100
data1 <- apply(data1, 1, function(x) 100*x)

m <- sort(data1, decreasing = TRUE)
d <- as.data.frame(m)
colnames(d) <- "Accuracy"; rownames(d) <- 1:nrow(d)
rownames(d)[rownames(d) == which(d$Accuracy == 100)] <- "Oliver" 

knitr::kable(d)
```

**I can finally see that I am classified as the first participant in this project. Part D was taking a dataset that contains at most 200 gene ids.**


This brings me to the end of the statistical analysis workflow for predicting PTB in asymptomatic women.</div>